{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dominos_Work_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMPQvgar/IiA5tNDyVpLL1F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmkarKotwalProject/Dominos_Work/blob/main/Dominos_Work_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7X--pvSECYl"
      },
      "outputs": [],
      "source": [
        "from warnings import filterwarnings\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import gensim\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate\n",
        "import sklearn.metrics as sm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from textblob import Word, TextBlob\n",
        "from wordcloud import WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspellchecker\n",
        "!pip install Counter\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fme10qSpFRIe",
        "outputId": "e6e1f610-8952-4540-8899-8acc89b6efd7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.6.3-py3-none-any.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.6.3\n",
            "Collecting Counter\n",
            "  Downloading Counter-1.0.0.tar.gz (5.2 kB)\n",
            "Building wheels for collected packages: Counter\n",
            "  Building wheel for Counter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Counter: filename=Counter-1.0.0-py3-none-any.whl size=5411 sha256=1788483049a1c1b6622b0868ac761690c075b4b0e889579de5c0b2e5f4e12cbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/15/75/7a0462a00beb08e391f5da370ca409b56781d2501dba083fa3\n",
            "Successfully built Counter\n",
            "Installing collected packages: Counter\n",
            "Successfully installed Counter-1.0.0\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option(\"display.max_rows\",500)\n",
        "pd.set_option(\"display.max_columns\",None)\n",
        "pd.set_option(\"display.max_colwidth\",None)"
      ],
      "metadata": {
        "id": "mNjyt0w4FSZC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv5RXbFDLb41",
        "outputId": "65e278d0-9037-4a51-b53b-566b579317c1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/CUSTOMER_REVIEWS/ScrapedReviews/PROJECT SCRAPED REVIEWS/Dominos Pizza 3k/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcG8TRlPQHGN",
        "outputId": "2b83d65f-31e8-4311-881a-d346f7fbe5e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CUSTOMER_REVIEWS/ScrapedReviews/PROJECT SCRAPED REVIEWS/Dominos Pizza 3k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('All_Reviews_DP.xlsx')"
      ],
      "metadata": {
        "id": "PkEYP41dLyZx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import pandas as pd\n",
        "# from google.colab import files\n",
        "# import io\n",
        "\n",
        "\n",
        "# uploaded = files.upload()\n",
        "# df= pd.read_excel(io.BytesIO(uploaded['All_Reviews_DP.xlsx']))"
      ],
      "metadata": {
        "id": "Tcn1OvqeFUXN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Keeping the original as it is.\n",
        "df_review=df "
      ],
      "metadata": {
        "id": "PgV4PVySFWSE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "THIS IS A BACKUP LOAD OF ORIGINAL DATAFRAME, ONLY USE IF MESSED UP"
      ],
      "metadata": {
        "id": "IV_MgALQFa5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #FOR EMPTYING THE DATAFRAME\n",
        "# df_review.drop(columns=['Review','Sentiment'],inplace=True)"
      ],
      "metadata": {
        "id": "m8P77CFoFYQj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #FOR RELOADING WITH ORIGINAL RAW DATA\n",
        "# df= pd.read_excel(io.BytesIO(uploaded['All_Reviews_DP.xlsx']))\n",
        "# df_review=df"
      ],
      "metadata": {
        "id": "WCvp-DTQFckD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BACKUP CODE END"
      ],
      "metadata": {
        "id": "nbq7uR6ZFd4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_review['Sentiment']=df_review['Sentiment'].astype(int)"
      ],
      "metadata": {
        "id": "00Llxeo-SCqt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_review.head())\n",
        "print(df_review.shape)"
      ],
      "metadata": {
        "id": "ZmiLZPP5Fglz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "805990b2-0eee-466a-d2a9-ccfb07d19136"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                                                                                                                                                                                              Review  \\\n",
            "0                                                                                                                                                                                                                                                       its too good   \n",
            "1                                                                                                                                                                                                                                                     waste of money   \n",
            "2                                                                                                                                                                                                                                      pizza was yum but little late   \n",
            "3                                                                                                                                                                                                                                        Delivery person was amazing   \n",
            "4  even after calling personally and even after giving special instructions received very cold pizza base is hard and it tastes stale as if it was premade thought chicken parcels were really hot and fresh with proper quantity but really disappointed with pizza   \n",
            "\n",
            "   Sentiment  \n",
            "0          1  \n",
            "1          0  \n",
            "2          1  \n",
            "3          1  \n",
            "4          0  \n",
            "(2746, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HOW MANY POSITIVE REVIEWS, HOW MANY NEGATIVE REVIEWS"
      ],
      "metadata": {
        "id": "sjeniecJFjri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_review[df_review['Sentiment']==1].count())\n",
        "print(df_review[df_review['Sentiment']==0].count())"
      ],
      "metadata": {
        "id": "bUXOMMm7Fh46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b306725-5075-4b71-d2cf-26953cdf61a2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review       1543\n",
            "Sentiment    1543\n",
            "dtype: int64\n",
            "Review       1203\n",
            "Sentiment    1203\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_review['Sentiment'].unique()"
      ],
      "metadata": {
        "id": "J6-bqsYvN5LT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0ee5dc9-f37a-4f00-f52e-c82cae474bd3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if any null values\n",
        "df_review[df_review.isna().any(axis=1)]"
      ],
      "metadata": {
        "id": "TiCIkUUDO5bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "a9977e8f-0cc2-4ebd-8f13-98bcab2d576d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Review, Sentiment]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-760fee6b-df3a-49e1-b9f9-19fcba4143e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-760fee6b-df3a-49e1-b9f9-19fcba4143e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-760fee6b-df3a-49e1-b9f9-19fcba4143e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-760fee6b-df3a-49e1-b9f9-19fcba4143e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PRE-PROCESSING!"
      ],
      "metadata": {
        "id": "8MNc9Ok5P6C_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.^[\\w\\s]=remove all except alphanumeric and whitespaces tabs and spaces [\\d] remove digits"
      ],
      "metadata": {
        "id": "jgeWe6JxQMBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Review']=df['Review'].replace('\\d+','',regex=True)"
      ],
      "metadata": {
        "id": "Y3sg8UhcP40W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38a67175-3f9d-4158-e8f6-d9a44badcf0d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<input>:1: DeprecationWarning: invalid escape sequence \\d\n",
            "<ipython-input-19-7140ae72fba7>:1: DeprecationWarning: invalid escape sequence \\d\n",
            "  df['Review']=df['Review'].replace('\\d+','',regex=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.WHAT AM I TRYING TO DO HERE:- Removing more than 2 consecutive occurrences of a character, if its a special char, replace with space\n",
        "so @@@@@@ => @@ and then '__'. This will happen with words too, hellllloo => helloo"
      ],
      "metadata": {
        "id": "AkmS00m4QuVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#WHAT AM I TRYING TO DO HERE:-  Removing more than 2 consecutive occurrences of a character, if its a special char, replace with space\n",
        "# so @@@@@@ => @@ and then '__'. This will happen with words too, hellllloo => helloo\n",
        "#1. REPLACE SPECIAL CHARACTERS BY ' ' AND then using regex, remove consecutive duplicates of ' ' i.e '         '  (big spaces between words)\n",
        "df_review['Review']=df_review['Review'].replace('\\n', ' ',regex=True)\n",
        "df_review['Review']=df_review['Review'].replace(('[^!|^.|^,|^;|^-|^@|^\\w\\s]'),\"\", regex = True)\n",
        "for i in range(len(df_review)):\n",
        "  sentence=df_review['Review'][i]\n",
        "  sentence=sentence.replace('.', ' ')\n",
        "  sentence=sentence.replace(',', ' ')\n",
        "  sentence=sentence.replace('!', ' ')\n",
        "  sentence=sentence.replace('.', ' ')\n",
        "  sentence=sentence.replace(';', ' ')\n",
        "  sentence=sentence.replace('-', ' ')\n",
        "  sentence=sentence.replace('@', ' ')\n",
        "  sentence=sentence.replace(')', ' ')\n",
        "  sentence=sentence.replace('(', ' ')\n",
        "  sentence=sentence.replace('{', ' ')\n",
        "  sentence=sentence.replace('}', ' ')\n",
        "\n",
        "  sentence=re.sub(r'(.)\\1+', r'\\1\\1',sentence)   # yummmyyy => yummyy,  '     '=>'  '  #This line will remove char which occures more than 2 times consecutively.\n",
        "  df_review['Review'][i]=sentence\n",
        "\n",
        "#df_review['Review']=df_review['Review'].replace('[^\\w\\s]', '',regex=True)\n",
        "print(df_review.head(10))"
      ],
      "metadata": {
        "id": "yzETyHagRH7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.REMOVING CHARACTERS WHICH ONLY OCCUR ONCE! ALSO REPLACING TWO CONSECUTIVE SPACES BY ONE"
      ],
      "metadata": {
        "id": "orTKzKDkROq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnter=0\n",
        "while(cnter<2):\n",
        "  for i in range(len(df_review)):\n",
        "    new_sentence=\" \"\n",
        "    sentence=df_review['Review'][i]    #get the row i.e. sentence\n",
        "    #print(\"before removing:\",df_review['Review'][i])\n",
        "    words=sentence.split()  #makes a list of the words in the sentence\n",
        "    for word in words:      #check every words length and if it is less than 2, remove it\n",
        "      if len(word)<2:\n",
        "        #print(word)\n",
        "        words.remove(word)\n",
        "    new_sentence=new_sentence.join(words) #Create a new sentence by joining all the words in the list with \" \" as a separator\n",
        "    df_review['Review'][i]=new_sentence   #replace current row i.e. sentence by the new sentence\n",
        "    #print(\"after removing:\",df_review['Review'][i])\n",
        "  cnter=cnter+1"
      ],
      "metadata": {
        "id": "N4sUqnCtRNmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing word if length is less than 2\n",
        "for i in range(len(df_review)):\n",
        "  sentence=df_review['Review'][i]\n",
        "  words=sentence.split()  #makes a list of the words in the sentence\n",
        "  for word in words:      #check every words length and if it is less than 2, print it\n",
        "    if len(word)<2:\n",
        "      print(word)"
      ],
      "metadata": {
        "id": "weC-dm6wRZqo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_review.head(5))"
      ],
      "metadata": {
        "id": "vZdzCjZBRbDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "636bbc22-4b1b-4c12-c36e-3c075359d911"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                                                                                                                                                                                              Review  \\\n",
            "0                                                                                                                                                                                                                                                       its too good   \n",
            "1                                                                                                                                                                                                                                                     waste of money   \n",
            "2                                                                                                                                                                                                                                      pizza was yum but little late   \n",
            "3                                                                                                                                                                                                                                        Delivery person was amazing   \n",
            "4  even after calling personally and even after giving special instructions received very cold pizza base is hard and it tastes stale as if it was premade thought chicken parcels were really hot and fresh with proper quantity but really disappointed with pizza   \n",
            "\n",
            "   Sentiment  \n",
            "0          1  \n",
            "1          0  \n",
            "2          1  \n",
            "3          1  \n",
            "4          0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.FINDING MISSPELLED WORDS AND CORRECTING THEM!\n",
        "Algorithm used for correcting words:\n",
        "\n",
        "    Create a list of misspelled words found in the dataset.\n",
        "    Create a list of correctly spelled words found in the dataset.\n",
        "    Use similar() function of 'SequenceMatcher' for finding similarity between words from both lists. If it is greater than 0.8, create a dictionary (dict['misspelled word'=correctly spelled word).\n",
        "    Now traverse the dataset, while checking a row, extract its misspelled words, check if misspelled word is in the dictionary, if it is then replace it with correctly spelled word."
      ],
      "metadata": {
        "id": "bLIgLlnERqrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This creates a list of sets of misspelled words found in each row.\n",
        "from spellchecker import SpellChecker\n",
        "spell=SpellChecker()\n",
        "mis_list=[]\n",
        "for i in range(len(df_review)):\n",
        "  sentence=df_review['Review'][i].split()\n",
        "  mis_sent=spell.unknown(sentence)\n",
        "  mis_list.append(mis_sent)\n",
        "  if set() in mis_list:\n",
        "    mis_list.remove(set())\n",
        "print(\"first 50 row's Misspelled words but they are in [{misspelled words list from row 1},{misspelled words list from row 2}]: \",mis_list[0:50])"
      ],
      "metadata": {
        "id": "X4d0uyW8Smku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a list of misspelled words. (Basically extracting each set element from the mis_list and putting it into mis_mis_list)\n",
        "\n",
        "from collections import Counter\n",
        "mis_mis_list=[]\n",
        "for i in mis_list:\n",
        "  for j in i:\n",
        "    mis_mis_list.append(j.lower())   #just making the words lower before appending to mis_mis_list\n",
        "\n",
        "\n",
        "#cnt=0\n",
        "#for i in mis_mis_list:        #removing 'rs', 'mr', 'ms' from the list as they aren't misspelled words in a way.\n",
        "  # if i=='rs':\n",
        "  #   #cnt=cnt+1\n",
        "  #   mis_mis_list.remove(i)\n",
        "  # if i=='mr':\n",
        "  #   mis_mis_list.remove(i)\n",
        "  # if i=='ms':\n",
        "  #   mis_mis_list.remove(i)    \n",
        "print(\"first 50 Misspelled words:\",mis_mis_list[0:50]) #LIST OF MISSPELLED WORDS   \n",
        "print(\"Total misspelled words: \",len(mis_mis_list)) #Note: this list is not a 'unique mispelled words' list, it has repeated occurences of them.\n",
        "\n",
        "\n",
        "#Finding common words and their occurrences in the mis_mis_list #Just a trial code for common words finder.\n",
        "cnt=Counter(mis_mis_list)\n",
        "cmmn=cnt.most_common(100)   \n",
        "print(cmmn)"
      ],
      "metadata": {
        "id": "n4NvhQhPStkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#REMOVING NAMES FROM THE LIST of misspelled words\n",
        "names_list=['zomato','pm','rs','aundh','nonveg','mexicana','hr','kandivali','chocolava','nigdi',\n",
        "            'cheeseburst','bbq','saudagar','zingy','makhani','paneer','periperi','tandoor']\n",
        "for name in names_list:\n",
        "  for j in range(len(mis_mis_list)):\n",
        "    if name in mis_mis_list:\n",
        "      mis_mis_list.remove(name)\n",
        "print(\"Final Misspelled words list after removing names: (Showing only first 50) \",mis_mis_list[0:50]) #This is the list of misseplled words!\n",
        "\n",
        "\n",
        "\n",
        "#Trial code for common words finder, again.\n",
        "cnt=Counter(mis_mis_list)\n",
        "cmmn=cnt.most_common(100)   #Finding common words and their occurrences in the mis_mis_list     \n",
        "print(cmmn)    "
      ],
      "metadata": {
        "id": "qCYa6ZTOTBU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding a list of correctly spelled words!"
      ],
      "metadata": {
        "id": "m4SwihH-Uk79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#first, just creating a list of words found in the dataset\n",
        "correct_word_list=[]\n",
        "for i in range(len(df_review)):\n",
        "  sentence=df_review['Review'][i]\n",
        "  words=sentence.split()\n",
        "  for word in words:\n",
        "    correct_word_list.append(word.lower())\n",
        "print(correct_word_list[0:50])\n"
      ],
      "metadata": {
        "id": "WtbCfznzUG8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We have to make both lists mis_mis_list and correct_words_list contain unique words, not repeated words or 'remove' won't work!\n",
        "print(\"total of all words of misspelled word list:\",len(mis_mis_list))\n",
        "print(\"total of all words of correct word list+misspelled word list:\",len(correct_word_list))\n",
        "mis_mis_list=list(set(mis_mis_list))\n",
        "correct_word_list=list(set(correct_word_list))\n",
        "print(\"total of unique words of misspelled word list:\",len(mis_mis_list))\n",
        "print(\"total of unique words of correct word list+missplled word list:\",len(correct_word_list))\n",
        "print(\"total of unique words of names list:\",len(names_list))"
      ],
      "metadata": {
        "id": "UT2X90I5UgiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67c9f313-8e8d-4d82-9e71-af2377965da0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total of all words of misspelled word list: 761\n",
            "total of all words of correct word list+misspelled word list: 60164\n",
            "total of unique words of misspelled word list: 536\n",
            "total of unique words of correct word list+missplled word list: 4136\n",
            "total of unique words of names list: 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names_list=['zomato','pm','rs','aundh','nonveg','mexicana','hr','kandivali','chocolava','nigdi',\n",
        "            'cheeseburst','bbq','saudagar','zingy','makhani','paneer','periperi','tandoor']\n",
        "cnt=0\n",
        "#Removing misspelled words from correct_word_list, found in mis_mis_list\n",
        "for w in mis_mis_list:\n",
        "  if w in correct_word_list:\n",
        "    correct_word_list.remove(w)\n",
        "\n",
        "#Removing names from correct_word_list, found in names_list\n",
        "for n in names_list:\n",
        "  if n in correct_word_list:\n",
        "    correct_word_list.remove(n) \n",
        "print(\"correct word list length after removing misspelled words and names:\",len(correct_word_list))"
      ],
      "metadata": {
        "id": "sOhJ8WKlU53p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6da05f8-4c34-4c87-8621-08172c11b6b9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct word list length after removing misspelled words and names: 3582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The only misspelled words in word_list\n",
        "\n",
        "mis_words=spell.unknown(correct_word_list)\n",
        "print(mis_words)"
      ],
      "metadata": {
        "id": "mzrF3zdWVXeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dabe982-2eac-420b-ec31-347877da32e6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "set()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking similarity between words from correct_word_list and mis_mis_list, if its more than 0.8, \n",
        "#do dictionary[misspelled word]=correct word\n",
        "#TAKES 1 MINUTE+\n",
        "from difflib import SequenceMatcher       #Library used for checking similarity\n",
        "\n",
        "def similar(a, b):\n",
        "    return SequenceMatcher(None, a, b).ratio()    #Function to check similarity!\n",
        "\n",
        "dictionary={}\n",
        "cnt=0\n",
        "for cor_word in correct_word_list:\n",
        "  for mis_word in mis_mis_list:\n",
        "    ratio=similar(cor_word,mis_word)\n",
        "    if(ratio>0.8):\n",
        "      cnt=cnt+1\n",
        "      dictionary[mis_word]=cor_word\n",
        "      #print(\"Correct word:\",cor_word,\"    misspelled word:\",mis_word,\"      Ratio:\",ratio)\n",
        "print(\"This many words can be corrected: \",cnt)"
      ],
      "metadata": {
        "id": "oNO-jEncVa8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01f121e3-6597-4fb5-df38-88422f767c68"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This many words can be corrected:  355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Replacing the misspelled words with correct words\n",
        "#Takes almost 10 seconds\n",
        "words_corrected_cnt=0\n",
        "for i in range(len(df_review)):\n",
        "  sentence=(df_review['Review'][i]).lower()\n",
        "  print(\"before:\",sentence)\n",
        "  misspelled_words=spell.unknown(sentence.split())\n",
        "  print(\"list:\",misspelled_words)\n",
        "  for misword in misspelled_words:\n",
        "    if misword in dictionary:\n",
        "      correct_word=dictionary[misword]\n",
        "      print(\"misspelled word: \",misword,\"     \",\"correct word:\",correct_word)\n",
        "      sentence=sentence.replace(misword,correct_word)\n",
        "      words_corrected_cnt=words_corrected_cnt+1\n",
        "  df_review['Review'][i]=sentence\n",
        "  print(\"After:\",sentence)"
      ],
      "metadata": {
        "id": "e-Iw-GIMVgpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This many words were corrected and replaced\n",
        "print(words_corrected_cnt)"
      ],
      "metadata": {
        "id": "SG2fvjDRVlXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fda31e3-7aab-4d43-ba66-19e22ae8cfce"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Removing stopwords"
      ],
      "metadata": {
        "id": "eygltVo3VpmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_review['Review'].head())"
      ],
      "metadata": {
        "id": "cM7O6m5lVnxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "225c5148-3938-41b0-a018-6e31cfe8f437"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                                                                                                                                                                                                                                                         its too good\n",
            "1                                                                                                                                                                                                                                                       waste of money\n",
            "2                                                                                                                                                                                                                                        pizza was yum but little late\n",
            "3                                                                                                                                                                                                                                          delivery person was amazing\n",
            "4    even after calling personally and even after giving special instructions received very cold pizza base is hard and it tastes stale as if it was premade thought chicken parcels were really hot and fresh with proper quantity but really disappointed with pizza\n",
            "Name: Review, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "sw=stopwords.words(\"english\")\n",
        "print(sw)\n",
        "#Removing the words below from the stopword list as they do impact the outcome when doing sentiment analysis. \n",
        "sw.append('would')\n",
        "words=['no','not']\n",
        "sw.remove('not')\n",
        "sw.remove('no')\n",
        "#sw.remove('never')\n",
        "sw.remove('don\\'t')\n",
        "sw.remove('didn\\'t')\n",
        "sw.remove('wouldn\\'t')\n",
        "sw.remove('wouldn')\n",
        "sw.remove('won\\'t')\n",
        "sw.remove('didn')\n",
        "sw.remove('don')\n",
        "sw.remove('isn\\'t')\n",
        "sw.remove('isn')\n",
        "#sw.remove('can\\'t')\n",
        "sw.remove('couldn\\'t')\n",
        "print(sw)"
      ],
      "metadata": {
        "id": "uFD12T0lXASW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa675787-80b6-429a-ae1d-aa6ee888e329"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', 'would']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making 'Review' lower so I can remove stopwords"
      ],
      "metadata": {
        "id": "qWgKBsezXGUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_review['Review']=df_review['Review'].str.lower()"
      ],
      "metadata": {
        "id": "TpGr6WeBXCoG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_review['Review']=df_review['Review'].apply(lambda x:\" \".join(x for x in str(x).split() if x not in sw))\n",
        "print(df_review.head())"
      ],
      "metadata": {
        "id": "e7uy-jvBXJQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e987066e-9e74-49ba-d6b4-ef30cf01682a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                                                                                                                           Review  \\\n",
            "0                                                                                                                                                                                            good   \n",
            "1                                                                                                                                                                                     waste money   \n",
            "2                                                                                                                                                                           pizza yum little late   \n",
            "3                                                                                                                                                                         delivery person amazing   \n",
            "4  even calling personally even giving special instructions received cold pizza base hard tastes stale premade thought chicken parcels really hot fresh proper quantity really disappointed pizza   \n",
            "\n",
            "   Sentiment  \n",
            "0          1  \n",
            "1          0  \n",
            "2          1  \n",
            "3          1  \n",
            "4          0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TOTAL WORDS AFTER REMOVING STOP WORDS!\n",
        "p_list=[]\n",
        "for i in range(len(df_review)):\n",
        "  ent=df_review['Review'][i].split()\n",
        "  p_list.append(ent)\n",
        "\n",
        "word_list=[]\n",
        "for element in p_list:\n",
        "  for word in element:\n",
        "    word_list.append(word)\n",
        "print(len(word_list))"
      ],
      "metadata": {
        "id": "Iu-eLxKfXZHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c60d4ee8-47ae-43aa-d91b-e47ea280f47b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Tokenization"
      ],
      "metadata": {
        "id": "MNy-z34PXjNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization done to apply Lemmatization\n",
        "w_tokenizer=nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer=nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "  return [lemmatizer.lemmatize(w,'v') for w in w_tokenizer.tokenize(text)]\n",
        "\n",
        "df_review['Review']=df_review.Review.apply(lemmatize_text)\n",
        "print(df_review.head())"
      ],
      "metadata": {
        "id": "n4tNqBH8XcZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed7db6f3-c0de-44cd-d31e-03e59d75ec14"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                                                                                                                                          Review  \\\n",
            "0                                                                                                                                                                                                         [good]   \n",
            "1                                                                                                                                                                                                 [waste, money]   \n",
            "2                                                                                                                                                                                     [pizza, yum, little, late]   \n",
            "3                                                                                                                                                                                      [delivery, person, amaze]   \n",
            "4  [even, call, personally, even, give, special, instructions, receive, cold, pizza, base, hard, taste, stale, premade, think, chicken, parcel, really, hot, fresh, proper, quantity, really, disappoint, pizza]   \n",
            "\n",
            "   Sentiment  \n",
            "0          1  \n",
            "1          0  \n",
            "2          1  \n",
            "3          1  \n",
            "4          0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From tokenized to normal"
      ],
      "metadata": {
        "id": "28tjU7BDYRg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_review['NewReview'] = df_review['Review'].apply(lambda s1: ' '.join(map(str,s1)) )\n",
        "\n",
        "print(df_review['NewReview'].head())"
      ],
      "metadata": {
        "id": "IYM2s2Z-YTA2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55559c15-eed3-4cd8-b5ff-60bbdc37418e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                                                                                                                                                                                  good\n",
            "1                                                                                                                                                                           waste money\n",
            "2                                                                                                                                                                 pizza yum little late\n",
            "3                                                                                                                                                                 delivery person amaze\n",
            "4    even call personally even give special instructions receive cold pizza base hard taste stale premade think chicken parcel really hot fresh proper quantity really disappoint pizza\n",
            "Name: NewReview, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_review['NewReview']=df_review['NewReview'].str.lower()\n",
        "df_review.head()"
      ],
      "metadata": {
        "id": "ua6hTyd6YUm_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "b5dfdaa2-4a33-4e17-f46e-b713e4af95c8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                          Review  \\\n",
              "0                                                                                                                                                                                                         [good]   \n",
              "1                                                                                                                                                                                                 [waste, money]   \n",
              "2                                                                                                                                                                                     [pizza, yum, little, late]   \n",
              "3                                                                                                                                                                                      [delivery, person, amaze]   \n",
              "4  [even, call, personally, even, give, special, instructions, receive, cold, pizza, base, hard, taste, stale, premade, think, chicken, parcel, really, hot, fresh, proper, quantity, really, disappoint, pizza]   \n",
              "\n",
              "   Sentiment  \\\n",
              "0          1   \n",
              "1          0   \n",
              "2          1   \n",
              "3          1   \n",
              "4          0   \n",
              "\n",
              "                                                                                                                                                                            NewReview  \n",
              "0                                                                                                                                                                                good  \n",
              "1                                                                                                                                                                         waste money  \n",
              "2                                                                                                                                                               pizza yum little late  \n",
              "3                                                                                                                                                               delivery person amaze  \n",
              "4  even call personally even give special instructions receive cold pizza base hard taste stale premade think chicken parcel really hot fresh proper quantity really disappoint pizza  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c97f6fe-3f76-4769-9f48-b7b1f6f1fde9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>NewReview</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[good]</td>\n",
              "      <td>1</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[waste, money]</td>\n",
              "      <td>0</td>\n",
              "      <td>waste money</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[pizza, yum, little, late]</td>\n",
              "      <td>1</td>\n",
              "      <td>pizza yum little late</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[delivery, person, amaze]</td>\n",
              "      <td>1</td>\n",
              "      <td>delivery person amaze</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[even, call, personally, even, give, special, instructions, receive, cold, pizza, base, hard, taste, stale, premade, think, chicken, parcel, really, hot, fresh, proper, quantity, really, disappoint, pizza]</td>\n",
              "      <td>0</td>\n",
              "      <td>even call personally even give special instructions receive cold pizza base hard taste stale premade think chicken parcel really hot fresh proper quantity really disappoint pizza</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c97f6fe-3f76-4769-9f48-b7b1f6f1fde9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c97f6fe-3f76-4769-9f48-b7b1f6f1fde9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c97f6fe-3f76-4769-9f48-b7b1f6f1fde9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis"
      ],
      "metadata": {
        "id": "AjEb6gVkYaUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The number of samples in the dataset!\")\n",
        "pos_percent=(len(df_review[df_review['Sentiment']==1])/len(df_review)*100)\n",
        "print(\"Positive reviews percentage: \",round(pos_percent,2),\"%\")\n",
        "neg_percent=(len(df_review[df_review['Sentiment']==0])/len(df_review)*100)\n",
        "print(\"Negative reviews percentage: \",round(neg_percent,2),\"%\")\n",
        "print(\"Positive reviews: \",len(df_review[df_review['Sentiment']==1]))\n",
        "print(\"Negative reviews: \",len(df_review[df_review['Sentiment']==0]))"
      ],
      "metadata": {
        "id": "xaCXykiVYYP3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f36f3f7-e014-4a26-cba2-5bb29a6fe371"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of samples in the dataset!\n",
            "Positive reviews percentage:  56.19 %\n",
            "Negative reviews percentage:  43.81 %\n",
            "Positive reviews:  1543\n",
            "Negative reviews:  1203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-test split starts here!"
      ],
      "metadata": {
        "id": "co78Y2FEYiGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "LCgTBYiCYfD2"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,test_data=train_test_split(df_review,test_size=0.2,random_state=50)  #keep random_state=50 for higher precision and recall of 0 class when using SVM\n",
        "#train_data,test_data=train_test_split(new_df_review,test_size=0.4,random_state=25)"
      ],
      "metadata": {
        "id": "QkA_JWcGYlqe"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_review.shape)\n",
        "print('test_data(Positive):',test_data[test_data['Sentiment']==1].count())\n",
        "print('test_data(Negative):',test_data[test_data['Sentiment']==0].count())\n",
        "\n",
        "print(\"train_data (Positive):\",train_data[train_data['Sentiment']==1].count())\n",
        "print('train_data (Negative):',train_data[train_data['Sentiment']==0].count())"
      ],
      "metadata": {
        "id": "VcdzoecJYnGn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb060cb-392e-42db-d1c6-e37d126253b5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2746, 3)\n",
            "test_data(Positive): Review       311\n",
            "Sentiment    311\n",
            "NewReview    311\n",
            "dtype: int64\n",
            "test_data(Negative): Review       239\n",
            "Sentiment    239\n",
            "NewReview    239\n",
            "dtype: int64\n",
            "train_data (Positive): Review       1232\n",
            "Sentiment    1232\n",
            "NewReview    1232\n",
            "dtype: int64\n",
            "train_data (Negative): Review       964\n",
            "Sentiment    964\n",
            "NewReview    964\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=train_data['NewReview']\n",
        "y_train=train_data['Sentiment']\n",
        "X_test=test_data['NewReview']\n",
        "y_test=test_data['Sentiment']"
      ],
      "metadata": {
        "id": "A_QxMQcMYog_"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if any null values\n",
        "train_data[train_data.isna().any(axis=1)]"
      ],
      "metadata": {
        "id": "5oBaFa9tOP7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "09ef7887-8981-4e92-e70a-3fe3aa66e3f8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Review, Sentiment, NewReview]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6ff1950-2b64-48a4-8436-858f60ac82c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>NewReview</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6ff1950-2b64-48a4-8436-858f60ac82c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6ff1950-2b64-48a4-8436-858f60ac82c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6ff1950-2b64-48a4-8436-858f60ac82c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.head())\n",
        "print(X_test.head())"
      ],
      "metadata": {
        "id": "Mlp9TfO4YsZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b2fc985-4a5c-4174-8f24-ed8ccceb0371"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17                                                                                                                                                                                                                      delivery charge high even zomato pro members around rs dominos outlet literally next door house\n",
            "1263                                                                                                                                              domino domino outlet locate thakur college thakur village domino time favourite ambience outdoor indoor staff friendly pizza tasty yummy think one best outlet domino\n",
            "473     dominos best place crave pizza like domino pizza hut cheese burst die soo freak cheesy new addition menu burger pizza look like burger taste like pizza try burger pizza today superb soo cheesy hot soft lot veggies chicken piece new favourite guy wait goo hog youll definitely love cant miss piece heaven\n",
            "2496                                                                                                                                                                                                                                                                                                      late delivery\n",
            "1555                                                                                                                                                                                                                                                                                                               love\n",
            "Name: NewReview, dtype: object\n",
            "1150             delivery domino always issue even complaint last order\n",
            "664                                                       great service\n",
            "2144    fall apart one side no toppings taste par quality seriously bad\n",
            "1847                              dominos always amaze whichever branch\n",
            "2211                                                non attentive staff\n",
            "Name: NewReview, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Vectorizer"
      ],
      "metadata": {
        "id": "DV3K_aOJZFEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "4xx8izAfY-iy"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_vectorizer=TfidfVectorizer(use_idf=True,lowercase=True,strip_accents='ascii')\n",
        "train_review_tfidf=train_vectorizer.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "D0o_3FtZZHOf"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_review_tfidf.shape)\n",
        "type(train_review_tfidf)"
      ],
      "metadata": {
        "id": "G6MWSlTKZI3H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "574b27e3-70e1-43d7-ddb3-5bebe9b685be"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2196, 2787)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_review['Sentiment'].unique()\n",
        "df_review[df_review['Sentiment']=='.']"
      ],
      "metadata": {
        "id": "MvQmWIvOZurl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "40f80ccb-7de1-4fdf-b0d8-5dc3cee18d8c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Review, Sentiment, NewReview]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ba92efc-838f-46e1-b1b5-45cc7917ae16\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>NewReview</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ba92efc-838f-46e1-b1b5-45cc7917ae16')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ba92efc-838f-46e1-b1b5-45cc7917ae16 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ba92efc-838f-46e1-b1b5-45cc7917ae16');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. LOGISTIC REGRESSION"
      ],
      "metadata": {
        "id": "RTKFTzf5ZPsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_model=LogisticRegression().fit(train_review_tfidf, y_train)"
      ],
      "metadata": {
        "id": "eZAKVsjnZK_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_val_score(log_model,train_review_tfidf,y_train,scoring='accuracy',cv=5).mean()"
      ],
      "metadata": {
        "id": "bQDGZw4FZSCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#USE THIS WHEN TESTING ON SPLIT TEST DATA\n",
        "nr=train_vectorizer.transform(X_test)\n",
        "log_model.predict(nr)"
      ],
      "metadata": {
        "id": "8cSDUR5DZVRR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78692651-f621-435c-cfff-8758c59dccb2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
              "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted=log_model.predict(nr)\n",
        "p=pd.DataFrame(predicted)\n",
        "actual=y_test"
      ],
      "metadata": {
        "id": "sdsqJHRdZeMM"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "cf_matrix=sm.confusion_matrix(actual,p)\n",
        "sns.heatmap(cf_matrix,annot=True,fmt='g')"
      ],
      "metadata": {
        "id": "iBs_jkMPZgZ2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "f0f93403-34df-4c89-d245-7d1689d6c752"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fba5151fb50>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(actual,predicted))"
      ],
      "metadata": {
        "id": "Al0YcOquZh2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeea3a5e-365d-4fcb-c1e5-c2043c4d0b50"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.91      0.92       239\n",
            "           1       0.93      0.95      0.94       311\n",
            "\n",
            "    accuracy                           0.93       550\n",
            "   macro avg       0.93      0.93      0.93       550\n",
            "weighted avg       0.93      0.93      0.93       550\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. SVM"
      ],
      "metadata": {
        "id": "ZpIF9yd7axde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "svclassifier=SVC(kernel='rbf',C=10,gamma=1)\n",
        "svclassifier.fit(train_review_tfidf,y_train)"
      ],
      "metadata": {
        "id": "Xa7jahlzayAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5cbb9d1-1f23-452f-f125-661c82c4da19"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10, gamma=1)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nr=train_vectorizer.transform(X_test)\n",
        "svclassifier.predict(nr)"
      ],
      "metadata": {
        "id": "hfK2H1MYazT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94ab4afa-12f5-4837-b76c-4cb20b2c0fc2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "       0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted=svclassifier.predict(nr)\n",
        "p=pd.DataFrame(predicted)\n",
        "actual=y_test"
      ],
      "metadata": {
        "id": "ldOC406pa0lv"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix=sm.confusion_matrix(actual,p)\n",
        "sns.heatmap(cf_matrix,annot=True,fmt='g')"
      ],
      "metadata": {
        "id": "RsUFBh7Fa2EN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "8300378d-8fce-4fd1-e024-e14b4f36ed97"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fba4dfe20d0>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(actual,predicted))"
      ],
      "metadata": {
        "id": "XSlpUoE0a3et",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f968f0-4bed-4edc-ed10-410c0e867993"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93       239\n",
            "           1       0.95      0.95      0.95       311\n",
            "\n",
            "    accuracy                           0.94       550\n",
            "   macro avg       0.94      0.94      0.94       550\n",
            "weighted avg       0.94      0.94      0.94       550\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LDA"
      ],
      "metadata": {
        "id": "6VsJcE6FSYDf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#kmeans trial"
      ],
      "metadata": {
        "id": "OAlgNJFaNc7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.cluster import KMeans\n",
        "# def cluster_texts(num_clusters,tfidf):\n",
        "#   print('Beginning KMeans Clustering, number of clusters=',num_clusters,'\\n')\n",
        "#   km=KMeans(n_clusters=num_clusters,max_iter=100,verbose=2,n_init=1).fit(tfidf)\n",
        "#   return km"
      ],
      "metadata": {
        "id": "6jBjTyLcNf7Y"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nr_vectorized_neg_reviews=train_vectorizer.transform(df_review[df_review['Sentiment']==0].NewReview)"
      ],
      "metadata": {
        "id": "2g994jhRNtNG"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# n=25\n",
        "# kmeans12=cluster_texts(n,nr_vectorized_neg_reviews)"
      ],
      "metadata": {
        "id": "dKZTOhTgNglv"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kmeans_df=pd.DataFrame()\n",
        "# kmeans_df['assigned_labels']=kmeans12.labels_\n",
        "# kmeans_df['reviews']=df_review[df_review['Sentiment']==0].NewReview"
      ],
      "metadata": {
        "id": "SS5scfpbN7mT"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kmeans_df['assigned_labels'].value_counts()"
      ],
      "metadata": {
        "id": "6debuXO7OMXV"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(6):\n",
        "#   print(\"Cluster \",i,\":\")\n",
        "#   df_clustered=kmeans_df[kmeans_df['assigned_labels']==i]\n",
        "#   print(df_clustered['reviews'])\n",
        "#   print(\"\\n\\n\")\n",
        "  "
      ],
      "metadata": {
        "id": "XYiTMxQWOZnl"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#kmeans trial end"
      ],
      "metadata": {
        "id": "ND2AOBOkNekn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19/04/22"
      ],
      "metadata": {
        "id": "hsU4kv1jqTbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTy8TMNvpQ6r",
        "outputId": "04fa042d-b698-4a00-82ce-e20ad137fab0"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "sw=stopwords.words('english')\n",
        "print(sw)\n",
        "sw.append('didnt')\n",
        "sw.append('hadnt')\n",
        "sw.append('wont')\n",
        "sw.append('couldnt')\n",
        "sw.append('dont')\n",
        "sw.append('good')\n",
        "sw.append('havent')\n",
        "#trial=pd.DataFrame()\n",
        "df_review['NewReview']=df_review['NewReview'].apply(lambda x:\" \".join(x for x in str(x).split() if x not in sw))\n",
        "# trial['Review']=df_review['Review'].apply(lambda x:' '.join(x for x in str(x).split() if x not in sw))\n",
        "# trial['Sentiment']=df_review['Sentiment']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP93vgRFoP5c",
        "outputId": "06710e08-d9b9-457e-9728-f5f95b655841"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize, pos_tag\n",
        "\n",
        "def nouns(text):\n",
        "  '''extract nouns only from given string'''\n",
        "  #is_noun=lambda pos:pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
        "  is_noun=lambda pos:pos[:2] == 'JJ' or pos[:2] == 'JJR' or pos[:2] == 'RBR' \n",
        "  tokenized=word_tokenize(text)\n",
        "  all_nouns=[word for (word,pos) in pos_tag(tokenized) if is_noun(pos)]\n",
        "  return ' '.join(all_nouns)"
      ],
      "metadata": {
        "id": "N-NXmEuGpWuS"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_nouns=pd.DataFrame(df_review[df_review['Sentiment']==0].NewReview) #.apply(nouns))"
      ],
      "metadata": {
        "id": "CvoTsdYspWuX"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_nouns=data_nouns.reset_index()"
      ],
      "metadata": {
        "id": "oQyViJoMD8rW"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count = CountVectorizer(stop_words='english', max_df=.1, max_features=2000)\n",
        "X = count.fit_transform(data_nouns.NewReview) #feature matrix"
      ],
      "metadata": {
        "id": "lJSGsLk2oXbS"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# vectorizer = CountVectorizer(analyzer='word',       \n",
        "#                              min_df=10,                        # minimum reqd occurences of a word \n",
        "#                              stop_words='english',             # remove stop words\n",
        "#                              lowercase=True,                   # convert all words to lowercase\n",
        "#                              token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
        "#                              # max_features=50000,             # max number of uniq words\n",
        "#                             )\n",
        "#vectorizer=CountVectorizer()\n",
        "num_components=10\n",
        "\n",
        "lda=LatentDirichletAllocation(n_components=num_components,max_iter=100)\n",
        "\n",
        "#nr_vectorized_neg_reviews=train_vectorizer.transform(df_review[df_review['Sentiment']==0].NewReview)\n",
        "nr_vectorized_neg_reviews=train_vectorizer.transform(data_nouns.NewReview)\n",
        "\n",
        "lda_matrix=lda.fit_transform(nr_vectorized_neg_reviews)\n",
        "\n",
        "lda_model_components=lda.components_"
      ],
      "metadata": {
        "id": "tTMRvy6ZSab_"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lda_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aidPfgj4JBT7",
        "outputId": "8cdb5f3a-8764-4741-f06b-3f997c9045b7"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1203, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the topics with their terms\n",
        "terms=train_vectorizer.get_feature_names()\n",
        "\n",
        "for index, component in enumerate(lda_model_components):\n",
        "  zipped=zip(terms,component)\n",
        "  top_terms_key=sorted(zipped, key=lambda t:t[1], reverse=True)[:10]\n",
        "  top_terms_list=list(dict(top_terms_key).keys())\n",
        "  print(\"Topic \"+str(index)+\": \",top_terms_list)"
      ],
      "metadata": {
        "id": "ABZsyqiZScBX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8e32348-ab26-423c-b144-e8e2361022f9"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0:  ['salty', 'satisfactory', 'prepare', 'cheeseburst', 'low', 'directly', 'pepperoni', 'thing', 'wasnt', 'properly']\n",
            "Topic 1:  ['miss', 'average', 'items', 'properly', 'seal', 'reason', 'peri', 'box', 'follow', 'hurry']\n",
            "Topic 2:  ['cheese', 'less', 'pizza', 'burst', 'bread', 'oregano', 'order', 'garlic', 'toppings', 'flake']\n",
            "Topic 3:  ['delay', 'bite', 'delivery', 'available', 'park', 'slow', 'unprofessional', 'inside', 'condition', 'rubbish']\n",
            "Topic 4:  ['late', 'delivery', 'deliver', 'order', 'cold', 'pizza', 'receive', 'time', 'food', 'hour']\n",
            "Topic 5:  ['pizza', 'order', 'cheese', 'taste', 'dominos', 'like', 'time', 'also', 'place', 'get']\n",
            "Topic 6:  ['min', 'water', 'free', 'spend', 'nothing', 'drink', 'costly', 'stale', 'money', 'overcook']\n",
            "Topic 7:  ['slow', 'clean', 'take', 'minutes', 'long', 'staff', 'short', 'estimate', 'weekend', 'return']\n",
            "Topic 8:  ['order', 'worst', 'deliver', 'call', 'receive', 'wrong', 'zomato', 'refund', 'delivery', 'cancel']\n",
            "Topic 9:  ['bad', 'pizza', 'experience', 'order', 'service', 'time', 'dominos', 'quality', 'cheese', 'worst']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "id": "JR9KjcvNJshv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_vectorizer=TfidfVectorizer(use_idf=True,lowercase=True,strip_accents='ascii')\n",
        "tfidf_=train_vectorizer.fit_transform(data_nouns.NewReview)\n",
        "tf_vectorizer = CountVectorizer()\n",
        "tf_ = tf_vectorizer.fit_transform(data_nouns.NewReview) #feature matrix\n",
        "\n",
        "num_components=10\n",
        "#for tf\n",
        "lda=LatentDirichletAllocation(n_components=num_components,max_iter=100)\n",
        "lda_tf=lda.fit(tf_)\n",
        "#for tfidf\n",
        "lda_tfidf=lda.fit(tfidf_)"
      ],
      "metadata": {
        "id": "A6X6qtWjevQf"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(len(lda_tf.columns))\n",
        "print(tf_.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIAfkUnQiSh1",
        "outputId": "4a1c2291-3b2f-4843-9133-e3cab1c8c9f8"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1203, 2133)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pyLDAvis for tf \n",
        "import pyLDAvis\n",
        "import pyLDAvis.sklearn\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "pyLDAvis.sklearn.prepare(lda_tf,tf_,tf_vectorizer)\n",
        "#pyLDAvis.save_html(lda,'topics_vis.html')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "id": "dABAJBDuIYiQ",
        "outputId": "fe0ec334-8dd3-4d85-d14d-fdb30e4873d2"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "8     -0.253726 -0.058375       1        1  67.771858\n",
              "0     -0.098499  0.118467       2        1   6.239204\n",
              "7      0.016243 -0.071329       3        1   4.240495\n",
              "9      0.080480 -0.013153       4        1   4.096185\n",
              "4      0.049325 -0.001451       5        1   4.011703\n",
              "3      0.045089 -0.035008       6        1   3.735990\n",
              "6      0.033561 -0.021041       7        1   3.622340\n",
              "1      0.053636 -0.006196       8        1   2.208904\n",
              "5      0.020512  0.089413       9        1   2.147865\n",
              "2      0.053378 -0.001325      10        1   1.925454, topic_info=          Term        Freq       Total Category  logprob  loglift\n",
              "486   delivery  164.000000  164.000000  Default  30.0000  30.0000\n",
              "1018      late  114.000000  114.000000  Default  29.0000  29.0000\n",
              "484    deliver  172.000000  172.000000  Default  28.0000  28.0000\n",
              "1291     order  315.000000  315.000000  Default  27.0000  27.0000\n",
              "1900      time  156.000000  156.000000  Default  26.0000  26.0000\n",
              "...        ...         ...         ...      ...      ...      ...\n",
              "590     enough    1.185271   18.013150  Topic10  -5.5863   1.2289\n",
              "1462  properly    1.359108   47.977011  Topic10  -5.4495   0.3861\n",
              "1599        rs    0.849915    7.354927  Topic10  -5.9189   1.7920\n",
              "1320   packets    0.785737    5.699114  Topic10  -5.9974   1.9686\n",
              "1643    season    0.830080   23.618507  Topic10  -5.9425   0.6017\n",
              "\n",
              "[527 rows x 6 columns], token_table=      Topic      Freq         Term\n",
              "term                              \n",
              "0         8  0.417722        abide\n",
              "9         3  0.207887   acceptable\n",
              "9         5  0.415774   acceptable\n",
              "11       10  0.386441  accommodate\n",
              "12        8  0.420227       accord\n",
              "...     ...       ...          ...\n",
              "2121      7  0.125676          yet\n",
              "2121      9  0.628381          yet\n",
              "2124      4  0.628649        youre\n",
              "2128      1  0.977397       zomato\n",
              "2129      7  0.336363       zomota\n",
              "\n",
              "[801 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[9, 1, 8, 10, 5, 4, 7, 2, 6, 3])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el581404381460986406078091618\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el581404381460986406078091618_data = {\"mdsDat\": {\"x\": [-0.2537255320750877, -0.09849872134793615, 0.016243479518998485, 0.08047956857789108, 0.049324826249230264, 0.04508901046247743, 0.03356121083852518, 0.05363598135819104, 0.020512375112735008, 0.05337780130497554], \"y\": [-0.05837512677570368, 0.1184666854618442, -0.07132945832106127, -0.013153404921227515, -0.001451042326099599, -0.035008441534130484, -0.021041230582510697, -0.00619568228013374, 0.08941319789307835, -0.0013254966140557357], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [67.77185821124829, 6.239204499131279, 4.240494973689782, 4.096185478978931, 4.011703183454904, 3.735990402782125, 3.622339770504437, 2.2089043552894103, 2.147865318571817, 1.925453806349015]}, \"tinfo\": {\"Term\": [\"delivery\", \"late\", \"deliver\", \"order\", \"time\", \"cheese\", \"worst\", \"service\", \"pizza\", \"bad\", \"cold\", \"receive\", \"less\", \"quality\", \"get\", \"food\", \"delay\", \"experience\", \"ever\", \"mins\", \"toppings\", \"min\", \"poor\", \"eat\", \"wrong\", \"much\", \"money\", \"staff\", \"hot\", \"top\", \"like\", \"outlet\", \"zomato\", \"call\", \"wait\", \"disappoint\", \"say\", \"veg\", \"make\", \"home\", \"oregano\", \"want\", \"dominos\", \"never\", \"horrible\", \"need\", \"please\", \"cancel\", \"miss\", \"pick\", \"one\", \"burst\", \"first\", \"even\", \"online\", \"serve\", \"non\", \"extra\", \"doesnt\", \"provide\", \"also\", \"better\", \"expect\", \"give\", \"come\", \"order\", \"place\", \"take\", \"taste\", \"cheese\", \"refund\", \"pizza\", \"go\", \"get\", \"service\", \"time\", \"pizzas\", \"experience\", \"deliver\", \"delivery\", \"worst\", \"food\", \"receive\", \"quality\", \"bad\", \"delievered\", \"km\", \"estimate\", \"ketchup\", \"commit\", \"anything\", \"min\", \"difficult\", \"daughter\", \"village\", \"dislike\", \"allthe\", \"chill\", \"fast\", \"wrongly\", \"wing\", \"constantly\", \"long\", \"crinkle\", \"bag\", \"sunday\", \"wrong\", \"se\", \"unprofessional\", \"thakur\", \"kms\", \"unease\", \"due\", \"airconditioning\", \"effective\", \"cold\", \"margherita\", \"late\", \"package\", \"deliver\", \"follow\", \"time\", \"pm\", \"free\", \"receive\", \"mins\", \"get\", \"order\", \"pizza\", \"food\", \"delivery\", \"hot\", \"plz\", \"show\", \"half\", \"bad\", \"service\", \"without\", \"taste\", \"take\", \"totally\", \"give\", \"hour\", \"tasty\", \"mood\", \"base\", \"chat\", \"happy\", \"combo\", \"honestly\", \"st\", \"brownish\", \"account\", \"reheat\", \"kindly\", \"tax\", \"fail\", \"fly\", \"messy\", \"veggies\", \"okayish\", \"rainy\", \"condiments\", \"asap\", \"fiesta\", \"onions\", \"busy\", \"freeze\", \"parathas\", \"roadside\", \"freshly\", \"audit\", \"push\", \"less\", \"fresh\", \"bad\", \"quality\", \"payment\", \"much\", \"fill\", \"cheese\", \"top\", \"toppings\", \"quantity\", \"experience\", \"food\", \"well\", \"pizza\", \"star\", \"hard\", \"chicken\", \"burst\", \"price\", \"expensive\", \"along\", \"cheez\", \"items\", \"cheeseburst\", \"mushroom\", \"rubbish\", \"maintain\", \"team\", \"standard\", \"report\", \"business\", \"irresponsible\", \"everytime\", \"point\", \"intimation\", \"form\", \"count\", \"reason\", \"attitude\", \"turn\", \"youre\", \"affordable\", \"pics\", \"burn\", \"mayo\", \"specially\", \"compromise\", \"prompt\", \"end\", \"untidy\", \"clearly\", \"stuff\", \"super\", \"rudely\", \"request\", \"ready\", \"dine\", \"upto\", \"customer\", \"best\", \"bread\", \"base\", \"arrive\", \"charge\", \"hours\", \"hate\", \"per\", \"overcook\", \"low\", \"shame\", \"health\", \"parcel\", \"whereas\", \"shittiest\", \"satisfy\", \"chocolava\", \"hair\", \"excellent\", \"wonder\", \"disgust\", \"overload\", \"rat\", \"sluggish\", \"confirmation\", \"either\", \"policy\", \"indie\", \"word\", \"fungus\", \"staple\", \"tandoori\", \"whenever\", \"duplicate\", \"advantage\", \"disastrous\", \"onwards\", \"buy\", \"acceptable\", \"worth\", \"smaller\", \"waste\", \"size\", \"money\", \"chicken\", \"cake\", \"taco\", \"pizza\", \"regular\", \"medium\", \"clean\", \"dominos\", \"find\", \"taste\", \"place\", \"water\", \"bottle\", \"coz\", \"plaza\", \"cost\", \"coke\", \"rainbow\", \"incomplete\", \"glass\", \"arrangement\", \"menu\", \"charge\", \"front\", \"cleanliness\", \"hopeless\", \"sweet\", \"nigadi\", \"deny\", \"main\", \"jalapeno\", \"chiz\", \"careless\", \"least\", \"soft\", \"exorbitantly\", \"assistance\", \"mobile\", \"bean\", \"idiot\", \"temperature\", \"high\", \"meal\", \"worst\", \"lack\", \"capsicum\", \"ever\", \"interest\", \"poor\", \"seem\", \"talk\", \"service\", \"staff\", \"experience\", \"washroom\", \"address\", \"value\", \"park\", \"look\", \"outlets\", \"pizza\", \"dominos\", \"smell\", \"dirty\", \"park\", \"costly\", \"myonies\", \"upto\", \"bust\", \"papsi\", \"local\", \"terrible\", \"sure\", \"wheres\", \"type\", \"availability\", \"acs\", \"zomota\", \"test\", \"expectations\", \"rubber\", \"previous\", \"okayokay\", \"upper\", \"multinational\", \"ther\", \"love\", \"delay\", \"probably\", \"normally\", \"hospitality\", \"dear\", \"degrade\", \"slow\", \"nothing\", \"margarita\", \"inside\", \"uncooked\", \"bite\", \"claim\", \"eat\", \"delivery\", \"half\", \"stale\", \"box\", \"base\", \"mark\", \"hot\", \"hour\", \"cook\", \"pizza\", \"bad\", \"cheese\", \"pizzas\", \"chicken\", \"item\", \"pimple\", \"saudagar\", \"step\", \"advertise\", \"toss\", \"update\", \"hand\", \"satisfactory\", \"washrooms\", \"pure\", \"door\", \"cheat\", \"haff\", \"placement\", \"successful\", \"select\", \"coca\", \"cola\", \"fanta\", \"moist\", \"pickup\", \"fond\", \"green\", \"hesitate\", \"cash\", \"resolution\", \"category\", \"abide\", \"accord\", \"bbq\", \"pepsi\", \"layer\", \"mint\", \"mark\", \"service\", \"package\", \"bad\", \"bubble\", \"mention\", \"condition\", \"nothing\", \"branch\", \"im\", \"yet\", \"present\", \"exactly\", \"dry\", \"late\", \"let\", \"dilevery\", \"chowk\", \"differ\", \"supreme\", \"spicy\", \"smelly\", \"april\", \"status\", \"appropriate\", \"wow\", \"unbelievable\", \"budget\", \"tight\", \"crave\", \"toast\", \"goodwill\", \"merely\", \"garlicbread\", \"reject\", \"landmark\", \"occur\", \"birthday\", \"babique\", \"unfortunately\", \"boys\", \"become\", \"delivery\", \"extremely\", \"receive\", \"order\", \"ago\", \"hours\", \"guess\", \"per\", \"parcel\", \"come\", \"refund\", \"minutes\", \"pizza\", \"flat\", \"saggy\", \"meatballs\", \"attend\", \"short\", \"peri\", \"freshness\", \"doubt\", \"masala\", \"accommodate\", \"seal\", \"irritate\", \"theres\", \"pro\", \"man\", \"instruction\", \"flaxe\", \"mistakly\", \"investment\", \"eve\", \"class\", \"special\", \"golden\", \"nonsense\", \"vety\", \"un\", \"dim\", \"light\", \"precautions\", \"weekend\", \"long\", \"useless\", \"connect\", \"tax\", \"salty\", \"mexicana\", \"cook\", \"build\", \"dry\", \"average\", \"gonna\", \"enough\", \"properly\", \"rs\", \"packets\", \"season\"], \"Freq\": [164.0, 114.0, 172.0, 315.0, 156.0, 180.0, 102.0, 131.0, 296.0, 110.0, 83.0, 106.0, 68.0, 80.0, 123.0, 96.0, 37.0, 89.0, 43.0, 53.0, 49.0, 33.0, 48.0, 43.0, 32.0, 42.0, 49.0, 60.0, 50.0, 36.0, 78.7751203573396, 70.8731848771899, 67.17057196867702, 83.24267670565295, 60.22680382442354, 77.71094429347622, 55.75188492659836, 53.119057440317974, 45.18822990903687, 42.893745453472626, 41.16838959041941, 40.53532549366486, 161.9797819682164, 51.31553169964729, 39.11171244483869, 38.725335895715524, 37.968066006695885, 35.91048108723241, 35.403291343798244, 33.408928039897084, 69.14524777029342, 83.44942092373783, 32.01014410179371, 72.42384066243034, 30.90889414706397, 29.98407689499096, 29.396157028864156, 29.295336602271053, 29.224855400817667, 38.90855391353925, 77.08225843562862, 41.865763327066716, 43.95830937248893, 77.08051626622841, 42.9747082578399, 278.06438475177043, 82.05521006182776, 76.05505825954171, 101.3756780421735, 159.70850902244663, 55.47454758415698, 249.9503622828226, 44.71112489251134, 103.30968678841997, 107.80498763103577, 124.55848289960201, 58.065465124519164, 74.12142078518424, 123.20761129295681, 115.97969587394772, 79.49267651127643, 75.86410902201919, 80.65449879827631, 65.92841047043653, 75.63367940313715, 4.010926656202045, 3.6568859746160776, 3.1389824376047866, 7.76663028535536, 2.4777754819170843, 2.7022934738005393, 17.72118932049293, 1.7887190662285952, 1.7206643316953825, 1.694125689360573, 1.642292787734736, 1.5516031055317008, 1.4943527219619566, 2.13069376074058, 1.3643439086332492, 1.7322505310830114, 1.3429674040798438, 4.117231825292468, 1.287926994665164, 2.263352284631638, 1.2522699378075393, 13.88960646132959, 1.4037225622024019, 2.3424031610404072, 1.6035854878972706, 1.1719445255314973, 1.1695506741153376, 3.1912450903019827, 1.1577036068165043, 1.1577036068165043, 31.38479318720817, 1.5041160937687266, 38.009932601358656, 2.0169889240548433, 48.27526224596531, 1.95580946142669, 30.912789383357403, 7.179702277791265, 5.476261345223502, 21.22395598894786, 12.086549133814675, 16.89454996754972, 30.262220297234464, 27.910179235862824, 13.472921188823724, 18.603929546992045, 7.665776853795312, 2.591456559844215, 3.788077947507038, 4.313318604947888, 5.607722453430014, 5.885212516196958, 3.6944010266447456, 5.036944712136046, 4.5618852315789695, 3.4961939771054524, 3.7808226611116065, 3.4820555035658614, 7.751911015488795, 2.6982358964155875, 11.292411977346246, 2.7720617094283893, 3.4514087475077595, 1.7181039254494752, 1.4606317812060858, 1.6212260265980032, 1.40328208831124, 1.3868911516977238, 1.293896599840822, 1.2767110595475994, 1.847636687031985, 1.39232928227235, 1.2019448347591852, 1.6843794676442692, 1.615570065543428, 1.1963636697015325, 1.193980949194551, 1.0817556189738886, 1.4510784979758695, 1.0702682869383202, 1.0702682869383202, 1.3131215480040377, 1.0297998422170973, 1.0297998422170973, 1.280064884059994, 0.9945052441515426, 0.9565178253963964, 0.9565178253963964, 20.08048004291746, 5.881797223378429, 21.634202558599185, 13.207453492623229, 1.562918410628404, 6.7233182719459945, 2.313048252302879, 16.313145606728167, 5.569736424323542, 6.754369177246206, 2.795088590579922, 7.594834330696507, 6.387535185391657, 3.4733565087684397, 6.71119737659181, 2.3746492059716293, 1.6043319526482003, 2.5029104326751845, 2.306141144536773, 1.600785887717002, 7.030549065612184, 5.77694281131015, 3.6152222133365797, 3.413132746497992, 3.2357589912896194, 2.632189348159616, 2.6191894723513207, 2.8895440110033763, 2.433088071860351, 2.817145356570314, 1.9928248889012028, 2.113245040300997, 1.9547010631759545, 2.5346402184486414, 2.197369724400788, 1.8112134788937209, 1.6863380323446937, 1.6482836343702305, 3.308294707047158, 2.9490788354014184, 1.5237922717419328, 1.5030413870329222, 1.491186475379865, 1.47269402775235, 3.748816800635441, 1.4454368724173654, 1.432298942414921, 1.7166164829478519, 1.393783897889521, 2.6201228584306175, 1.7941340799673968, 2.023731021906348, 5.713744549530954, 1.911321646248098, 2.0456632144701716, 1.9962063239015413, 1.7446641265267362, 1.8525941937790122, 2.2224154343639384, 3.4060015977989995, 2.5050606458007096, 3.3738897490761564, 2.538884802866035, 2.2986023772112403, 1.9924923956368528, 1.972930842857819, 5.182132688659648, 4.868218646739589, 2.6078814123686147, 3.4727176520708687, 2.49592152359529, 2.0919959523114993, 4.789400448549524, 1.8364489704106426, 1.8197687654106143, 3.5218184686223677, 2.360680450283903, 1.686628407045593, 1.9419992834316195, 1.5871515279308577, 2.034480007019514, 1.4986721589741132, 2.7523689491160273, 1.4236573419050642, 1.7051889293855735, 2.20308397825674, 1.895156034209006, 1.539465686870381, 1.577110009566067, 1.2122866649748598, 1.2122866649748598, 1.1448142577751292, 1.141534020463984, 1.1281985332001738, 1.095823977740833, 1.0847175844358383, 1.39894485275673, 1.7581034148907448, 1.7046737355303991, 4.687401481715026, 1.8567265510495783, 5.070016791572292, 3.8964635947991346, 5.411114367720831, 4.176742560167984, 2.389897775540389, 2.532700166500775, 4.689852234501121, 2.213123731512802, 1.9811567849404579, 2.0008902968838327, 2.1833845143495547, 1.873308225899212, 1.990175757052789, 1.8408511118243378, 7.35211788805451, 3.8613378972916546, 3.1774625308604016, 2.529992926544676, 3.0395051855528434, 4.868977129547973, 1.8697894820990486, 2.6456968664546694, 1.72038064911041, 1.6869707695699285, 2.7222640690822306, 3.9814478492072305, 1.7087777803564035, 1.949398121728157, 1.3769204803131727, 1.267711380143992, 1.2394669759701222, 2.0675999718517524, 1.2227398724601959, 1.2083367911397846, 1.2052842449063361, 1.162192241639415, 2.1967786918194347, 1.3267633912736028, 1.1334546521979323, 1.0891809989945935, 1.2298708730542354, 1.0856350979142821, 1.0642277591919378, 1.0645154025246222, 3.5692137257986647, 1.4941228634555996, 19.126094550743368, 2.123396742430508, 1.596519484533548, 7.185691137087958, 1.4031706735919642, 6.037425196435197, 2.0267837374377353, 2.343138687638256, 6.509278267944359, 4.44022544958118, 4.554898592220424, 1.7619439924224727, 2.1461341118053068, 1.642107119661929, 1.6846262546134199, 2.022277222537981, 1.9051115531845852, 2.5355421980883865, 2.191868630989951, 3.4986865388477044, 2.472880560492107, 3.63273086291521, 2.612364613780645, 1.867729092547038, 4.151330682822532, 2.514974464830339, 1.5714191001223763, 1.5642505692978832, 1.5214759576539427, 1.7645650059718527, 1.4429922834842597, 1.8342450721788925, 1.6244311208201105, 1.374826116906053, 1.264702470037462, 2.5170556143716745, 1.2375944807841437, 1.2345570881367078, 1.3162968058037796, 1.209914317780179, 1.2826218934231186, 1.19590600637814, 1.19590600637814, 2.8229882344559982, 15.132600853829997, 1.1263334930472988, 1.6027769115441468, 1.0907982196627268, 1.0671792991981595, 1.3136492527684955, 7.205546179070492, 2.3640109515477326, 4.087149983054899, 2.926609013470457, 2.1088197913468796, 4.732588375129343, 2.6238416853324713, 5.510191914748077, 8.4286948621147, 3.876954681648287, 2.7009051277420384, 2.880463566696538, 2.905608652287181, 3.260727902827618, 3.335415242182578, 2.8827481860594433, 2.3483465874935927, 3.630311695457489, 3.0290135905721236, 3.1770448348824467, 2.3611603833893096, 2.152362830247015, 3.0174714315032545, 1.626141569279201, 1.626141569279201, 1.2843260977201083, 1.2786184773424827, 1.1883410025359964, 2.262074772986798, 2.153932352760944, 1.8182834671733632, 1.00490586193045, 0.9733731782927231, 1.19922387113177, 1.2285968441615573, 0.8294607845217071, 0.8136352563589496, 0.8136352563589496, 0.7509473703438848, 0.7436108487464083, 0.7436108487464083, 0.7436108487464083, 0.7239174794450908, 1.0397370229556924, 0.966120880792595, 1.2889751068101172, 0.6830707848358339, 0.7563217146519609, 0.665815789201967, 0.6613870501630722, 0.6529348409815655, 0.6387142137145017, 0.8937417356697099, 0.9726221195217745, 0.9988305431416676, 0.8225060658145144, 3.44980527011052, 8.020263922281183, 1.0936929097074535, 2.9360296378324064, 0.8360888948485121, 0.9608370587699623, 1.1735711870930887, 0.9459880153858639, 0.8817026623052989, 0.8623489765109456, 5.226478864713532, 1.3830430382127923, 1.3375757297449955, 3.874134028004058, 40.07005278484169, 1.1036494907455168, 1.0289262059382427, 0.8036950328870751, 0.94027312482877, 0.7639362486088954, 1.4049614191208049, 0.7409902197251742, 0.6941235829941821, 0.9974744958949596, 0.6624758397152941, 0.6573167298146232, 0.7712595235854234, 0.6288732825075263, 0.6288732825075263, 0.8047489805153641, 0.6222892422453626, 0.6194533709324903, 0.6194533709324903, 0.6079163108129862, 0.6079163108129862, 0.5966397055138635, 0.5957943233568369, 0.5618712554615898, 0.5495600657156473, 0.5418517329264468, 0.8253786591021581, 1.4246019239395036, 20.38995011669491, 1.948789999186025, 3.332356986121103, 3.61322088806668, 0.6451583486531217, 1.1186145351390522, 0.6876018108169789, 0.7778829551578343, 0.7908551363581173, 0.980103753284022, 0.9405592266458932, 0.8656026580645809, 0.8445660904462297, 1.2870797194958634, 1.2028467920629742, 1.091059996245179, 1.0870642915172015, 1.1705280269439169, 1.6626581589205724, 0.8713402435349119, 1.03164450632783, 0.8554195393181409, 0.8390316687776144, 1.3933353694850805, 1.0183174100725838, 1.36912475254137, 0.7291447782261594, 0.9019991286328058, 0.6792713888947349, 0.6598415100388736, 0.6553549824875898, 0.6503115398471354, 0.6402934001241739, 0.6394968521901054, 0.9821345399298654, 0.630165101828242, 0.7242965330562493, 0.5991701442197085, 0.5988131274585627, 0.5776192879325872, 0.5776192879325872, 0.5776192879325872, 1.207895289508901, 2.237694336716158, 0.7660143577069848, 0.7815279392639292, 0.9083609158333551, 1.1869027901714928, 1.1465599952455763, 1.847160334907224, 0.7674584426866775, 1.1039655349832813, 1.2160421508497257, 0.9240088799941839, 1.1852711439104002, 1.3591081135596925, 0.8499148836237577, 0.7857372403209828, 0.8300798377420193], \"Total\": [164.0, 114.0, 172.0, 315.0, 156.0, 180.0, 102.0, 131.0, 296.0, 110.0, 83.0, 106.0, 68.0, 80.0, 123.0, 96.0, 37.0, 89.0, 43.0, 53.0, 49.0, 33.0, 48.0, 43.0, 32.0, 42.0, 49.0, 60.0, 50.0, 36.0, 80.15391058447062, 72.25198029180818, 68.54941217883639, 85.05761460523614, 61.60554853265672, 79.50557029533384, 57.130643027579794, 54.49783696008864, 46.56709022362004, 44.27250134846557, 42.54708030356321, 41.91408103851151, 167.60673252861997, 53.105533659670776, 40.49047988363536, 40.10408857783147, 39.34682337229495, 37.28922422177323, 36.782090238304235, 34.78766936000722, 72.0229226278692, 86.95942247864154, 33.38891523329188, 75.64783334706108, 32.28767022262434, 31.36286386817175, 30.77492326255727, 30.674065280239237, 30.603601163596824, 40.75279577321022, 81.07451150458847, 43.956967306302, 46.2435697780497, 82.04371182192251, 45.22900044649819, 315.3688369873434, 88.58989002889639, 82.03431594114669, 111.33143094810113, 180.48559212751792, 59.13491454738424, 296.89514001087116, 47.15593419151542, 123.13395339162713, 131.5898170097106, 156.65363113307075, 64.67317389768668, 89.46909814089246, 172.66538433119138, 164.54830749945754, 102.70521655096128, 96.7320970677265, 106.2885308648179, 80.55253444680267, 110.93542159333116, 5.673829111551034, 5.32001051699985, 4.802050097889914, 11.883929600750653, 4.140614946288275, 4.925234071118784, 33.1408961481614, 3.4520941759832495, 3.3836138594448055, 3.3573303714465266, 3.305121170107925, 3.2145528586791565, 3.157181098326369, 4.574639407045159, 3.027172284874683, 3.84890022022144, 3.0057957816340504, 9.259198096884736, 2.9508365953544033, 5.21345221157146, 2.917141839262106, 32.64402340874486, 3.3148106592175535, 5.553313856048903, 3.8551058335980946, 2.8353576791578754, 2.832379052869504, 7.729975706390818, 2.8205319864152343, 2.8205319864152343, 83.00873305487579, 3.6955100680894764, 114.467395166734, 5.094153637851775, 172.66538433119138, 4.976938418009067, 156.65363113307075, 25.490461727271793, 18.12190294094666, 106.2885308648179, 53.31776352763879, 123.13395339162713, 315.3688369873434, 296.89514001087116, 96.7320970677265, 164.54830749945754, 50.82070041050149, 8.9171161264201, 21.903301205069646, 31.996803942998977, 110.93542159333116, 131.5898170097106, 28.52515989975771, 111.33143094810113, 82.03431594114669, 26.08506439182383, 82.04371182192251, 62.73702120837145, 9.43647042107657, 4.382716280006502, 18.484745638353512, 4.962419317310448, 6.7730661241360455, 3.6530622400336483, 3.145284464489182, 3.5182712048840528, 3.0876945709419545, 3.0715869722348947, 2.9782570945771054, 2.9612290093727553, 4.32991335546366, 3.317030470861627, 2.8864995875491672, 4.050773824478507, 3.8889865201185176, 2.8807193558892306, 2.878434148353779, 2.766185205246368, 3.717220684146635, 2.7546239729718938, 2.7546239729718938, 3.444009513272499, 2.7142451245067356, 2.7142451245067356, 3.4162965890407375, 2.678860927561583, 2.6409120544000144, 2.6409120544000144, 68.05897988056643, 20.69824601674334, 110.93542159333116, 80.55253444680267, 4.854002556926292, 42.668698736004295, 8.723732372912538, 180.48559212751792, 36.02762800756822, 49.29260875638918, 12.581304280917117, 89.46909814089246, 96.7320970677265, 28.970410118450655, 296.89514001087116, 20.56223910496446, 5.594901246377971, 36.73856628730475, 86.95942247864154, 16.96434085620744, 8.708400000544525, 7.455035458813326, 5.293210472761084, 5.091036221946993, 5.126601897337183, 4.3102922186750305, 4.29708002583955, 4.898775160904346, 4.299721914944693, 5.178872732902185, 3.6707146342411816, 3.903174506144316, 3.6326170872076315, 4.754822446775203, 4.17024978284503, 3.4892362556767287, 3.364935967439825, 3.3263231342353223, 6.685125788520231, 6.143095480118004, 3.202542253472266, 3.1814232344013167, 3.169024370517003, 3.15077140575353, 8.087337942874855, 3.1234997028707605, 3.110222191238759, 3.770263234279491, 3.0716916845884565, 5.776082522047941, 3.970603056806581, 4.608680847251622, 17.15995989061172, 4.505978459336362, 5.204407039379825, 5.517288866323604, 4.297118072736977, 5.0045575903723725, 8.29486348293425, 37.11039487811568, 13.758038757970015, 55.2666725776533, 18.484745638353512, 13.694554549070775, 8.281681699569333, 29.56286452034368, 6.864912323676727, 7.815384848083847, 4.2905728412757345, 5.803894811110184, 4.178942094836922, 3.774902255480769, 8.731661341413586, 3.519595855321129, 3.502456732823072, 6.789010262904501, 4.627203713065464, 3.369316364650467, 3.922943880473386, 3.2698969776217734, 4.303614756965614, 3.181558331446803, 5.944078908636562, 3.10634530400716, 3.759718813057444, 4.9623111234212285, 4.339613093271662, 3.537680501711317, 3.7344015901710517, 2.895012792785715, 2.895012792785715, 2.8276690965431572, 2.8244847651049705, 2.8108864935005786, 2.778541003413865, 2.7675874651076957, 3.62331462422703, 4.747450311818113, 4.810305494972741, 18.45929138346968, 5.560566608108481, 24.562208717148568, 18.03112995640716, 49.82241047936709, 36.73856628730475, 14.288682278049809, 17.24077216466289, 296.89514001087116, 23.6706215500272, 13.086947052207577, 16.901170769306958, 167.60673252861997, 17.507051631510603, 111.33143094810113, 88.58989002889639, 9.340021834306558, 5.556021806582336, 5.071682048026118, 4.224515057760444, 5.44534811184355, 9.026143955235309, 3.5642298377217854, 5.056124761579052, 3.4148234459477806, 3.38140494206559, 5.652333991136714, 8.281681699569333, 3.58496942809292, 4.305242075530094, 3.071346959529837, 2.96224411157908, 2.9339209997000855, 4.918757714106722, 2.9171994641887435, 2.902761895313997, 2.899663134912739, 2.8565534596273405, 5.4473640415972095, 3.2907231030574198, 2.827815876222526, 2.7838655415627342, 3.147526245893696, 2.7800504288473524, 2.75858898366457, 2.765337885893253, 11.181670526514424, 4.204654503153722, 102.70521655096128, 6.663881819479659, 4.610451134987517, 43.64061800185672, 3.887801511687046, 48.08175780503798, 8.017733932116238, 11.83816082495945, 131.5898170097106, 60.26394262669519, 89.46909814089246, 7.144780678696319, 12.714991500968214, 5.915670106492623, 6.860791550723136, 30.846038495267337, 19.160004650565213, 296.89514001087116, 167.60673252861997, 6.046752871138471, 4.561824257033584, 6.860791550723136, 4.953845599381421, 3.575944742129099, 8.29486348293425, 5.1747598551122636, 3.279598876411564, 3.272669457034796, 3.2298055159537298, 3.800330049157984, 3.151172058823418, 4.02185131841099, 3.6260719185516983, 3.083167677603, 2.972979926481547, 5.958006363108623, 2.945812809314526, 2.943359689280006, 3.160281395322992, 2.9180940888142146, 3.107070071931663, 2.904148533866127, 2.904148533866127, 6.865046967249039, 37.577415554597565, 2.834782507313502, 4.039611551710997, 2.799121996978108, 2.775397419929343, 3.4256146434002304, 20.077018734699145, 7.760061717577436, 16.787293657938037, 10.568671944860139, 6.801998725797415, 26.03533850305706, 10.296421364797588, 43.78496584468843, 164.54830749945754, 31.996803942998977, 15.126097014368046, 17.661110904004197, 18.484745638353512, 25.429973557327493, 50.82070041050149, 62.73702120837145, 23.963186345787264, 296.89514001087116, 110.93542159333116, 180.48559212751792, 64.67317389768668, 36.73856628730475, 6.05408811062111, 3.3686028923734557, 3.3686028923734557, 3.0251820415922284, 3.0196234737035477, 2.9293281866295047, 5.618210162157864, 5.367180033646195, 4.7403129084392335, 2.7457473608456797, 2.7143674204655253, 3.5052736505924043, 3.6099124567635488, 2.5704715556824316, 2.5544834505439837, 2.5544834505439837, 2.4920477058142487, 2.4844523467104143, 2.4844523467104143, 2.4844523467104143, 2.464788312050328, 3.6111390217427526, 3.3807970758780184, 4.5623440489994485, 2.4239521747220647, 2.709516051572354, 2.4070708654345245, 2.4024575595307356, 2.3939394352570367, 2.379668195825606, 3.3641538696783515, 3.8821508525015833, 4.100631541777499, 3.194361127105016, 25.429973557327493, 131.5898170097106, 5.094153637851775, 110.93542159333116, 3.4919185310088077, 5.761731900487212, 15.571452967822296, 7.760061717577436, 17.11196810051848, 14.894419234080386, 7.956950639080451, 3.13791722623323, 3.0922097735333023, 9.371977648430864, 114.467395166734, 3.305754640064646, 3.160606087748178, 2.558387615718148, 3.0379591918045405, 2.518593569115905, 4.665854900096668, 2.4959828772285175, 2.4487322246399463, 3.6155827522036215, 2.4174027715522213, 2.4122321734378254, 2.8761542988731814, 2.383513116650521, 2.383513116650521, 3.0662886415561363, 2.377050988815299, 2.3740987555471835, 2.3740987555471835, 2.3625582546061796, 2.3625582546061796, 2.35137491774848, 2.350955011854258, 2.3165186877933457, 2.3044225608941185, 2.2970901318279155, 3.6823426079660457, 7.05497096362105, 164.54830749945754, 22.31528501222588, 106.2885308648179, 315.3688369873434, 2.918619714055729, 29.56286452034368, 3.836001728021035, 7.815384848083847, 8.731661341413586, 45.22900044649819, 59.13491454738424, 43.43054803013521, 296.89514001087116, 3.151706742434028, 2.9517061672578384, 2.8397513925416877, 2.835840857705087, 3.1778149486941576, 4.7372221365524005, 2.620026667859148, 3.1108110040403165, 2.6041049444741944, 2.5877170722369174, 4.423753458540272, 3.277620956698021, 4.416309954476125, 2.478001602157111, 3.156352593406232, 2.427956791428757, 2.408930007612474, 2.4041514582268655, 2.3993325347806853, 2.389085518422673, 2.3882627088439716, 3.6841140573485607, 2.3789161388664444, 2.8028023422509696, 2.347955152367042, 2.347672255885832, 2.3263046914105496, 2.3263046914105496, 2.3263046914105496, 4.942717144177655, 9.259198096884736, 3.3117888913809606, 3.4438565943023534, 4.32991335546366, 7.083378811098902, 8.04835102036718, 23.963186345787264, 3.675223919523287, 9.371977648430864, 14.779083395685918, 6.865513856253551, 18.013149510462874, 47.977011153244426, 7.354926687916911, 5.699114328552806, 23.618507285554276], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.9507, -5.0564, -5.1101, -4.8955, -5.2192, -4.9643, -5.2964, -5.3448, -5.5065, -5.5586, -5.5996, -5.6151, -4.2298, -5.3793, -5.6509, -5.6608, -5.6805, -5.7363, -5.7505, -5.8085, -5.0811, -4.8931, -5.8512, -5.0348, -5.8862, -5.9166, -5.9364, -5.9399, -5.9423, -5.6561, -4.9724, -5.5828, -5.5341, -4.9724, -5.5567, -3.6894, -4.9099, -4.9858, -4.6985, -4.2439, -5.3014, -3.796, -5.5171, -4.6796, -4.637, -4.4925, -5.2557, -5.0116, -4.5034, -4.5639, -4.9416, -4.9883, -4.9271, -5.1287, -4.9914, -5.543, -5.6354, -5.7881, -4.8822, -6.0246, -5.9379, -4.0572, -6.3505, -6.3893, -6.4048, -6.4359, -6.4927, -6.5303, -6.1756, -6.6213, -6.3826, -6.6371, -5.5168, -6.679, -6.1152, -6.707, -4.3009, -6.5929, -6.0808, -6.4598, -6.7733, -6.7754, -5.7716, -6.7856, -6.7856, -3.4857, -6.5238, -3.2942, -6.2304, -3.0551, -6.2612, -3.5008, -4.9607, -5.2316, -3.8769, -4.4399, -4.105, -3.5221, -3.603, -4.3313, -4.0086, -4.8952, -5.9798, -5.6001, -5.4703, -5.2079, -5.1596, -5.6252, -5.3152, -5.4143, -5.6803, -5.6021, -5.6844, -4.4979, -5.5532, -4.1217, -5.5262, -5.307, -6.0046, -6.167, -6.0626, -6.207, -6.2188, -6.2882, -6.3015, -5.9319, -6.2148, -6.3619, -6.0244, -6.0661, -6.3665, -6.3685, -6.4672, -6.1735, -6.4779, -6.4779, -6.2734, -6.5165, -6.5165, -6.2989, -6.5513, -6.5903, -6.5903, -3.5461, -4.774, -3.4716, -3.965, -6.0993, -4.6402, -5.7073, -3.7539, -4.8285, -4.6356, -5.518, -4.5184, -4.6915, -5.3007, -4.642, -5.681, -6.0731, -5.6284, -5.7103, -6.0753, -4.5609, -4.7573, -5.226, -5.2836, -5.3369, -5.5434, -5.5483, -5.4501, -5.622, -5.4755, -5.8216, -5.763, -5.841, -5.5812, -5.7239, -5.9172, -5.9886, -6.0115, -5.3148, -5.4297, -6.09, -6.1037, -6.1116, -6.1241, -5.1898, -6.1428, -6.1519, -5.9708, -6.1792, -5.548, -5.9267, -5.8063, -4.7683, -5.8634, -5.7955, -5.82, -5.9546, -5.8946, -5.7126, -5.2857, -5.5929, -5.2951, -5.5795, -5.6789, -5.8218, -5.8317, -4.8451, -4.9076, -5.5318, -5.2454, -5.5757, -5.7522, -4.924, -5.8825, -5.8917, -5.2314, -5.6314, -5.9676, -5.8266, -6.0284, -5.7801, -6.0858, -5.4779, -6.1371, -5.9567, -5.7005, -5.8511, -6.0589, -6.0348, -6.2979, -6.2979, -6.3551, -6.358, -6.3697, -6.3989, -6.409, -6.1546, -5.9261, -5.957, -4.9455, -5.8715, -4.867, -5.1303, -4.8019, -5.0608, -5.6191, -5.5611, -4.945, -5.696, -5.8067, -5.7968, -5.7095, -5.8627, -5.8021, -5.8801, -4.4242, -5.0681, -5.2631, -5.4909, -5.3075, -4.8363, -5.7933, -5.4462, -5.8766, -5.8962, -5.4177, -5.0375, -5.8834, -5.7516, -6.0993, -6.1819, -6.2045, -5.6928, -6.2181, -6.2299, -6.2324, -6.2689, -5.6322, -6.1364, -6.2939, -6.3337, -6.2122, -6.337, -6.3569, -6.3566, -5.1468, -6.0176, -3.4681, -5.6661, -5.9513, -4.4471, -6.0804, -4.6212, -5.7127, -5.5677, -4.5459, -4.9285, -4.903, -5.8527, -5.6555, -5.9232, -5.8976, -5.7149, -5.7746, -5.4888, -5.6344, -5.1359, -5.4829, -5.0983, -5.428, -5.7635, -4.9648, -5.466, -5.9363, -5.9409, -5.9686, -5.8204, -6.0215, -5.7816, -5.9031, -6.0699, -6.1534, -5.4652, -6.1751, -6.1776, -6.1134, -6.1977, -6.1394, -6.2094, -6.2094, -5.3505, -3.6714, -6.2693, -5.9165, -6.3014, -6.3232, -6.1155, -4.4134, -5.5279, -4.9804, -5.3144, -5.6421, -4.8338, -5.4236, -4.6817, -4.2566, -5.0332, -5.3947, -5.3303, -5.3216, -5.2063, -5.1837, -5.3295, -5.5346, -5.0989, -5.28, -5.2323, -5.5291, -5.6217, -4.7892, -5.4074, -5.4074, -5.6434, -5.6479, -5.7211, -5.0774, -5.1263, -5.2957, -5.8887, -5.9206, -5.712, -5.6878, -6.0806, -6.0999, -6.0999, -6.1801, -6.1899, -6.1899, -6.1899, -6.2167, -5.8547, -5.9281, -5.6398, -6.2748, -6.1729, -6.3004, -6.3071, -6.3199, -6.3419, -6.006, -5.9214, -5.8948, -6.089, -4.6553, -3.8117, -5.8041, -4.8166, -6.0727, -5.9336, -5.7336, -5.9492, -6.0195, -6.0417, -4.2119, -5.5413, -5.5748, -4.5113, -2.175, -5.767, -5.8371, -6.0842, -5.9272, -6.1349, -5.5256, -6.1654, -6.2307, -5.8681, -6.2774, -6.2852, -6.1254, -6.3294, -6.3294, -6.0828, -6.34, -6.3445, -6.3445, -6.3633, -6.3633, -6.3821, -6.3835, -6.4421, -6.4643, -6.4784, -6.0575, -5.5117, -2.8506, -5.1984, -4.6619, -4.581, -6.3039, -5.7535, -6.2402, -6.1168, -6.1003, -5.8857, -5.9269, -6.0099, -6.0346, -5.5039, -5.5716, -5.6692, -5.6728, -5.5989, -5.2479, -5.894, -5.7252, -5.9125, -5.9318, -5.4246, -5.7382, -5.4421, -6.0722, -5.8594, -6.143, -6.1721, -6.1789, -6.1866, -6.2021, -6.2034, -5.7743, -6.2181, -6.0789, -6.2685, -6.2691, -6.3051, -6.3051, -6.3051, -5.5674, -4.9509, -6.0229, -6.0028, -5.8524, -5.585, -5.6195, -5.1427, -6.021, -5.6574, -5.5607, -5.8353, -5.5863, -5.4495, -5.9189, -5.9974, -5.9425], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.3717, 0.3698, 0.3687, 0.3675, 0.3664, 0.3662, 0.3646, 0.3634, 0.359, 0.3574, 0.3561, 0.3556, 0.3549, 0.3547, 0.3544, 0.354, 0.3534, 0.3513, 0.3508, 0.3486, 0.3482, 0.3478, 0.3469, 0.3455, 0.3454, 0.3441, 0.3432, 0.343, 0.3429, 0.3427, 0.3385, 0.3403, 0.3383, 0.3266, 0.3379, 0.2631, 0.3124, 0.3133, 0.2953, 0.2667, 0.3251, 0.2169, 0.3358, 0.2135, 0.1897, 0.1598, 0.2812, 0.2008, 0.0515, 0.0392, 0.1328, 0.146, 0.113, 0.1887, 0.006, 2.4275, 2.3995, 2.3492, 2.349, 2.2608, 2.174, 2.1483, 2.1168, 2.0981, 2.0903, 2.0749, 2.0459, 2.0263, 2.0102, 1.9774, 1.976, 1.9687, 1.9639, 1.9453, 1.9399, 1.9287, 1.9198, 1.915, 1.9111, 1.8972, 1.8908, 1.8898, 1.8896, 1.8838, 1.8838, 1.8017, 1.8754, 1.6719, 1.8478, 1.4999, 1.8403, 1.1515, 1.5073, 1.5776, 1.1633, 1.2901, 0.788, 0.4305, 0.4099, 0.8031, 0.5945, 0.8828, 1.5386, 1.0195, 0.7704, -0.2105, -0.3329, 0.7303, -0.3214, -0.1151, 0.7646, -0.303, -0.117, 2.9638, 2.6754, 2.6677, 2.5782, 2.4863, 2.4061, 2.3935, 2.3857, 2.3719, 2.3654, 2.3268, 2.3192, 2.3089, 2.2924, 2.2844, 2.283, 2.282, 2.2817, 2.2805, 2.2216, 2.2198, 2.2151, 2.2151, 2.1963, 2.1913, 2.1913, 2.1788, 2.1696, 2.1449, 2.1449, 1.9399, 1.9023, 1.5258, 1.3524, 2.0272, 1.3126, 1.833, 0.7568, 1.2936, 1.1729, 1.6561, 0.6941, 0.4429, 1.0393, -0.6291, 1.0019, 1.9113, 0.4741, -0.4694, 0.7999, 2.9811, 2.9401, 2.8138, 2.7953, 2.7349, 2.7019, 2.7, 2.6672, 2.6257, 2.5863, 2.5843, 2.5815, 2.5754, 2.566, 2.5544, 2.5394, 2.5043, 2.493, 2.4917, 2.4613, 2.4524, 2.4453, 2.4413, 2.4346, 2.4263, 2.4246, 2.4197, 2.4083, 2.4049, 2.4046, 2.4007, 2.3721, 2.0954, 2.3375, 2.2613, 2.1785, 2.2937, 2.2014, 1.8781, 0.8068, 1.4918, 0.399, 1.2099, 1.4104, 1.7705, 0.4881, 2.9347, 2.7426, 2.7181, 2.7024, 2.7006, 2.6257, 2.6154, 2.5654, 2.5612, 2.5596, 2.543, 2.524, 2.5128, 2.4931, 2.4667, 2.4632, 2.446, 2.4357, 2.4253, 2.4039, 2.3875, 2.3839, 2.354, 2.3455, 2.3455, 2.3117, 2.31, 2.3031, 2.2855, 2.2793, 2.2643, 2.2226, 2.1786, 1.8453, 2.1191, 1.6381, 1.6839, 0.9959, 1.0417, 1.4277, 1.298, -0.932, 0.8461, 1.328, 1.0822, -1.1248, 0.9811, -0.8083, -0.6578, 3.0478, 2.9233, 2.8196, 2.7745, 2.7041, 2.6699, 2.642, 2.6395, 2.6016, 2.5918, 2.5566, 2.5548, 2.5462, 2.4948, 2.4849, 2.4384, 2.4255, 2.4205, 2.4176, 2.4107, 2.4093, 2.3878, 2.379, 2.3788, 2.3729, 2.3487, 2.3474, 2.3469, 2.3347, 2.3325, 2.1452, 2.2525, 1.6063, 2.1435, 2.2267, 1.4833, 2.268, 1.2122, 1.912, 1.6673, 0.2807, 0.6791, 0.3095, 1.8872, 1.508, 2.0055, 1.8829, 0.5624, 0.9789, -1.4758, -1.0497, 2.7709, 2.7057, 2.6822, 2.6781, 2.6685, 2.6258, 2.5965, 2.5823, 2.5799, 2.5653, 2.5509, 2.537, 2.5329, 2.5151, 2.5104, 2.4633, 2.4564, 2.4508, 2.4492, 2.4422, 2.4377, 2.4333, 2.4308, 2.4308, 2.4294, 2.4085, 2.3951, 2.3936, 2.3757, 2.3623, 2.3596, 2.2933, 2.1294, 1.9053, 2.034, 2.147, 1.6131, 1.9509, 1.2454, 0.3465, 1.2075, 1.5952, 1.5046, 1.4677, 1.2641, 0.5943, 0.2378, 0.9952, -1.086, -0.2827, -0.7216, 0.0079, 0.4808, 3.1164, 3.0844, 3.0844, 2.9559, 2.9533, 2.9105, 2.9029, 2.8997, 2.8545, 2.8075, 2.7871, 2.7401, 2.7349, 2.6816, 2.6686, 2.6686, 2.6131, 2.6064, 2.6064, 2.6064, 2.5875, 2.5676, 2.5601, 2.5487, 2.5461, 2.5366, 2.5275, 2.5228, 2.5135, 2.4974, 2.4872, 2.4285, 2.4004, 2.4559, 1.8151, 1.015, 2.2741, 0.1808, 2.3832, 2.0215, 1.2273, 1.7082, 0.847, 0.9636, 3.4204, 3.0214, 3.0027, 2.9573, 2.791, 2.7437, 2.7184, 2.6828, 2.6679, 2.6477, 2.6404, 2.6262, 2.58, 2.5529, 2.5462, 2.5406, 2.5245, 2.5083, 2.5083, 2.503, 2.5005, 2.4972, 2.4972, 2.4832, 2.4832, 2.4693, 2.468, 2.4241, 2.4072, 2.3963, 2.3452, 2.2409, 1.7525, 1.4026, 0.3782, -0.6284, 2.3313, 0.5663, 2.1217, 1.5334, 1.4391, 0.0089, -0.3004, -0.0748, -2.0216, 3.0544, 3.0523, 2.9934, 2.9912, 2.9513, 2.903, 2.8491, 2.8463, 2.8368, 2.8237, 2.7947, 2.781, 2.7789, 2.7267, 2.6974, 2.6762, 2.6551, 2.6502, 2.6445, 2.6333, 2.6324, 2.628, 2.6216, 2.5968, 2.5843, 2.5838, 2.5569, 2.5569, 2.5569, 2.541, 2.5298, 2.486, 2.4669, 2.3883, 2.1636, 2.0013, 1.3871, 2.3837, 1.8112, 1.4524, 1.9445, 1.2289, 0.3861, 1.792, 1.9686, 0.6017]}, \"token.table\": {\"Topic\": [8, 3, 5, 10, 8, 3, 7, 1, 6, 5, 8, 4, 5, 9, 2, 2, 4, 1, 2, 3, 2, 3, 9, 9, 6, 1, 4, 3, 6, 10, 4, 6, 3, 7, 1, 10, 9, 1, 2, 3, 4, 7, 8, 2, 4, 6, 3, 4, 7, 8, 5, 8, 6, 1, 9, 1, 4, 1, 5, 9, 1, 5, 7, 6, 1, 2, 7, 3, 7, 9, 1, 8, 1, 3, 4, 3, 3, 4, 8, 9, 2, 5, 10, 2, 4, 5, 1, 3, 4, 4, 6, 7, 3, 5, 7, 1, 5, 6, 1, 5, 1, 2, 3, 6, 6, 8, 8, 3, 4, 6, 3, 8, 1, 3, 7, 4, 4, 1, 3, 5, 7, 2, 6, 5, 7, 9, 1, 7, 10, 1, 5, 6, 10, 4, 6, 8, 2, 4, 6, 8, 1, 2, 3, 1, 9, 2, 4, 3, 1, 2, 8, 5, 2, 10, 2, 1, 7, 10, 5, 6, 6, 7, 4, 6, 9, 2, 1, 4, 2, 7, 5, 7, 1, 7, 2, 1, 2, 1, 2, 7, 9, 6, 7, 8, 6, 9, 2, 3, 9, 10, 4, 5, 10, 6, 7, 1, 6, 5, 5, 2, 1, 1, 5, 6, 8, 10, 5, 10, 4, 5, 7, 9, 10, 2, 4, 8, 10, 5, 1, 2, 7, 2, 5, 7, 4, 6, 10, 1, 10, 2, 10, 1, 2, 3, 1, 6, 3, 4, 9, 5, 6, 1, 2, 5, 7, 4, 1, 2, 3, 4, 6, 1, 1, 9, 3, 8, 2, 7, 3, 1, 3, 1, 5, 1, 10, 10, 3, 2, 4, 10, 5, 8, 1, 2, 3, 4, 1, 2, 3, 1, 3, 3, 10, 6, 5, 9, 1, 2, 5, 1, 2, 6, 1, 6, 10, 10, 1, 10, 9, 2, 5, 8, 3, 5, 9, 8, 5, 1, 2, 7, 2, 8, 2, 3, 5, 1, 3, 7, 5, 5, 8, 1, 5, 6, 1, 3, 6, 1, 7, 1, 2, 3, 7, 1, 2, 7, 1, 4, 9, 6, 1, 8, 3, 6, 5, 1, 4, 7, 10, 6, 10, 4, 10, 4, 10, 2, 4, 6, 8, 4, 6, 2, 3, 4, 7, 3, 2, 2, 1, 6, 9, 1, 2, 9, 6, 8, 1, 4, 6, 1, 2, 3, 9, 10, 1, 7, 2, 5, 10, 1, 4, 6, 3, 4, 7, 5, 10, 6, 3, 4, 1, 10, 1, 7, 2, 7, 1, 4, 6, 7, 8, 10, 4, 4, 6, 10, 1, 5, 2, 5, 6, 8, 3, 5, 6, 9, 3, 8, 1, 10, 1, 2, 1, 2, 6, 8, 1, 7, 9, 1, 10, 6, 8, 1, 2, 5, 3, 1, 2, 3, 5, 7, 4, 7, 1, 1, 10, 6, 1, 10, 5, 7, 3, 4, 5, 7, 8, 9, 3, 7, 1, 2, 3, 3, 1, 2, 5, 1, 2, 5, 7, 9, 1, 1, 1, 6, 5, 5, 2, 5, 8, 1, 2, 10, 7, 3, 4, 5, 9, 6, 7, 3, 5, 7, 1, 8, 5, 7, 9, 5, 10, 1, 7, 8, 4, 8, 1, 2, 3, 5, 6, 7, 9, 1, 5, 6, 7, 8, 9, 1, 4, 5, 7, 8, 6, 1, 1, 2, 1, 2, 4, 5, 8, 1, 2, 6, 10, 9, 7, 1, 3, 4, 6, 10, 7, 4, 1, 2, 3, 7, 8, 10, 1, 10, 8, 3, 1, 3, 1, 3, 6, 3, 4, 5, 7, 9, 4, 5, 7, 2, 4, 1, 2, 9, 1, 2, 9, 1, 5, 3, 9, 4, 2, 4, 6, 7, 8, 3, 5, 2, 4, 5, 10, 7, 4, 4, 6, 8, 10, 1, 2, 10, 5, 7, 8, 2, 5, 7, 9, 8, 1, 2, 2, 10, 1, 10, 2, 4, 5, 6, 7, 8, 1, 1, 2, 4, 5, 6, 8, 5, 5, 10, 1, 2, 1, 2, 5, 1, 7, 5, 1, 5, 3, 7, 9, 6, 4, 5, 10, 4, 4, 5, 6, 9, 3, 1, 3, 6, 7, 1, 7, 4, 6, 5, 1, 3, 8, 9, 8, 1, 4, 8, 2, 3, 4, 9, 5, 7, 6, 1, 5, 1, 2, 1, 6, 8, 5, 1, 2, 3, 5, 6, 3, 3, 10, 4, 6, 7, 2, 7, 2, 3, 7, 5, 10, 9, 1, 2, 9, 1, 3, 7, 1, 3, 8, 1, 2, 4, 5, 7, 10, 5, 9, 3, 4, 5, 7, 2, 9, 2, 3, 4, 4, 6, 2, 4, 5, 8, 7, 4, 6, 7, 3, 10, 1, 6, 1, 3, 7, 10, 2, 1, 1, 1, 6, 8, 1, 2, 5, 6, 2, 5, 6, 10, 1, 3, 4, 6, 5, 5, 7, 2, 1, 2, 5, 5, 6, 1, 2, 6, 1, 5, 9, 1, 2, 2, 7, 9, 4, 1, 7], \"Freq\": [0.41772151177777406, 0.20788700448341627, 0.41577400896683253, 0.38644101039050743, 0.42022665250314795, 0.3255646052152635, 0.3243417499684763, 0.7078258761961951, 0.15729463915471004, 0.3599011131278416, 0.33116711692981604, 0.31555453132626343, 0.3426277137730955, 0.3426277137730955, 0.35454304536037323, 0.6221705126422434, 0.8048251457887855, 0.9497436194313934, 0.02466866543977645, 0.012334332719888225, 0.6091081066769563, 0.20303603555898542, 0.4136671024654684, 0.4083745825442538, 0.5914701238882869, 0.7302172527165943, 0.14604345054331885, 0.26901819530512233, 0.35921275114409656, 0.35262909668677705, 0.4883531453661164, 0.16278438178870547, 0.3786570621819471, 0.5515610404105903, 0.8119583386005423, 0.06766319488337853, 0.4339481903058608, 0.6850832575243823, 0.05408552033087228, 0.1983135745465317, 0.018028506776957425, 0.02704276016543614, 0.02704276016543614, 0.3836229659036525, 0.19181148295182626, 0.19181148295182626, 0.5950852781645202, 0.16229598495396003, 0.16229598495396003, 0.05409866165132001, 0.29725156420850946, 0.29725156420850946, 0.35970570519996425, 0.5669761109756505, 0.14174402774391262, 0.7268477852053595, 0.21805433556160783, 0.9554799289799633, 0.022749522118570554, 0.4316822502962726, 0.7681866704998519, 0.038409333524992595, 0.19204666762496297, 0.719939578937778, 0.7360805370998825, 0.05662157977691404, 0.16986473933074211, 0.2715662572615299, 0.2715662572615299, 0.2715662572615299, 0.8765794741953445, 0.05843863161302297, 0.9047043664470069, 0.018094087328940137, 0.054282261986820415, 0.323866229973301, 0.28637552426261853, 0.28637552426261853, 0.28637552426261853, 0.41954877152313297, 0.27209226482442733, 0.27209226482442733, 0.27209226482442733, 0.24730016404990834, 0.4946003280998167, 0.12365008202495417, 0.9544681603696938, 0.022999232779992624, 0.5124034287607769, 0.1932456825048755, 0.1932456825048755, 0.5797370475146265, 0.2903592444057449, 0.4212787641023393, 0.21063938205116964, 0.6998545985840795, 0.1399709197168159, 0.06998545985840796, 0.9758091663540553, 0.011756736944024763, 0.9654263597948372, 0.21689851398950086, 0.21689851398950086, 0.4337970279790017, 0.35007221609304584, 0.3690695980264416, 0.416240443471279, 0.12074842239493488, 0.24149684478986977, 0.48299368957973954, 0.6045438339994921, 0.27701502792024646, 0.8864973547969175, 0.08864973547969175, 0.016621825402442204, 0.5851829457555959, 0.7556850460762975, 0.7349225277016329, 0.08165805863351476, 0.10887741151135302, 0.05443870575567651, 0.3167382449268124, 0.3448676461619717, 0.432226485804539, 0.2161132429022695, 0.3908711853732518, 0.5827267346025082, 0.2913633673012541, 0.41871440536960264, 0.8283449821964066, 0.11833499745662951, 0.4645499521078022, 0.2322749760539011, 0.4339636582109382, 0.2169818291054691, 0.40250319203106016, 0.11078928111045513, 0.11078928111045513, 0.5539464055522757, 0.40250319203106016, 0.6023462611692407, 0.37345468192492925, 0.5474858813195523, 0.9507174506512719, 0.022109708154680743, 0.48302004072917665, 0.5304669397658666, 0.3615086936707609, 0.7706409944401115, 0.0642200828700093, 0.0642200828700093, 0.5319546751884826, 0.2903721373457994, 0.2903721373457994, 0.3326905993115629, 0.7928828714942663, 0.0834613548941333, 0.0834613548941333, 0.18364298837479556, 0.5509289651243867, 0.2018633766310497, 0.6055901298931491, 0.6012644951464625, 0.5915197308489775, 0.3261271579092116, 0.3388869453409694, 0.889238718919167, 0.08083988353810609, 0.5910839957158015, 0.36030875896161146, 0.2919184158459254, 0.2919184158459254, 0.5588463094139179, 0.3991759352956556, 0.7049912715659028, 0.712360502809714, 0.27799434255988836, 0.7049601528133762, 0.11546761123667369, 0.048617941573336286, 0.12154485393334072, 0.40660673207466835, 0.20330336603733418, 0.20330336603733418, 0.3291683452159877, 0.3291683452159877, 0.5793584699728959, 0.31639501166450806, 0.31639501166450806, 0.42986630413991567, 0.3996357248136267, 0.19981786240681335, 0.19981786240681335, 0.21921054903817572, 0.43842109807635143, 0.9810633356915597, 0.012577735072968714, 0.36132552723535577, 0.4647256115949739, 0.6051215362657014, 0.9476008998083428, 0.9665482857160134, 0.01193269488538288, 0.01193269488538288, 0.2852844313113746, 0.2852844313113746, 0.32145958037990785, 0.32145958037990785, 0.10670106540079388, 0.21340213080158776, 0.10670106540079388, 0.4268042616031755, 0.10670106540079388, 0.3880995379480593, 0.25873302529870623, 0.12936651264935312, 0.12936651264935312, 0.35575965173699897, 0.8222000247230334, 0.022838889575639818, 0.13703333745383892, 0.35454304536037323, 0.4030380099628084, 0.2015190049814042, 0.5193831612600185, 0.17312772042000618, 0.17312772042000618, 0.8882400043760508, 0.05551500027350317, 0.6247331741329064, 0.41857019863408745, 0.9517787465197403, 0.013219149257218614, 0.013219149257218614, 0.8020051411396351, 0.160401028227927, 0.2103127953133594, 0.6309383859400781, 0.32339332491577816, 0.5098212110438495, 0.35362981317433845, 0.9514836378588868, 0.021624628133156517, 0.021624628133156517, 0.33946488277803855, 0.8038215974877473, 0.8271012174892797, 0.01117704347958486, 0.08941634783667889, 0.01117704347958486, 0.055885217397924306, 0.9454240817138216, 0.8514343415103355, 0.08962466752740374, 0.301474469042258, 0.40250319203106016, 0.43719292867540693, 0.21859646433770347, 0.36302595556123235, 0.5731491735722151, 0.22925966942888604, 0.799677769545254, 0.11423968136360772, 0.9584019060341618, 0.31728840330738106, 0.41512206533186685, 0.346440375156633, 0.4018534753741364, 0.2009267376870682, 0.2009267376870682, 0.29578823500972545, 0.29578823500972545, 0.7856750996185783, 0.13439179335580945, 0.062026981548835125, 0.5943649505823073, 0.6070002712102252, 0.27590921418646597, 0.36842656212995195, 0.6763858149465922, 0.28987963497711094, 0.3732929879679286, 0.3816755044013009, 0.557884813278291, 0.3454216169586435, 0.4232699862745574, 0.8364873957421707, 0.13806102648171747, 0.01624247370373147, 0.9385240902694653, 0.04875449819581638, 0.5856818168369177, 0.954280744757182, 0.021206238772381824, 0.021206238772381824, 0.4203595005566278, 0.7282776067002878, 0.14565552134005758, 0.4212124696428306, 0.21918557418292609, 0.21918557418292609, 0.21918557418292609, 0.26068809945919724, 0.26068809945919724, 0.26068809945919724, 0.38903367663779154, 0.5935922257058458, 0.6875686721458842, 0.12501248584470623, 0.12501248584470623, 0.3726351617538903, 0.3726351617538903, 0.14764361984249155, 0.4429308595274747, 0.14764361984249155, 0.35746832909602483, 0.35746832909602483, 0.17873416454801241, 0.7283414214563614, 0.5298150427858644, 0.41254939368375204, 0.5365924515279323, 0.08943207525465538, 0.3577283010186215, 0.9712575230739776, 0.3179362665889769, 0.32559004670481134, 0.963189374689586, 0.35725488245227816, 0.7477268060663673, 0.1574161696981826, 0.019677021212272824, 0.059031063636818475, 0.8766753495886564, 0.04781865543210854, 0.04781865543210854, 0.8456555345912523, 0.06765244276730019, 0.033826221383650094, 0.362504166413214, 0.8728101308075372, 0.06713924083134902, 0.19777992971987013, 0.5933397891596104, 0.5653421780266817, 0.5677156062089693, 0.09461926770149488, 0.28385780310448466, 0.4118689440974521, 0.2572147772960937, 0.2572147772960937, 0.5731913385762137, 0.4167825782812579, 0.5505672499980961, 0.3050993428500139, 0.1651776422357696, 0.1651776422357696, 0.1651776422357696, 0.4955329267073088, 0.589270998911238, 0.34449949257440843, 0.6731780033007497, 0.08414725041259372, 0.08414725041259372, 0.16829450082518743, 0.3376976238024289, 0.7518782128753662, 0.35268918886346934, 0.45018805574109827, 0.3001253704940655, 0.4252830939259713, 0.3057639247317436, 0.3319722611373216, 0.34944448540770695, 0.24386487540076093, 0.24386487540076093, 0.18357502681366458, 0.18357502681366458, 0.36715005362732916, 0.6758843591356098, 0.014693138242078473, 0.2938627648415695, 0.30250278949330744, 0.42986630413991567, 0.9856038142611324, 0.6111219071332982, 0.43200285361059537, 0.10800071340264884, 0.21600142680529769, 0.8753149939867504, 0.03241907385136113, 0.06483814770272225, 0.14566542731181342, 0.14566542731181342, 0.43699628193544027, 0.5168942749026412, 0.17229809163421372, 0.3427945234036625, 0.20413265911460884, 0.6123979773438265, 0.96634768854797, 0.3168213849393907, 0.6552574955879528, 0.23827545294107372, 0.5411972807948457, 0.2705986403974229, 0.6291787902936964, 0.07864734878671205, 0.039323674393356024, 0.11797102318006808, 0.11797102318006808, 0.38400910152333134, 0.3201537042186735, 0.23783166946295944, 0.23783166946295944, 0.352143501936964, 0.7641201542351427, 0.15282403084702853, 0.17355892590480304, 0.17355892590480304, 0.17355892590480304, 0.17355892590480304, 0.17691806633650373, 0.17691806633650373, 0.5307541990095112, 0.4212124696428306, 0.49373282406293767, 0.24686641203146883, 0.6212452696641816, 0.12424905393283632, 0.4224387879377455, 0.543135584491387, 0.7502190143302777, 0.2250657042990833, 0.3130516432580932, 0.3130516432580932, 0.9210107128338594, 0.023025267820846483, 0.023025267820846483, 0.9515500552916267, 0.4159471719546032, 0.31770982094418215, 0.4057143549046419, 0.8229228494871659, 0.04014257802376419, 0.10035644505941047, 0.6845070062339398, 0.7734006655364499, 0.023436383804134844, 0.16405468662894393, 0.023436383804134844, 0.3443350050242634, 0.6960084949697889, 0.5592927587603634, 0.9724694260115468, 0.9603518971645368, 0.01883042935616739, 0.3408408065868928, 0.942325664066992, 0.35678577291215124, 0.24754855440901125, 0.4950971088180225, 0.12886495448030838, 0.12886495448030838, 0.12886495448030838, 0.25772990896061676, 0.12886495448030838, 0.4253590540685313, 0.3471355159799371, 0.34268943000612984, 0.9580283260165912, 0.013884468492994075, 0.013884468492994075, 0.36302595556123235, 0.9601188251197493, 0.27599038551981453, 0.27599038551981453, 0.8815075156305215, 0.09512671031984045, 0.006341780687989363, 0.0031708903439946817, 0.012683561375978727, 0.9636383908713555, 0.9826720279949182, 0.8350728662024623, 0.1043841082753078, 0.699207334540438, 0.3143113832350367, 0.3926069259354745, 0.19630346296773726, 0.19630346296773726, 0.5263975816329691, 0.17546586054432306, 0.17546586054432306, 0.6098306760576582, 0.36842656212995195, 0.22905148537016165, 0.5726287134254041, 0.11452574268508083, 0.2915115530348969, 0.5830231060697938, 0.4120310973355694, 0.2060155486677847, 0.2060155486677847, 0.5151783318031649, 0.25758916590158243, 0.6397637604789079, 0.12795275209578158, 0.12795275209578158, 0.4221883505457771, 0.4221883505457771, 0.9486119825531523, 0.27692093657402184, 0.27692093657402184, 0.3173825934099598, 0.5937179489241716, 0.8420481385813388, 0.09430939152110994, 0.023577347880277485, 0.016840962771626774, 0.010104577662976065, 0.01347277021730142, 0.003368192554325355, 0.89681697223885, 0.030924723180650003, 0.015462361590325002, 0.030924723180650003, 0.015462361590325002, 0.015462361590325002, 0.9256135206088766, 0.011287969763522886, 0.02257593952704577, 0.02257593952704577, 0.3914685764697546, 0.7101406809969805, 0.9657704674262655, 0.5607193995361054, 0.33643163972166323, 0.6669161265844, 0.27461252271122355, 0.47958757967623683, 0.46087057924608366, 0.23043528962304183, 0.7903205235150197, 0.062393725540659445, 0.12478745108131889, 0.42986630413991567, 0.3186827210226971, 0.3164275186000633, 0.7073661217794424, 0.11789435362990705, 0.11789435362990705, 0.058947176814953525, 0.403550990091974, 0.3527607488123281, 0.3255535068891458, 0.8962625842333687, 0.02084331591240392, 0.02084331591240392, 0.02084331591240392, 0.02084331591240392, 0.02084331591240392, 0.9569895576498716, 0.02453819378589414, 0.3684099626529174, 0.3786570621819471, 0.8193410729191489, 0.16138536284771116, 0.7153471372320981, 0.2384490457440327, 0.5611310412233059, 0.3474111091170578, 0.1682346441510107, 0.5047039324530321, 0.1682346441510107, 0.1682346441510107, 0.4654282163408495, 0.23271410817042476, 0.23271410817042476, 0.29917163315526857, 0.4487574497329029, 0.7620765791091714, 0.19757540939867405, 0.028225058485524864, 0.930076595543721, 0.033820967110680764, 0.016910483555340382, 0.8449292283149623, 0.08449292283149623, 0.33576684894693215, 0.4232699862745574, 0.5448530325249444, 0.18124843999084303, 0.36249687998168606, 0.18124843999084303, 0.18124843999084303, 0.41544269192900557, 0.2927146323325488, 0.2927146323325488, 0.27192657178836505, 0.27192657178836505, 0.13596328589418252, 0.13596328589418252, 0.3397478071205821, 0.6981485059529161, 0.3842896961876231, 0.19214484809381155, 0.19214484809381155, 0.33878710933107853, 0.42352669255798076, 0.14117556418599359, 0.14117556418599359, 0.21095653795758684, 0.21095653795758684, 0.4219130759151737, 0.14729687557905916, 0.5891875023162366, 0.14729687557905916, 0.14729687557905916, 0.5937179489241716, 0.9802095168606105, 0.30167635584834446, 0.22605238048911863, 0.22605238048911863, 0.9314729222306017, 0.04233967828320917, 0.12472352019494558, 0.12472352019494558, 0.12472352019494558, 0.24944704038989116, 0.12472352019494558, 0.40127642727981455, 0.9565452991187187, 0.8207321999089808, 0.04559623332827671, 0.007599372221379451, 0.015198744442758903, 0.05319560554965616, 0.06079497777103561, 0.47859002460718414, 0.5710277535357153, 0.31468163380971087, 0.7761387126459847, 0.1826208735637611, 0.6655156958555409, 0.05545964132129508, 0.2218385652851803, 0.59769830165374, 0.34865734263134834, 0.3219217125378844, 0.5395133646318284, 0.35967557642121895, 0.16537801714587386, 0.4961340514376215, 0.4006437740912619, 0.30388457754798553, 0.2714356788181784, 0.2714356788181784, 0.2714356788181784, 0.321520437612759, 0.21432299576638825, 0.21432299576638825, 0.21432299576638825, 0.21432299576638825, 0.5684610092660299, 0.8794645303628463, 0.01659367038420465, 0.0663746815368186, 0.01659367038420465, 0.7272199820979113, 0.19833272239033944, 0.5792766408296796, 0.19309221360989318, 0.3454216169586435, 0.8267582101939275, 0.09726567178752088, 0.27658058701339944, 0.27658058701339944, 0.3305586196967093, 0.58275194486154, 0.34965116691692405, 0.3914685764697546, 0.3428012949322173, 0.22192738137218693, 0.44385476274437385, 0.397046991726826, 0.2631350401319917, 0.5262700802639834, 0.33758190153576884, 0.8120285951399987, 0.17400612752999972, 0.9264415644609526, 0.06095010292506267, 0.6757806485558877, 0.16894516213897193, 0.08447258106948596, 0.3536481695197313, 0.9072011303535901, 0.044910947047207425, 0.01796437881888297, 0.01796437881888297, 0.008982189409441486, 0.8477746067143727, 0.4619030072452418, 0.2309515036226209, 0.4651463605235795, 0.3616194625261796, 0.6192323315199428, 0.3356827566321176, 0.5035241349481764, 0.5187925017698763, 0.2593962508849382, 0.3443350050242634, 0.2264333822372354, 0.2264333822372354, 0.41954877152313297, 0.7979387333436126, 0.19788880586921595, 0.42068933510693896, 0.7771813341171981, 0.16653885731082818, 0.02775647621847136, 0.8317677038078389, 0.14200912016231396, 0.3413752015101468, 0.8050583922109195, 0.11500834174441707, 0.6245038602789882, 0.24864171269143143, 0.49728342538286285, 0.42595383469430514, 0.34768649247774347, 0.34768649247774347, 0.1470156111919541, 0.1470156111919541, 0.1470156111919541, 0.2940312223839082, 0.3530600888277622, 0.4353333751010664, 0.3601453207658191, 0.18007266038290956, 0.18007266038290956, 0.5037018234727626, 0.2518509117363813, 0.17799262952739311, 0.17799262952739311, 0.17799262952739311, 0.35598525905478623, 0.32184661975721096, 0.2411130700480816, 0.1205565350240408, 0.4822261400961632, 0.3019516137041624, 0.3019516137041624, 0.5071276704066732, 0.33808511360444876, 0.9725156622053536, 0.514272803377845, 0.2571364016889225, 0.4259025130832976, 0.5957114071971081, 0.9739382479192499, 0.9781915524362413, 0.5598492353903668, 0.2799246176951834, 0.36419956703227196, 0.6514072160305885, 0.08142590200382356, 0.2035647550095589, 0.7494629160596292, 0.20231786906478444, 0.20231786906478444, 0.20231786906478444, 0.20231786906478444, 0.7939135105771863, 0.10355393616224169, 0.03451797872074723, 0.03451797872074723, 0.35404687338182034, 0.5682470608028146, 0.3173422400722159, 0.5196289551733126, 0.8413625053931373, 0.14022708423218955, 0.6116400650196077, 0.5355610401580809, 0.26778052007904046, 0.7691916988539819, 0.029209811348885385, 0.1849954718762741, 0.7042523859632834, 0.2708663022935705, 0.4145537942041609, 0.5514026189301795, 0.42886870361236185, 0.33034129078034863, 0.12567628547153656, 0.6283814273576828, 0.6286494605224576, 0.9773971485737298, 0.33636284964206836], \"Term\": [\"abide\", \"acceptable\", \"acceptable\", \"accommodate\", \"accord\", \"account\", \"acs\", \"address\", \"address\", \"advantage\", \"advertise\", \"affordable\", \"ago\", \"ago\", \"airconditioning\", \"allthe\", \"along\", \"also\", \"also\", \"also\", \"anything\", \"anything\", \"appropriate\", \"april\", \"arrangement\", \"arrive\", \"arrive\", \"asap\", \"assistance\", \"attend\", \"attitude\", \"attitude\", \"audit\", \"availability\", \"average\", \"average\", \"babique\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bag\", \"bag\", \"bag\", \"base\", \"base\", \"base\", \"base\", \"bbq\", \"bbq\", \"bean\", \"become\", \"become\", \"best\", \"best\", \"better\", \"better\", \"birthday\", \"bite\", \"bite\", \"bite\", \"bottle\", \"box\", \"box\", \"box\", \"boys\", \"boys\", \"boys\", \"branch\", \"branch\", \"bread\", \"bread\", \"bread\", \"brownish\", \"bubble\", \"bubble\", \"bubble\", \"budget\", \"build\", \"build\", \"build\", \"burn\", \"burn\", \"burn\", \"burst\", \"burst\", \"business\", \"bust\", \"bust\", \"bust\", \"busy\", \"buy\", \"buy\", \"cake\", \"cake\", \"cake\", \"call\", \"call\", \"cancel\", \"capsicum\", \"capsicum\", \"capsicum\", \"careless\", \"cash\", \"category\", \"charge\", \"charge\", \"charge\", \"chat\", \"cheat\", \"cheese\", \"cheese\", \"cheese\", \"cheeseburst\", \"cheez\", \"chicken\", \"chicken\", \"chicken\", \"chicken\", \"chill\", \"chiz\", \"chocolava\", \"chocolava\", \"chowk\", \"claim\", \"claim\", \"class\", \"clean\", \"clean\", \"cleanliness\", \"cleanliness\", \"clearly\", \"clearly\", \"coca\", \"coke\", \"coke\", \"coke\", \"cola\", \"cold\", \"cold\", \"combo\", \"come\", \"come\", \"commit\", \"compromise\", \"condiments\", \"condition\", \"condition\", \"condition\", \"confirmation\", \"connect\", \"connect\", \"constantly\", \"cook\", \"cook\", \"cook\", \"cost\", \"cost\", \"costly\", \"costly\", \"count\", \"coz\", \"crave\", \"crinkle\", \"customer\", \"customer\", \"daughter\", \"dear\", \"degrade\", \"degrade\", \"delay\", \"delay\", \"delievered\", \"deliver\", \"deliver\", \"delivery\", \"delivery\", \"delivery\", \"delivery\", \"deny\", \"deny\", \"deny\", \"differ\", \"differ\", \"difficult\", \"dilevery\", \"dilevery\", \"dim\", \"dine\", \"dine\", \"dine\", \"dirty\", \"dirty\", \"disappoint\", \"disappoint\", \"disastrous\", \"disgust\", \"dislike\", \"doesnt\", \"dominos\", \"dominos\", \"dominos\", \"door\", \"door\", \"doubt\", \"doubt\", \"dry\", \"dry\", \"dry\", \"dry\", \"dry\", \"due\", \"due\", \"due\", \"due\", \"duplicate\", \"eat\", \"eat\", \"eat\", \"effective\", \"either\", \"either\", \"end\", \"end\", \"end\", \"enough\", \"enough\", \"estimate\", \"eve\", \"even\", \"even\", \"even\", \"ever\", \"ever\", \"everytime\", \"everytime\", \"exactly\", \"excellent\", \"exorbitantly\", \"expect\", \"expect\", \"expect\", \"expectations\", \"expensive\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"extra\", \"extremely\", \"extremely\", \"fail\", \"fanta\", \"fast\", \"fast\", \"fiesta\", \"fill\", \"fill\", \"find\", \"find\", \"first\", \"flat\", \"flaxe\", \"fly\", \"follow\", \"follow\", \"follow\", \"fond\", \"fond\", \"food\", \"food\", \"food\", \"form\", \"free\", \"free\", \"freeze\", \"fresh\", \"fresh\", \"freshly\", \"freshness\", \"front\", \"fungus\", \"garlicbread\", \"get\", \"get\", \"get\", \"give\", \"give\", \"glass\", \"go\", \"go\", \"go\", \"golden\", \"gonna\", \"gonna\", \"goodwill\", \"green\", \"green\", \"green\", \"guess\", \"guess\", \"guess\", \"haff\", \"hair\", \"half\", \"half\", \"half\", \"hand\", \"hand\", \"happy\", \"happy\", \"happy\", \"hard\", \"hard\", \"hard\", \"hate\", \"health\", \"hesitate\", \"high\", \"high\", \"high\", \"home\", \"honestly\", \"hopeless\", \"horrible\", \"hospitality\", \"hot\", \"hot\", \"hot\", \"hot\", \"hour\", \"hour\", \"hour\", \"hours\", \"hours\", \"hours\", \"idiot\", \"im\", \"im\", \"incomplete\", \"incomplete\", \"indie\", \"inside\", \"inside\", \"inside\", \"instruction\", \"interest\", \"interest\", \"intimation\", \"investment\", \"irresponsible\", \"irritate\", \"item\", \"item\", \"item\", \"item\", \"items\", \"jalapeno\", \"ketchup\", \"ketchup\", \"ketchup\", \"ketchup\", \"kindly\", \"km\", \"kms\", \"lack\", \"lack\", \"landmark\", \"late\", \"late\", \"late\", \"layer\", \"layer\", \"least\", \"least\", \"least\", \"less\", \"less\", \"less\", \"let\", \"light\", \"like\", \"local\", \"long\", \"long\", \"long\", \"look\", \"look\", \"look\", \"love\", \"love\", \"love\", \"low\", \"low\", \"main\", \"maintain\", \"maintain\", \"make\", \"man\", \"margarita\", \"margarita\", \"margherita\", \"margherita\", \"mark\", \"mark\", \"mark\", \"mark\", \"mark\", \"masala\", \"mayo\", \"meal\", \"meal\", \"meatballs\", \"medium\", \"medium\", \"mention\", \"mention\", \"mention\", \"mention\", \"menu\", \"menu\", \"menu\", \"merely\", \"messy\", \"messy\", \"mexicana\", \"mexicana\", \"min\", \"min\", \"mins\", \"mins\", \"mint\", \"mint\", \"minutes\", \"minutes\", \"minutes\", \"miss\", \"mistakly\", \"mobile\", \"moist\", \"money\", \"money\", \"money\", \"mood\", \"much\", \"much\", \"much\", \"much\", \"multinational\", \"mushroom\", \"myonies\", \"need\", \"never\", \"never\", \"nigadi\", \"non\", \"nonsense\", \"normally\", \"normally\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"occur\", \"okayish\", \"okayokay\", \"one\", \"one\", \"one\", \"onions\", \"online\", \"onwards\", \"onwards\", \"order\", \"order\", \"order\", \"order\", \"order\", \"oregano\", \"outlet\", \"outlets\", \"outlets\", \"overcook\", \"overload\", \"package\", \"package\", \"package\", \"packets\", \"packets\", \"packets\", \"papsi\", \"parathas\", \"parcel\", \"parcel\", \"parcel\", \"park\", \"park\", \"payment\", \"payment\", \"payment\", \"pepsi\", \"pepsi\", \"per\", \"per\", \"per\", \"peri\", \"peri\", \"pick\", \"pickup\", \"pickup\", \"pics\", \"pimple\", \"pizza\", \"pizza\", \"pizza\", \"pizza\", \"pizza\", \"pizza\", \"pizza\", \"pizzas\", \"pizzas\", \"pizzas\", \"pizzas\", \"pizzas\", \"pizzas\", \"place\", \"place\", \"place\", \"place\", \"placement\", \"plaza\", \"please\", \"plz\", \"plz\", \"pm\", \"pm\", \"point\", \"policy\", \"policy\", \"poor\", \"poor\", \"poor\", \"precautions\", \"present\", \"previous\", \"price\", \"price\", \"price\", \"price\", \"pro\", \"probably\", \"prompt\", \"properly\", \"properly\", \"properly\", \"properly\", \"properly\", \"properly\", \"provide\", \"provide\", \"pure\", \"push\", \"quality\", \"quality\", \"quantity\", \"quantity\", \"rainbow\", \"rainy\", \"rat\", \"rat\", \"rat\", \"rat\", \"ready\", \"ready\", \"ready\", \"reason\", \"reason\", \"receive\", \"receive\", \"receive\", \"refund\", \"refund\", \"refund\", \"regular\", \"regular\", \"reheat\", \"reject\", \"report\", \"request\", \"request\", \"request\", \"request\", \"resolution\", \"roadside\", \"roadside\", \"rs\", \"rs\", \"rs\", \"rs\", \"rubber\", \"rubbish\", \"rudely\", \"rudely\", \"rudely\", \"saggy\", \"salty\", \"salty\", \"salty\", \"satisfactory\", \"satisfactory\", \"satisfactory\", \"satisfy\", \"satisfy\", \"satisfy\", \"satisfy\", \"saudagar\", \"say\", \"se\", \"seal\", \"seal\", \"season\", \"season\", \"seem\", \"seem\", \"seem\", \"seem\", \"seem\", \"select\", \"serve\", \"service\", \"service\", \"service\", \"service\", \"service\", \"service\", \"shame\", \"shittiest\", \"short\", \"show\", \"show\", \"size\", \"size\", \"size\", \"slow\", \"slow\", \"sluggish\", \"smaller\", \"smaller\", \"smell\", \"smell\", \"smelly\", \"soft\", \"special\", \"special\", \"special\", \"specially\", \"spicy\", \"spicy\", \"spicy\", \"spicy\", \"st\", \"staff\", \"staff\", \"staff\", \"staff\", \"stale\", \"stale\", \"standard\", \"standard\", \"staple\", \"star\", \"star\", \"status\", \"status\", \"step\", \"stuff\", \"stuff\", \"successful\", \"sunday\", \"super\", \"super\", \"supreme\", \"sure\", \"sure\", \"sweet\", \"taco\", \"taco\", \"take\", \"take\", \"talk\", \"talk\", \"talk\", \"tandoori\", \"taste\", \"taste\", \"taste\", \"taste\", \"taste\", \"tasty\", \"tax\", \"tax\", \"team\", \"temperature\", \"terrible\", \"test\", \"test\", \"thakur\", \"thakur\", \"ther\", \"theres\", \"theres\", \"tight\", \"time\", \"time\", \"toast\", \"top\", \"top\", \"top\", \"toppings\", \"toppings\", \"toss\", \"totally\", \"totally\", \"turn\", \"type\", \"type\", \"un\", \"unbelievable\", \"unbelievable\", \"uncooked\", \"uncooked\", \"uncooked\", \"uncooked\", \"unease\", \"unfortunately\", \"unprofessional\", \"unprofessional\", \"unprofessional\", \"untidy\", \"untidy\", \"update\", \"update\", \"update\", \"update\", \"upper\", \"upto\", \"upto\", \"upto\", \"useless\", \"useless\", \"value\", \"value\", \"veg\", \"veggies\", \"veggies\", \"vety\", \"village\", \"wait\", \"want\", \"washroom\", \"washroom\", \"washrooms\", \"waste\", \"waste\", \"waste\", \"water\", \"weekend\", \"weekend\", \"weekend\", \"weekend\", \"well\", \"well\", \"well\", \"well\", \"whenever\", \"whereas\", \"wheres\", \"wing\", \"without\", \"without\", \"wonder\", \"word\", \"word\", \"worst\", \"worst\", \"worst\", \"worth\", \"worth\", \"wow\", \"wrong\", \"wrong\", \"wrongly\", \"yet\", \"yet\", \"youre\", \"zomato\", \"zomota\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [9, 1, 8, 10, 5, 4, 7, 2, 6, 3]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el581404381460986406078091618\", ldavis_el581404381460986406078091618_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el581404381460986406078091618\", ldavis_el581404381460986406078091618_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el581404381460986406078091618\", ldavis_el581404381460986406078091618_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pyLDAvis for tfidf \n",
        "import pyLDAvis\n",
        "import pyLDAvis.sklearn\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "pyLDAvis.sklearn.prepare(lda_tfidf,tfidf_,train_vectorizer)\n",
        "#pyLDAvis.save_html(lda,'topics_vis.html')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "id": "BuREJI9bIy_5",
        "outputId": "795bb505-f76c-43ef-cf08-c20df417282a"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "8     -0.253726 -0.058375       1        1  48.624780\n",
              "0     -0.098499  0.118467       2        1   8.465994\n",
              "7      0.016243 -0.071329       3        1   6.217631\n",
              "6      0.033561 -0.021041       4        1   6.122645\n",
              "9      0.080480 -0.013153       5        1   5.867971\n",
              "4      0.049325 -0.001451       6        1   5.862001\n",
              "3      0.045089 -0.035008       7        1   5.769752\n",
              "5      0.020512  0.089413       8        1   4.725400\n",
              "1      0.053636 -0.006196       9        1   4.375957\n",
              "2      0.053378 -0.001325      10        1   3.967868, topic_info=          Term       Freq      Total Category  logprob  loglift\n",
              "1018      late  35.000000  35.000000  Default  30.0000  30.0000\n",
              "486   delivery  36.000000  36.000000  Default  29.0000  29.0000\n",
              "484    deliver  33.000000  33.000000  Default  28.0000  28.0000\n",
              "1291     order  54.000000  54.000000  Default  27.0000  27.0000\n",
              "1900      time  28.000000  28.000000  Default  26.0000  26.0000\n",
              "...        ...        ...        ...      ...      ...      ...\n",
              "558        dry   0.490728   3.686535  Topic10  -5.6574   1.2104\n",
              "1462  properly   0.604142   8.526214  Topic10  -5.4495   0.5799\n",
              "1599        rs   0.377799   2.337937  Topic10  -5.9189   1.4043\n",
              "1320   packets   0.349271   1.497568  Topic10  -5.9974   1.7712\n",
              "1643    season   0.368982   4.134279  Topic10  -5.9425   0.8106\n",
              "\n",
              "[511 rows x 6 columns], token_table=      Topic      Freq            Term\n",
              "term                                 \n",
              "9         6  0.649836      acceptable\n",
              "15        4  0.995580             acs\n",
              "21        1  0.385844         address\n",
              "21        7  0.385844         address\n",
              "26        9  0.948707       advertise\n",
              "46        5  0.874375           along\n",
              "48        1  0.908740            also\n",
              "72        2  0.680820        anything\n",
              "100       7  0.938703     arrangement\n",
              "102       1  0.736241          arrive\n",
              "102       5  0.368121          arrive\n",
              "120       5  0.514221        attitude\n",
              "131       4  0.843116    availability\n",
              "133       1  0.694905         average\n",
              "133      10  0.347453         average\n",
              "145       1  0.516511             bad\n",
              "145       2  0.086085             bad\n",
              "145       3  0.301298             bad\n",
              "145       4  0.043043             bad\n",
              "145       9  0.043043             bad\n",
              "147       2  0.622277             bag\n",
              "158       3  0.669321            base\n",
              "158       4  0.167330            base\n",
              "158       5  0.167330            base\n",
              "169       1  0.560373          become\n",
              "169       8  0.560373          become\n",
              "180       1  0.725113            best\n",
              "180       5  0.362556            best\n",
              "181       1  0.834754          better\n",
              "192       1  0.561899            bite\n",
              "192       4  0.374599            bite\n",
              "210       7  0.558751          bottle\n",
              "213       1  0.546431             box\n",
              "213       4  0.273216             box\n",
              "217       1  0.639617          branch\n",
              "220       1  0.843206           bread\n",
              "220       5  0.105401           bread\n",
              "242       2  0.400936            burn\n",
              "242       5  0.400936            burn\n",
              "243       1  0.923761           burst\n",
              "243       3  0.071059           burst\n",
              "244       5  0.840108        business\n",
              "245       4  0.578810            bust\n",
              "248       6  0.647207             buy\n",
              "250       1  0.672490            cake\n",
              "250       6  0.336245            cake\n",
              "251       1  0.962655            call\n",
              "253       1  0.993127          cancel\n",
              "259       7  0.695899        capsicum\n",
              "284       5  0.375352          charge\n",
              "284       7  0.375352          charge\n",
              "286       3  0.650306            chat\n",
              "289       9  0.778748           cheat\n",
              "291       1  0.793994          cheese\n",
              "291       3  0.158799          cheese\n",
              "291       4  0.031760          cheese\n",
              "292       5  0.637309     cheeseburst\n",
              "294       5  0.617535           cheez\n",
              "299       1  0.540978         chicken\n",
              "299       3  0.135244         chicken\n",
              "299       4  0.135244         chicken\n",
              "299       6  0.135244         chicken\n",
              "313       6  0.685157       chocolava\n",
              "321       1  0.419656           claim\n",
              "321       4  0.419656           claim\n",
              "323       1  0.629154           clean\n",
              "323       6  0.314577           clean\n",
              "324       7  0.700267     cleanliness\n",
              "327       5  0.696792         clearly\n",
              "338       7  0.697352            coke\n",
              "340       1  0.459269            cold\n",
              "340       2  0.516678            cold\n",
              "346       3  0.889902           combo\n",
              "347       1  0.927115            come\n",
              "352       2  0.815679          commit\n",
              "371       5  0.833596      compromise\n",
              "375       1  0.648492       condition\n",
              "375       9  0.324246       condition\n",
              "380       6  0.822126    confirmation\n",
              "404       1  0.606872            cook\n",
              "404       4  0.202291            cook\n",
              "404      10  0.202291            cook\n",
              "412       7  0.566653            cost\n",
              "413       4  0.600032          costly\n",
              "416       5  0.988591           count\n",
              "428       7  0.611839             coz\n",
              "448       1  0.767904        customer\n",
              "448       5  0.153581        customer\n",
              "457       2  0.995623        daughter\n",
              "480       1  0.325037           delay\n",
              "480       4  0.650074           delay\n",
              "482       2  0.597112      delievered\n",
              "484       1  0.565068         deliver\n",
              "484       2  0.416366         deliver\n",
              "486       1  0.492349        delivery\n",
              "486       2  0.136764        delivery\n",
              "486       4  0.082058        delivery\n",
              "486       8  0.273527        delivery\n",
              "490       7  0.606036            deny\n",
              "506       2  0.976199       difficult\n",
              "518       4  0.652958           dirty\n",
              "519       1  0.948672      disappoint\n",
              "524       1  0.579252        discount\n",
              "524       5  0.579252        discount\n",
              "527       6  0.731465         disgust\n",
              "538       1  0.998636          doesnt\n",
              "544       1  0.927231         dominos\n",
              "544       6  0.037089         dominos\n",
              "544       7  0.037089         dominos\n",
              "545       9  0.786595            door\n",
              "558       8  0.542515             dry\n",
              "559       2  0.406113             due\n",
              "569       1  0.727212             eat\n",
              "569       4  0.242404             eat\n",
              "580       6  0.635281          either\n",
              "588       5  0.527067             end\n",
              "590       1  0.593525          enough\n",
              "590      10  0.296762          enough\n",
              "606       2  0.704452        estimate\n",
              "611       1  0.897443            even\n",
              "612       1  0.604100            ever\n",
              "612       7  0.241640            ever\n",
              "619       5  0.686469       everytime\n",
              "621       8  0.874621         exactly\n",
              "623       6  0.796045       excellent\n",
              "633       1  0.925751          expect\n",
              "636       5  0.747755       expensive\n",
              "637       1  0.670258      experience\n",
              "637       3  0.121865      experience\n",
              "637       7  0.121865      experience\n",
              "644       1  0.996466           extra\n",
              "646       1  0.695433       extremely\n",
              "646       8  0.231811       extremely\n",
              "666       2  0.701387            fast\n",
              "681       1  0.508650            fill\n",
              "681       3  0.508650            fill\n",
              "684       1  0.614972            find\n",
              "684       6  0.307486            find\n",
              "690       1  0.919472           first\n",
              "696      10  0.894810            flat\n",
              "711       1  0.663872            food\n",
              "711       2  0.221291            food\n",
              "711       3  0.110645            food\n",
              "720       5  0.977101            form\n",
              "735       1  0.525851            free\n",
              "735       2  0.525851            free\n",
              "740       1  0.455001           fresh\n",
              "740       3  0.455001           fresh\n",
              "748       7  0.867157           front\n",
              "771       1  0.729259             get\n",
              "771       2  0.227893             get\n",
              "771       6  0.045579             get\n",
              "776       1  0.891379            give\n",
              "776       2  0.074282            give\n",
              "777       7  0.928988           glass\n",
              "785       1  0.637449           gonna\n",
              "796       9  0.648656           green\n",
              "812       6  0.966929            hair\n",
              "813       1  0.448849            half\n",
              "813       2  0.149616            half\n",
              "813       4  0.149616            half\n",
              "815       9  0.537418            hand\n",
              "823       3  0.467806           happy\n",
              "824       3  0.604889            hard\n",
              "830       6  0.936338            hate\n",
              "833       6  0.860580          health\n",
              "853       1  0.370872            high\n",
              "853       7  0.370872            high\n",
              "864       1  0.982831            home\n",
              "872       1  0.917857        horrible\n",
              "876       1  0.602433             hot\n",
              "876       2  0.200811             hot\n",
              "876       4  0.100405             hot\n",
              "878       1  0.817714            hour\n",
              "878       2  0.090857            hour\n",
              "878       4  0.090857            hour\n",
              "879       1  0.734434           hours\n",
              "879       5  0.183608           hours\n",
              "879       8  0.183608           hours\n",
              "904       1  0.719839              im\n",
              "917       7  0.604796      incomplete\n",
              "937       1  0.386482          inside\n",
              "937       4  0.386482          inside\n",
              "952       5  0.941716      intimation\n",
              "959       5  0.903989   irresponsible\n",
              "965       9  0.454595            item\n",
              "966       5  0.642314           items\n",
              "995       2  0.553340         ketchup\n",
              "995       4  0.276670         ketchup\n",
              "1003      2  0.636481              km\n",
              "1010      1  0.605636            lack\n",
              "1010      7  0.605636            lack\n",
              "1018      1  0.138957            late\n",
              "1018      2  0.305706            late\n",
              "1018      8  0.528037            late\n",
              "1027      7  0.612906           least\n",
              "1030      1  0.497345            less\n",
              "1030      3  0.426295            less\n",
              "1033      8  0.843581             let\n",
              "1040      1  0.946713            like\n",
              "1053      4  0.931515           local\n",
              "1059      2  0.321287            long\n",
              "1059     10  0.321287            long\n",
              "1061      1  0.725546            look\n",
              "1061      7  0.181387            look\n",
              "1070      4  0.441522            love\n",
              "1074      6  0.538873             low\n",
              "1084      5  0.666751        maintain\n",
              "1087      1  0.936152            make\n",
              "1102      1  0.541348       margarita\n",
              "1102      4  0.270674       margarita\n",
              "1104      1  0.329005            mark\n",
              "1104      4  0.164503            mark\n",
              "1104      5  0.164503            mark\n",
              "1104      9  0.164503            mark\n",
              "1124      1  0.773571          medium\n",
              "1124      6  0.386785          medium\n",
              "1133      7  0.555534            menu\n",
              "1137      3  0.753574           messy\n",
              "1140      1  0.536319        mexicana\n",
              "1140     10  0.536319        mexicana\n",
              "1146      1  0.255864             min\n",
              "1146      2  0.639659             min\n",
              "1151      1  0.590427            mins\n",
              "1151      2  0.393618            mins\n",
              "1155      1  0.803442         minutes\n",
              "1163      1  0.838498            miss\n",
              "1172      1  0.658631           money\n",
              "1172      2  0.109772           money\n",
              "1172      6  0.219544           money\n",
              "1175      3  0.737281            mood\n",
              "1189      1  0.610363            much\n",
              "1189      3  0.244145            much\n",
              "1194      5  0.760118        mushroom\n",
              "1197      4  0.844499         myonies\n",
              "1207      1  0.926331            need\n",
              "1219      1  0.929317           never\n",
              "1234      1  0.993374             non\n",
              "1240      4  0.759045        normally\n",
              "1242      4  0.381130         nothing\n",
              "1272      1  0.945525             one\n",
              "1276      1  0.949222          online\n",
              "1291      1  0.785171           order\n",
              "1291      2  0.164338           order\n",
              "1291      6  0.018260           order\n",
              "1291      8  0.036520           order\n",
              "1296      1  0.875243         oregano\n",
              "1304      1  0.960489          outlet\n",
              "1305      1  0.563987         outlets\n",
              "1305      7  0.281994         outlets\n",
              "1310      6  0.754958        overcook\n",
              "1318      2  0.607488         package\n",
              "1328      4  0.929289           papsi\n",
              "1331      5  0.354112          parcel\n",
              "1331      6  0.708224          parcel\n",
              "1333      4  0.428459            park\n",
              "1333      7  0.428459            park\n",
              "1364      6  0.773258             per\n",
              "1367     10  0.600216            peri\n",
              "1379      1  0.884271            pick\n",
              "1384      9  0.831288          pimple\n",
              "1388      1  0.732134           pizza\n",
              "1388      2  0.150181           pizza\n",
              "1388      3  0.037545           pizza\n",
              "1388      4  0.018773           pizza\n",
              "1388      6  0.018773           pizza\n",
              "1388      7  0.018773           pizza\n",
              "1391      1  0.790827          pizzas\n",
              "1391      4  0.087870          pizzas\n",
              "1393      1  0.869851           place\n",
              "1393      4  0.066912           place\n",
              "1393      6  0.066912           place\n",
              "1401      7  0.742860           plaza\n",
              "1402      1  0.943401          please\n",
              "1404      1  0.504823             plz\n",
              "1404      2  0.504823             plz\n",
              "1405      1  0.579297              pm\n",
              "1405      2  0.386198              pm\n",
              "1408      5  0.762021           point\n",
              "1411      6  0.710047          policy\n",
              "1414      1  0.659405            poor\n",
              "1414      2  0.109901            poor\n",
              "1414      7  0.219802            poor\n",
              "1439      8  0.858396         present\n",
              "1444      1  0.567920           price\n",
              "1444      3  0.283960           price\n",
              "1444      5  0.283960           price\n",
              "1462      1  0.820997        properly\n",
              "1462     10  0.117285        properly\n",
              "1468      1  0.893864         provide\n",
              "1477      1  0.670973         quality\n",
              "1477      3  0.268389         quality\n",
              "1479      1  0.378666        quantity\n",
              "1479      3  0.378666        quantity\n",
              "1491      7  0.887940         rainbow\n",
              "1496      6  0.518666             rat\n",
              "1512      5  0.485726          reason\n",
              "1515      1  0.581040         receive\n",
              "1515      2  0.290520         receive\n",
              "1515      8  0.096840         receive\n",
              "1526      1  0.910086          refund\n",
              "1531      1  0.704128         regular\n",
              "1531      6  0.234709         regular\n",
              "1554      5  0.894467          report\n",
              "1558      5  0.576043         request\n",
              "1599      2  0.427727              rs\n",
              "1599      5  0.427727              rs\n",
              "1601      5  0.762463         rubbish\n",
              "1603      5  0.595251          rudely\n",
              "1611     10  0.958036           saggy\n",
              "1616      1  0.542592           salty\n",
              "1616     10  0.542592           salty\n",
              "1621      9  0.595208    satisfactory\n",
              "1622      6  0.454917         satisfy\n",
              "1624      9  0.831288        saudagar\n",
              "1629      1  0.987680             say\n",
              "1641     10  0.646976            seal\n",
              "1643      1  0.725640          season\n",
              "1650      4  0.382518            seem\n",
              "1650      7  0.382518            seem\n",
              "1665      1  0.975735           serve\n",
              "1668      1  0.677374         service\n",
              "1668      2  0.079691         service\n",
              "1668      6  0.039846         service\n",
              "1668      7  0.079691         service\n",
              "1668      9  0.119537         service\n",
              "1672      6  0.775592           shame\n",
              "1681      6  0.929224       shittiest\n",
              "1686     10  0.899966           short\n",
              "1691      1  0.721894            show\n",
              "1691      2  0.240631            show\n",
              "1711      1  0.529365            size\n",
              "1711      6  0.264683            size\n",
              "1719      1  0.411696            slow\n",
              "1719      4  0.617545            slow\n",
              "1724      6  0.713956         smaller\n",
              "1726      4  0.489143           smell\n",
              "1764      8  0.603885           spicy\n",
              "1769      3  0.895667              st\n",
              "1770      1  0.744705           staff\n",
              "1770      7  0.093088           staff\n",
              "1771      1  0.635625           stale\n",
              "1771      4  0.317812           stale\n",
              "1773      5  0.624823        standard\n",
              "1778      1  0.787794            star\n",
              "1778      3  0.262598            star\n",
              "1786      9  0.946550            step\n",
              "1799      1  0.529161           stuff\n",
              "1799      5  0.529161           stuff\n",
              "1817      5  0.711071           super\n",
              "1822      4  0.800224            sure\n",
              "1836      1  0.602999            taco\n",
              "1836      6  0.301499            taco\n",
              "1839      1  0.879981            take\n",
              "1839      2  0.073332            take\n",
              "1843      1  0.377463            talk\n",
              "1843      7  0.377463            talk\n",
              "1847      1  0.851980           taste\n",
              "1847      2  0.053249           taste\n",
              "1847      6  0.053249           taste\n",
              "1849      3  0.676881           tasty\n",
              "1850      3  0.693501             tax\n",
              "1854      5  0.761241            team\n",
              "1864      4  0.945261        terrible\n",
              "1865      2  0.518667            test\n",
              "1865      4  0.518667            test\n",
              "1873     10  0.652568          theres\n",
              "1900      1  0.660836            time\n",
              "1900      2  0.313028            time\n",
              "1919      1  0.565753             top\n",
              "1919      3  0.282877             top\n",
              "1919      4  0.141438             top\n",
              "1920      1  0.669501        toppings\n",
              "1920      3  0.223167        toppings\n",
              "1921      9  0.984763            toss\n",
              "1923      1  0.629900         totally\n",
              "1923      2  0.209967         totally\n",
              "1946      4  0.755848            type\n",
              "1958      4  0.453160        uncooked\n",
              "1980      2  0.599364  unprofessional\n",
              "1985      5  0.817963          untidy\n",
              "1989      9  0.507370          update\n",
              "1995      4  0.719754            upto\n",
              "1995      5  0.359877            upto\n",
              "2009      7  0.689881           value\n",
              "2015      1  0.919033             veg\n",
              "2021      3  0.813930         veggies\n",
              "2041      1  0.917917            wait\n",
              "2048      1  0.887930            want\n",
              "2052      1  0.602007        washroom\n",
              "2052      7  0.602007        washroom\n",
              "2055      1  0.583960           waste\n",
              "2055      2  0.194653           waste\n",
              "2055      6  0.389307           waste\n",
              "2058      7  0.653698           water\n",
              "2068     10  0.586449         weekend\n",
              "2069      1  0.722008            well\n",
              "2069      3  0.180502            well\n",
              "2076      6  0.924644         whereas\n",
              "2078      4  0.971564          wheres\n",
              "2086      2  0.847876            wing\n",
              "2090      1  0.774046         without\n",
              "2090      2  0.193512         without\n",
              "2094      6  0.997152          wonder\n",
              "2101      1  0.601109           worst\n",
              "2101      2  0.050092           worst\n",
              "2101      7  0.300554           worst\n",
              "2102      1  0.519343           worth\n",
              "2102      6  0.259672           worth\n",
              "2109      1  0.416015           wrong\n",
              "2109      2  0.554687           wrong\n",
              "2121      8  0.597972             yet\n",
              "2128      1  0.919161          zomato, R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[9, 1, 8, 7, 10, 5, 4, 6, 2, 3])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el581404381119939364304158226\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el581404381119939364304158226_data = {\"mdsDat\": {\"x\": [-0.25372553207508775, -0.09849872134793612, 0.016243479518998488, 0.033561210838525174, 0.080479568577891, 0.04932482624923029, 0.045089010462477444, 0.020512375112735026, 0.05363598135819103, 0.05337780130497555], \"y\": [-0.05837512677570362, 0.11846668546184412, -0.07132945832106133, -0.021041230582510673, -0.013153404921227456, -0.0014510423260995385, -0.035008441534130456, 0.08941319789307849, -0.006195682280133742, -0.0013254966140557316], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [48.624780208257405, 8.465994351765332, 6.217630903270466, 6.122645100201784, 5.867970903602474, 5.86200107172326, 5.7697520492452545, 4.72540042512761, 4.375956928671069, 3.9678680581353496]}, \"tinfo\": {\"Term\": [\"late\", \"delivery\", \"deliver\", \"order\", \"time\", \"worst\", \"cheese\", \"cold\", \"less\", \"bad\", \"service\", \"receive\", \"pizza\", \"quality\", \"delay\", \"get\", \"food\", \"min\", \"experience\", \"ever\", \"mins\", \"wrong\", \"toppings\", \"poor\", \"base\", \"eat\", \"slow\", \"much\", \"money\", \"mark\", \"like\", \"outlet\", \"zomato\", \"call\", \"disappoint\", \"wait\", \"say\", \"veg\", \"make\", \"home\", \"dominos\", \"oregano\", \"want\", \"horrible\", \"need\", \"please\", \"never\", \"cancel\", \"one\", \"miss\", \"burst\", \"even\", \"pick\", \"first\", \"online\", \"serve\", \"non\", \"extra\", \"also\", \"doesnt\", \"better\", \"expect\", \"give\", \"provide\", \"take\", \"order\", \"place\", \"taste\", \"cheese\", \"pizza\", \"refund\", \"get\", \"time\", \"service\", \"deliver\", \"pizzas\", \"experience\", \"food\", \"delivery\", \"worst\", \"receive\", \"quality\", \"bad\", \"delievered\", \"km\", \"min\", \"estimate\", \"ketchup\", \"commit\", \"wrong\", \"anything\", \"cold\", \"difficult\", \"daughter\", \"village\", \"dislike\", \"allthe\", \"chill\", \"wrongly\", \"constantly\", \"fast\", \"wing\", \"crinkle\", \"sunday\", \"free\", \"deliver\", \"bag\", \"unprofessional\", \"se\", \"kms\", \"unease\", \"thakur\", \"pm\", \"long\", \"mins\", \"late\", \"time\", \"receive\", \"due\", \"plz\", \"get\", \"food\", \"order\", \"pizza\", \"delivery\", \"hot\", \"show\", \"half\", \"without\", \"totally\", \"service\", \"bad\", \"taste\", \"take\", \"give\", \"hour\", \"tasty\", \"mood\", \"base\", \"chat\", \"happy\", \"combo\", \"honestly\", \"brownish\", \"account\", \"st\", \"less\", \"reheat\", \"kindly\", \"fly\", \"okayish\", \"rainy\", \"fail\", \"fresh\", \"veggies\", \"tax\", \"condiments\", \"fiesta\", \"onions\", \"messy\", \"freeze\", \"parathas\", \"roadside\", \"freshly\", \"busy\", \"audit\", \"fill\", \"asap\", \"bad\", \"quality\", \"quantity\", \"much\", \"toppings\", \"top\", \"cheese\", \"experience\", \"well\", \"food\", \"star\", \"pizza\", \"hard\", \"chicken\", \"payment\", \"burst\", \"price\", \"smell\", \"delay\", \"dirty\", \"myonies\", \"costly\", \"park\", \"upto\", \"slow\", \"papsi\", \"local\", \"bust\", \"terrible\", \"sure\", \"wheres\", \"type\", \"availability\", \"acs\", \"zomota\", \"test\", \"expectations\", \"rubber\", \"okayokay\", \"upper\", \"multinational\", \"ther\", \"previous\", \"love\", \"probably\", \"normally\", \"hospitality\", \"margarita\", \"inside\", \"claim\", \"bite\", \"eat\", \"stale\", \"nothing\", \"uncooked\", \"box\", \"half\", \"delivery\", \"mark\", \"base\", \"hot\", \"cook\", \"hour\", \"pizza\", \"bad\", \"cheese\", \"pizzas\", \"chicken\", \"expensive\", \"along\", \"cheez\", \"items\", \"cheeseburst\", \"mushroom\", \"rubbish\", \"maintain\", \"team\", \"report\", \"business\", \"irresponsible\", \"standard\", \"everytime\", \"intimation\", \"point\", \"form\", \"count\", \"reason\", \"turn\", \"youre\", \"affordable\", \"pics\", \"mayo\", \"attitude\", \"specially\", \"stuff\", \"burn\", \"prompt\", \"justify\", \"untidy\", \"end\", \"clearly\", \"compromise\", \"super\", \"rudely\", \"best\", \"request\", \"customer\", \"arrive\", \"bread\", \"upto\", \"base\", \"discount\", \"charge\", \"hours\", \"hate\", \"overcook\", \"shame\", \"per\", \"low\", \"health\", \"whereas\", \"parcel\", \"shittiest\", \"hair\", \"chocolava\", \"satisfy\", \"wonder\", \"excellent\", \"overload\", \"sluggish\", \"disgust\", \"rat\", \"indie\", \"confirmation\", \"either\", \"fungus\", \"staple\", \"word\", \"policy\", \"tandoori\", \"smaller\", \"whenever\", \"duplicate\", \"advantage\", \"worth\", \"onwards\", \"waste\", \"size\", \"buy\", \"money\", \"acceptable\", \"chicken\", \"taco\", \"cake\", \"pizza\", \"medium\", \"regular\", \"clean\", \"find\", \"dominos\", \"taste\", \"place\", \"water\", \"bottle\", \"coz\", \"plaza\", \"cost\", \"coke\", \"rainbow\", \"incomplete\", \"glass\", \"arrangement\", \"menu\", \"charge\", \"front\", \"hopeless\", \"sweet\", \"cleanliness\", \"nigadi\", \"least\", \"main\", \"jalapeno\", \"chiz\", \"high\", \"careless\", \"exorbitantly\", \"lack\", \"assistance\", \"bean\", \"deny\", \"soft\", \"idiot\", \"worst\", \"ever\", \"value\", \"poor\", \"washroom\", \"talk\", \"capsicum\", \"meal\", \"address\", \"staff\", \"service\", \"experience\", \"seem\", \"outlets\", \"look\", \"pizza\", \"dominos\", \"yet\", \"present\", \"exactly\", \"late\", \"dry\", \"let\", \"dilevery\", \"chowk\", \"differ\", \"supreme\", \"smelly\", \"spicy\", \"april\", \"appropriate\", \"wow\", \"become\", \"unbelievable\", \"budget\", \"tight\", \"toast\", \"goodwill\", \"merely\", \"garlicbread\", \"reject\", \"crave\", \"landmark\", \"occur\", \"status\", \"birthday\", \"babique\", \"delivery\", \"boys\", \"extremely\", \"receive\", \"order\", \"hours\", \"guess\", \"come\", \"per\", \"parcel\", \"refund\", \"minutes\", \"pizza\", \"item\", \"pimple\", \"saudagar\", \"step\", \"advertise\", \"toss\", \"hand\", \"update\", \"satisfactory\", \"washrooms\", \"pure\", \"haff\", \"cheat\", \"placement\", \"successful\", \"door\", \"select\", \"coca\", \"cola\", \"fanta\", \"moist\", \"pepsi\", \"hesitate\", \"fond\", \"resolution\", \"category\", \"green\", \"abide\", \"pickup\", \"accord\", \"cash\", \"bbq\", \"mark\", \"service\", \"layer\", \"package\", \"mint\", \"bad\", \"bubble\", \"condition\", \"mention\", \"nothing\", \"branch\", \"im\", \"saggy\", \"flat\", \"meatballs\", \"attend\", \"short\", \"peri\", \"freshness\", \"doubt\", \"masala\", \"accommodate\", \"irritate\", \"seal\", \"theres\", \"pro\", \"instruction\", \"flaxe\", \"man\", \"mistakly\", \"investment\", \"eve\", \"class\", \"golden\", \"special\", \"vety\", \"un\", \"nonsense\", \"dim\", \"light\", \"precautions\", \"grab\", \"long\", \"weekend\", \"salty\", \"connect\", \"mexicana\", \"tax\", \"cook\", \"gonna\", \"average\", \"useless\", \"enough\", \"build\", \"dry\", \"properly\", \"rs\", \"packets\", \"season\"], \"Freq\": [35.0, 36.0, 33.0, 54.0, 28.0, 19.0, 31.0, 17.0, 14.0, 23.0, 25.0, 20.0, 53.0, 14.0, 9.0, 21.0, 18.0, 7.0, 16.0, 8.0, 10.0, 7.0, 8.0, 9.0, 5.0, 8.0, 4.0, 8.0, 9.0, 6.0, 12.191535033196178, 10.968601665410787, 10.395571312886629, 12.882950920422628, 12.026839127874462, 9.320927539458609, 8.628372196273224, 8.220905874549496, 6.993501063852286, 6.638397986938622, 25.068602594029493, 6.3713753996835845, 6.273400010006853, 6.0530762798779865, 5.993279186414052, 5.8760812394012385, 7.941785421912712, 5.5576416290823465, 10.701179595113368, 5.47914702955008, 12.914947436153216, 11.20858700906283, 5.170491835141781, 4.954010751927917, 4.783577151287376, 4.640448941812012, 4.549460243704245, 4.533856893848403, 11.929541330980523, 4.52294895701755, 6.479303592024004, 6.803153918188108, 11.929271706266782, 6.021634698571675, 11.77056795364944, 43.03429398530263, 12.699174099476167, 15.689282666389754, 24.717091818004093, 38.68326172664729, 8.585450422100745, 15.988597161593502, 19.277141070223433, 16.68430689150445, 19.068075080313704, 8.986430602367838, 11.47131091788493, 11.741015928742875, 17.949455601878114, 12.302586732632793, 12.482394736099554, 10.203329709776526, 11.705353770963324, 1.1739633322954186, 1.0703387053828024, 5.186837918054387, 0.9187528464947531, 2.2732251053266332, 0.725223323875394, 4.065366954641485, 0.7909377865181382, 9.186055879751658, 0.5235425066382196, 0.5036234779998993, 0.49585584830719626, 0.4806848090110484, 0.4541407281415416, 0.43738403901914086, 0.39933159059375284, 0.3930748737127449, 0.623635524123148, 0.5070146577465316, 0.37696502479604943, 0.3665285145138939, 1.6028540455653062, 14.129749205479811, 0.6624635197744086, 0.6856010234598007, 0.41085737985092263, 0.34301796527017436, 0.34231730579010405, 0.4693555191495437, 2.1014363845052206, 1.2050779303030001, 3.537627763685195, 11.125176539445425, 9.047904473375793, 6.212067243550568, 0.9340496701901271, 0.7584967862200385, 4.944887772222837, 3.9434068010512893, 8.857488562615544, 8.16906660959033, 5.4452083014294335, 2.243706183457398, 1.1087374543171244, 1.2624708245129705, 1.0813190346846884, 1.0233055559286535, 1.7225504949331223, 1.6413315680646834, 1.4742698896534374, 1.3352241132937657, 1.1066138951190603, 1.0191673477456533, 2.4517615019807244, 0.8533935542959858, 3.571545248035565, 0.8767430594484005, 1.0916058089200684, 0.5433990473319918, 0.4619661864765107, 0.4438277211472445, 0.43864362302097215, 0.5127586668732586, 6.351020775670363, 0.409231461080369, 0.40379604702601857, 0.3801491100038561, 0.37838390841714903, 0.37763030554460253, 0.4403635858996704, 1.8602850272562184, 0.5109698089332484, 0.5843674533751848, 0.3421358650598849, 0.3385026708205544, 0.3385026708205544, 0.5327327319993249, 0.32570337854097536, 0.32570337854097536, 0.4048567890556237, 0.3145404618624802, 0.41531189565836774, 0.30252586434228207, 0.7315670479045625, 0.45894468997138277, 6.842429544565899, 4.177231388197596, 0.88402596305826, 2.1264399025975362, 2.136260631197825, 1.7615869575968275, 5.159494516238351, 2.402081549790483, 1.0985474102885677, 2.0202389873670517, 0.7510500949091748, 2.1226063260072543, 0.5074154373084477, 0.7916163420191167, 0.4943172312297245, 0.729382479366929, 0.5062938937994389, 1.2756043573314289, 5.517273803345748, 0.9016004100678388, 0.6809650828428746, 0.9524556279267409, 1.3244762759664637, 1.5135552868008977, 2.6271076305116354, 0.5729318785929657, 0.5703182665834714, 0.916947646007594, 0.5547228480198694, 0.6433519509162962, 0.5261080762652095, 0.6687569693670534, 0.5922598074720258, 0.5012550183692659, 0.46110446408809636, 0.9177064231640236, 0.4512210210227982, 0.450113602209202, 0.44112896614807634, 0.4676378000408332, 0.4360216028947848, 0.4360216028947848, 0.4799155118302617, 1.0292479913771946, 0.4106557977076334, 0.584364786469063, 0.397699807205194, 1.4901553110182326, 1.0670276311800944, 0.9566401132524072, 1.7254790578521846, 2.0089895845599264, 0.9847370753086248, 0.861907072008422, 0.7688655970748367, 1.0502032222705715, 1.4135191107219995, 3.073061782857407, 1.1888457781899442, 1.0593710000605363, 1.2160764244512852, 0.8561959198887847, 1.0510361835495565, 1.3235942590964414, 1.1043638495898151, 1.1583353323639287, 0.860867768508843, 0.784741180536154, 2.17249426890977, 1.785120199327984, 1.1171317440517887, 1.0546845291306546, 0.9998746610749737, 0.8133669533055422, 0.8093498907082269, 0.8928915430477505, 0.7518431124709133, 0.6157983693271657, 0.6530091314363297, 0.6040178110629294, 0.87051979649357, 0.7832235145418764, 0.559679033023875, 0.6790043122358718, 0.5210915501084582, 0.5093324455584731, 1.0222887606429993, 0.47086364755781596, 0.4644514630065931, 0.4607882032264046, 0.45507389327508185, 0.4466512205649696, 0.9112882662052518, 0.44259149814936866, 1.7655914455650792, 1.1584135091821584, 0.43069005023721324, 0.42178656624182337, 0.554401366096643, 0.8096383142565201, 0.6253486044796737, 0.5304478265234214, 0.5906132342958929, 0.6321258223334806, 0.7740831968433987, 0.6168432590065306, 1.0524809487936535, 0.7102859882479131, 1.0425581381193496, 0.686743631149363, 0.78453512409536, 0.6012133641211362, 0.615695626325942, 0.6096509545788534, 1.6333779452115627, 0.8219889838042396, 0.7866998810240504, 1.5344340733407207, 1.0945803134783416, 0.6593849010186713, 0.5788379854378202, 1.5095910377915356, 0.5735804822811998, 0.5316154192393198, 0.7440726849051693, 1.110056603968279, 0.5002608881675745, 0.6121068273908488, 0.47237270804118664, 0.44872847599888516, 0.6412562111177915, 0.8675306111727605, 0.48523058968496424, 0.5374655874351426, 0.6943991977295835, 0.3821056736307095, 0.3821056736307095, 0.49709586024974867, 0.5973421089324228, 0.36083876511029517, 0.585229360377016, 0.35980485347564906, 0.35560158580691037, 0.3453973150847353, 1.4774415594066186, 0.44093924380988664, 1.598039669522319, 1.2281425587562123, 0.5541439240967071, 1.705551632553557, 0.5373032013421751, 1.3164848510217164, 0.7982922943769724, 0.7532818151145235, 1.4782140223654952, 0.6244490430763117, 0.6975636692954513, 0.6306689307415605, 0.5904558074059256, 0.6881900418064052, 0.627291770389913, 0.5802255146905094, 2.4492037640408957, 1.2863236765621298, 1.0585049517944438, 0.8428140425710378, 1.0125473577311948, 1.6219975378922429, 0.6228811217733174, 0.8813583816930135, 0.5731087049393482, 0.5619789047956846, 0.9068651382130899, 1.32633578610792, 0.5692434527414533, 0.45869215843877087, 0.4223114388591158, 0.6494010691950776, 0.4129024084179514, 0.731810713959148, 0.40733012496142834, 0.4025320407194641, 0.40151514901033925, 1.1890086400948234, 0.38715995256104324, 0.377586627799222, 0.7073650577016452, 0.36283778947473855, 0.36165654695318894, 0.6887775346771774, 0.44198337695029066, 0.3545251413670445, 6.371456970404799, 2.3937621850141704, 0.5470335214522245, 2.0112414873338325, 0.5869546604090536, 0.7805674746806932, 0.5318469576280012, 0.49773567247346673, 0.7149395350842271, 1.4791679145914935, 2.1684294345907973, 1.5173688652376691, 0.6751804628561163, 0.6346479283960699, 0.6736792120025196, 0.8446626659146085, 0.7301750302489098, 2.4802863711009495, 0.6563391696626057, 0.634762129279893, 19.015709885011823, 1.8385153902279416, 0.5237497101250875, 0.4882889056889186, 0.3814028312732116, 0.4462175543023318, 0.36253483748058446, 0.35164553242753477, 0.6667407924089981, 0.3294044245321161, 0.31438561964213785, 0.3119373039969645, 0.6760614225472453, 0.36601018284909625, 0.29843913505205144, 0.29843913505205144, 0.2953146021204677, 0.2939688063850248, 0.2939688063850248, 0.2884937602368096, 0.2884937602368096, 0.38190299438607683, 0.28314231595478395, 0.28274113001359485, 0.4733631306523348, 0.2666425433466563, 0.26080012497488075, 9.676288126468592, 0.39169304844799496, 0.9248209741653398, 1.5814087897918305, 1.7146960231590376, 0.5308515461054844, 0.3263094416449273, 0.46511964258531235, 0.3691534093853947, 0.37530950894445747, 0.4463533272493055, 0.4107818152832062, 0.40079866729598096, 1.289437665425596, 0.6948891601264614, 0.6948891601264614, 0.5488232391530419, 0.5463842365437629, 0.5078065137724154, 0.9204267770134604, 0.9666386179653497, 0.7769959856176524, 0.4294202937770873, 0.41594562437344734, 0.3544484187619722, 0.5250087970826989, 0.34768579232075114, 0.34768579232075114, 0.5124570236426205, 0.32089776027848527, 0.3177626892444302, 0.3177626892444302, 0.3177626892444302, 0.30934724183666323, 0.4156246790090278, 0.2918924729240464, 0.41284654430928963, 0.2845190008656952, 0.2826264948199141, 0.5508098718564962, 0.27901466381435547, 0.4443044814076813, 0.27293784988574926, 0.32319434605737585, 0.38191720561253234, 1.4741842481829737, 3.42725047205877, 0.4268241648480982, 0.4673611214549737, 0.3514765012286795, 1.254635640391445, 0.35728076872782455, 0.5014950186097314, 0.41058864086660696, 0.4042432897109685, 0.3767726218094108, 0.36850232928318827, 0.5346819097610777, 0.5721246022151517, 0.4849911445960315, 0.4832149989980271, 0.5203157750471625, 0.7390743738583679, 0.3873226985673649, 0.4585801437703045, 0.38024572700994425, 0.3729610936091285, 0.4526560665525372, 0.6193566971369834, 0.6085947455822427, 0.32411486241372417, 0.3019454562765977, 0.2933086084239624, 0.4009509938277883, 0.29131428534379533, 0.28907240586208377, 0.2846192052427933, 0.2842651287524087, 0.280117037625743, 0.43657228411556925, 0.2663393535212933, 0.26618065467042906, 0.3219597508870171, 0.25675970208719673, 0.25675970208719673, 0.25675970208719673, 0.24093996421397376, 0.9946858480330085, 0.5369260361732058, 0.5275945820674564, 0.3473998965243114, 0.5096616559637973, 0.4037788955625133, 0.8210881236248074, 0.4107346304213438, 0.5405474278658252, 0.3405038965774894, 0.5268692929078624, 0.3411458121729703, 0.4907278337109848, 0.6041422120630526, 0.37779883199499215, 0.3492709886224869, 0.36898188183789243], \"Total\": [35.0, 36.0, 33.0, 54.0, 28.0, 19.0, 31.0, 17.0, 14.0, 23.0, 25.0, 20.0, 53.0, 14.0, 9.0, 21.0, 18.0, 7.0, 16.0, 8.0, 10.0, 7.0, 8.0, 9.0, 5.0, 8.0, 4.0, 8.0, 9.0, 6.0, 12.675433837695355, 11.452504864893289, 10.879484880602737, 13.50432239846029, 12.649263725355404, 9.804813326665291, 9.112259313667941, 8.70480146272546, 7.477420768129815, 7.12228498517879, 26.96200900241013, 6.855240137144761, 6.7572894752090695, 6.536966203976332, 6.4771660308228896, 6.359968881731372, 8.608476039429629, 6.041525789587884, 11.633752418422985, 5.9630457768847345, 14.072901165003712, 12.257047231186736, 5.654375213992593, 5.437902695935494, 5.2674706514067395, 5.12434393391551, 5.033353294162354, 5.017734429194038, 13.205095360418195, 5.006831429050502, 7.187748969359203, 7.5614306243551725, 13.462293923307257, 6.712431757373089, 13.636663386517368, 54.765153150819955, 14.945095161095098, 18.77979306615939, 31.486400856036557, 53.26891665161475, 9.889176703117169, 21.940085433081304, 28.75145017904649, 25.09691147016043, 33.62428361378143, 11.380487059355522, 16.41158629071927, 18.075774913012957, 36.55942767114165, 19.96311782299233, 20.65261906825312, 14.903722563723552, 23.232786374932093, 1.6747280456217621, 1.5711380590453223, 7.816663956561442, 1.4195440522677272, 3.6144153670700256, 1.2259717400162484, 7.211280246399076, 1.4688163316045106, 17.418987580035896, 1.0243816124917289, 1.0043963552884736, 0.9966733205238886, 0.9814315114951503, 0.9549062230214015, 0.9381307393843598, 0.90007829091518, 0.8938215744985156, 1.4257465434929104, 1.1794176054031316, 0.8777242981135113, 0.8676440879604297, 3.8033604693587555, 33.62428361378143, 1.607001933088534, 1.6684340585395816, 1.0020277328877623, 0.8438551967864889, 0.8430640069972516, 1.156234717797084, 5.178690834219558, 3.1124799445485287, 10.162143112363344, 35.98230295489383, 28.75145017904649, 20.65261906825312, 2.462367390610687, 1.9808915652851036, 21.940085433081304, 18.075774913012957, 54.765153150819955, 53.26891665161475, 36.55942767114165, 9.959620096842253, 4.15573274016322, 6.683756255036052, 5.167649092855757, 4.76266130146132, 25.09691147016043, 23.232786374932093, 18.77979306615939, 13.636663386517368, 13.462293923307257, 11.006297622988678, 2.9547284182405487, 1.356335721793569, 5.9762080647649976, 1.5377376252948187, 2.1376393379211573, 1.12371985014249, 0.9649350271785562, 0.9467706079704341, 0.9416268429388648, 1.116486005409713, 14.074745529894404, 0.9121557351232841, 0.9067440378844733, 0.8831331996845685, 0.8813067748572256, 0.880568266410487, 1.0334380946107573, 4.395599049603977, 1.2286075479797978, 1.4419589606065903, 0.8450701721987679, 0.8414255372077395, 0.8414255372077395, 1.3270103584075292, 0.8286401145238801, 0.8286401145238801, 1.0501624202461524, 0.8174633273269909, 1.0962500007623859, 0.8054546977923871, 1.9659878469182226, 1.2280729281378335, 23.232786374932093, 14.903722563723552, 2.640850678517077, 8.191845288739499, 8.961904128168456, 7.070220715919427, 31.486400856036557, 16.41158629071927, 5.540104547080554, 18.075774913012957, 3.8081005120034517, 53.26891665161475, 1.6531961100822024, 7.3940211319690885, 1.5590039025919058, 14.072901165003712, 3.521621913577321, 2.0443905013017973, 9.229723134078425, 1.5314917303492912, 1.1841334004346036, 1.666578998319348, 2.3339444505469396, 2.778729066311891, 4.857948499295764, 1.076091670168009, 1.0735204411960078, 1.7276839380340463, 1.0579084448271683, 1.2496495754500239, 1.0292678675099804, 1.3230180387342005, 1.1860763206273974, 1.004439851732528, 0.9642793790060517, 1.9280194282419545, 0.9543867783327262, 0.953369800955465, 0.9442887559054232, 1.0072367871815542, 0.9391973516625192, 0.9391973516625192, 1.0407352504551268, 2.26489535199828, 0.9138572633481649, 1.317445414967389, 0.9009075699370782, 3.694481206819351, 2.5874438077682256, 2.382902203304319, 5.339035460230284, 8.25068392153346, 3.1465095319059704, 2.623774549340652, 2.2067251339355214, 3.6601114046189327, 6.683756255036052, 36.55942767114165, 6.078931374198708, 5.9762080647649976, 9.959620096842253, 4.943381559306239, 11.006297622988678, 53.26891665161475, 23.232786374932093, 31.486400856036557, 11.380487059355522, 7.3940211319690885, 2.6746739611777572, 2.2873479533924685, 1.6193414123212733, 1.5568721423615688, 1.569098020701883, 1.3155854306726213, 1.311539722149837, 1.499809592219591, 1.3136441203206535, 1.1179838566166649, 1.19032298408437, 1.1062079166110417, 1.6004535472741719, 1.4567306988529518, 1.06189146254081, 1.3122992677292855, 1.0234353586196843, 1.0115411184560015, 2.0587748821091063, 0.973214464242986, 0.9667204960002052, 0.9629656663965785, 0.9573167715298934, 0.9488819975688586, 1.944689705028432, 0.9447930079733424, 3.7795714532705182, 2.494165159053102, 0.9328783304785155, 0.9239893653441442, 1.2225498306736469, 1.8972914879106966, 1.4351486355087208, 1.1996220565926365, 1.4063286714708887, 1.6799630178203881, 2.7581915404759183, 1.7359813772905703, 6.511229626159489, 2.7165002321710014, 9.487604001400978, 2.778729066311891, 5.9762080647649976, 1.7263646110630433, 2.664164611957808, 5.4463710468276245, 2.1359816918530545, 1.324576320827549, 1.2893381688722096, 2.5864598411948085, 1.8557246937382899, 1.1620069749440787, 1.0814978088700615, 2.823963324748825, 1.0761672848733574, 1.0342022183787989, 1.459519097349943, 2.198202770864788, 1.0028565855002682, 1.256210537944976, 0.9750042694773551, 0.9513152767203125, 1.3671191713823063, 1.9280212070997014, 1.0928590130663938, 1.2163592000040808, 1.5741074016636465, 0.8846983836643162, 0.8846983836643162, 1.1698230899119784, 1.4083566903669094, 0.8634514073845143, 1.4006472106596302, 0.8624323289814231, 0.8581883858934226, 0.847988615420794, 3.8510164482981697, 1.102061506712847, 5.137333855820169, 3.7781100147928974, 1.5451016608655705, 9.109811379805386, 1.5388505782018693, 7.3940211319690885, 3.3167563456754947, 2.974021660376719, 53.26891665161475, 2.585412570065119, 4.2605888247901404, 3.1788704136889248, 3.252179431318776, 26.96200900241013, 18.77979306615939, 14.945095161095098, 3.0595177853246667, 1.7897045830434553, 1.6344166318603717, 1.3461482547079169, 1.7647470581172329, 2.8679919942278307, 1.1262026749178193, 1.6534497920564366, 1.0764397745890133, 1.065299502657939, 1.8000708268754675, 2.664164611957808, 1.153193090726847, 0.9620159038273448, 0.925647292124819, 1.4280261145095006, 0.9162260857855397, 1.6315702613485186, 0.9106547080250023, 0.905854317792381, 0.9048271881357556, 2.696347573579223, 0.8904692558609519, 0.8808959332069712, 1.651157074937159, 0.8661971482342582, 0.8649742257706778, 1.6500671380242211, 1.0604027387375075, 0.857834446931749, 19.96311782299233, 8.276781041599433, 1.4495260142728854, 9.099108694674655, 1.6611091953869908, 2.649263985072951, 1.4369898517520878, 1.3100180071677032, 2.591718978886921, 10.742512552010345, 25.09691147016043, 16.41158629071927, 2.614256141431151, 3.546178677953183, 5.513086120840853, 53.26891665161475, 26.96200900241013, 3.344640596450549, 1.1649633308728482, 1.1433519161381689, 35.98230295489383, 3.68653489441353, 1.185422343918897, 1.116083512956625, 0.8899988814332503, 1.069025032649168, 0.8711254283756177, 0.8603500434896202, 1.6559439225281891, 0.8379874785428342, 0.8230179491882613, 0.8205678530281704, 1.784527021557835, 0.9849755041039066, 0.8070270185349728, 0.8070270185349728, 0.8039213579901914, 0.8025575492019488, 0.8025575492019488, 0.7970879081867421, 0.7970879081867421, 1.0552381999088425, 0.7917449610069827, 0.7914096437386551, 1.3251065596466616, 0.7752316032280381, 0.76942247537249, 36.55942767114165, 1.2791930393136417, 4.313859250339327, 20.65261906825312, 54.765153150819955, 5.4463710468276245, 1.26796317626604, 7.550305290073929, 2.5864598411948085, 2.823963324748825, 9.889176703117169, 7.467870040628619, 53.26891665161475, 2.199761787646908, 1.2029522894741231, 1.2029522894741231, 1.0564678199161677, 1.0540664562518403, 1.0154730765366091, 1.8607482114117062, 1.970947252307372, 1.6800859736865297, 0.9370622411769812, 0.9236123520458435, 0.86211657148397, 1.2841119013575897, 0.8553296994635703, 0.8553296994635703, 1.2713024221769063, 0.828579777453174, 0.825404636314909, 0.825404636314909, 0.825404636314909, 0.8169937285090174, 1.1041418200923585, 0.7995405958921721, 1.1328611253368726, 0.7922249760939707, 0.7903051560784302, 1.5416494025321485, 0.7867007772555795, 1.2547151164112134, 0.7805972065289855, 0.9251023333373926, 1.1195158219321908, 6.078931374198708, 25.09691147016043, 1.3906543582379038, 1.6461232958007919, 1.0692760715795975, 23.232786374932093, 1.1517668687846616, 3.0840792805362964, 1.8785189766793358, 2.623774549340652, 3.126869340505303, 2.7783978861120056, 1.0438024883211554, 1.117555830278649, 0.9940857212838392, 0.9923227593635907, 1.1111525315654183, 1.6660673290271655, 0.8964165060587671, 1.071750505087577, 0.8893393766960944, 0.8820547427231342, 1.1273389258970665, 1.5456517399613365, 1.5324062722401275, 0.8332423574738161, 0.8110391050800072, 0.8024646568856679, 1.0975730613036, 0.8004251286459718, 0.7982274310152564, 0.7937411511255661, 0.7933823263313375, 0.7892258155471082, 1.2424476997985738, 0.7754645057311051, 0.7753011959554422, 0.9512271881656004, 0.7658533512062058, 0.7658533512062058, 0.7658533512062058, 0.7500812067705, 3.1124799445485287, 1.7051774276559282, 1.8430040277826012, 1.1263651025272827, 1.8645618210890769, 1.4419589606065903, 4.943381559306239, 1.5687530684550328, 2.878090407353491, 1.1368540740060311, 3.3696998800175897, 1.19811676621459, 3.68653489441353, 8.526214393824567, 2.3379374613057657, 1.4975682703308948, 4.1342788780799955], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.9507, -5.0564, -5.1101, -4.8955, -4.9643, -5.2192, -5.2964, -5.3448, -5.5065, -5.5586, -4.2298, -5.5996, -5.6151, -5.6509, -5.6608, -5.6805, -5.3793, -5.7363, -5.0811, -5.7505, -4.8931, -5.0348, -5.8085, -5.8512, -5.8862, -5.9166, -5.9364, -5.9399, -4.9724, -5.9423, -5.5828, -5.5341, -4.9724, -5.6561, -4.9858, -3.6894, -4.9099, -4.6985, -4.2439, -3.796, -5.3014, -4.6796, -4.4925, -4.637, -4.5034, -5.2557, -5.0116, -4.9883, -4.5639, -4.9416, -4.9271, -5.1287, -4.9914, -5.543, -5.6354, -4.0572, -5.7881, -4.8822, -6.0246, -4.3009, -5.9379, -3.4857, -6.3505, -6.3893, -6.4048, -6.4359, -6.4927, -6.5303, -6.6213, -6.6371, -6.1756, -6.3826, -6.679, -6.707, -5.2316, -3.0551, -6.1152, -6.0808, -6.5929, -6.7733, -6.7754, -6.4598, -4.9607, -5.5168, -4.4399, -3.2942, -3.5008, -3.8769, -5.7716, -5.9798, -4.105, -4.3313, -3.5221, -3.603, -4.0086, -4.8952, -5.6001, -5.4703, -5.6252, -5.6803, -5.1596, -5.2079, -5.3152, -5.4143, -5.6021, -5.6844, -4.4979, -5.5532, -4.1217, -5.5262, -5.307, -6.0046, -6.167, -6.207, -6.2188, -6.0626, -3.5461, -6.2882, -6.3015, -6.3619, -6.3665, -6.3685, -6.2148, -4.774, -6.0661, -5.9319, -6.4672, -6.4779, -6.4779, -6.0244, -6.5165, -6.5165, -6.2989, -6.5513, -6.2734, -6.5903, -5.7073, -6.1735, -3.4716, -3.965, -5.518, -4.6402, -4.6356, -4.8285, -3.7539, -4.5184, -5.3007, -4.6915, -5.681, -4.642, -6.0731, -5.6284, -6.0993, -5.7103, -6.0753, -5.1359, -3.6714, -5.4829, -5.7635, -5.428, -5.0983, -4.9648, -4.4134, -5.9363, -5.9409, -5.466, -5.9686, -5.8204, -6.0215, -5.7816, -5.9031, -6.0699, -6.1534, -5.4652, -6.1751, -6.1776, -6.1977, -6.1394, -6.2094, -6.2094, -6.1134, -5.3505, -6.2693, -5.9165, -6.3014, -4.9804, -5.3144, -5.4236, -4.8338, -4.6817, -5.3947, -5.5279, -5.6421, -5.3303, -5.0332, -4.2566, -5.2063, -5.3216, -5.1837, -5.5346, -5.3295, -5.0989, -5.28, -5.2323, -5.5291, -5.6217, -4.5609, -4.7573, -5.226, -5.2836, -5.3369, -5.5434, -5.5483, -5.4501, -5.622, -5.8216, -5.763, -5.841, -5.4755, -5.5812, -5.9172, -5.7239, -5.9886, -6.0115, -5.3148, -6.09, -6.1037, -6.1116, -6.1241, -6.1428, -5.4297, -6.1519, -4.7683, -5.1898, -6.1792, -6.2001, -5.9267, -5.548, -5.8063, -5.9708, -5.8634, -5.7955, -5.5929, -5.82, -5.2857, -5.6789, -5.2951, -5.7126, -5.5795, -5.8456, -5.8218, -5.8317, -4.8451, -5.5318, -5.5757, -4.9076, -5.2454, -5.7522, -5.8825, -4.924, -5.8917, -5.9676, -5.6314, -5.2314, -6.0284, -5.8266, -6.0858, -6.1371, -5.7801, -5.4779, -6.0589, -5.9567, -5.7005, -6.2979, -6.2979, -6.0348, -5.8511, -6.3551, -5.8715, -6.358, -6.3697, -6.3989, -4.9455, -6.1546, -4.867, -5.1303, -5.9261, -4.8019, -5.957, -5.0608, -5.5611, -5.6191, -4.945, -5.8067, -5.696, -5.7968, -5.8627, -5.7095, -5.8021, -5.8801, -4.4242, -5.0681, -5.2631, -5.4909, -5.3075, -4.8363, -5.7933, -5.4462, -5.8766, -5.8962, -5.4177, -5.0375, -5.8834, -6.0993, -6.1819, -5.7516, -6.2045, -5.6322, -6.2181, -6.2299, -6.2324, -5.1468, -6.2689, -6.2939, -5.6661, -6.3337, -6.337, -5.6928, -6.1364, -6.3569, -3.4681, -4.4471, -5.9232, -4.6212, -5.8527, -5.5677, -5.9513, -6.0176, -5.6555, -4.9285, -4.5459, -4.903, -5.7127, -5.7746, -5.7149, -5.4888, -5.6344, -4.2119, -5.5413, -5.5748, -2.175, -4.5113, -5.767, -5.8371, -6.0842, -5.9272, -6.1349, -6.1654, -5.5256, -6.2307, -6.2774, -6.2852, -5.5117, -6.1254, -6.3294, -6.3294, -6.34, -6.3445, -6.3445, -6.3633, -6.3633, -6.0828, -6.3821, -6.3835, -5.8681, -6.4421, -6.4643, -2.8506, -6.0575, -5.1984, -4.6619, -4.581, -5.7535, -6.2402, -5.8857, -6.1168, -6.1003, -5.9269, -6.0099, -6.0346, -4.7892, -5.4074, -5.4074, -5.6434, -5.6479, -5.7211, -5.1263, -5.0774, -5.2957, -5.8887, -5.9206, -6.0806, -5.6878, -6.0999, -6.0999, -5.712, -6.1801, -6.1899, -6.1899, -6.1899, -6.2167, -5.9214, -6.2748, -5.9281, -6.3004, -6.3071, -5.6398, -6.3199, -5.8547, -6.3419, -6.1729, -6.006, -4.6553, -3.8117, -5.8948, -5.8041, -6.089, -4.8166, -6.0727, -5.7336, -5.9336, -5.9492, -6.0195, -6.0417, -5.5716, -5.5039, -5.6692, -5.6728, -5.5989, -5.2479, -5.894, -5.7252, -5.9125, -5.9318, -5.7382, -5.4246, -5.4421, -6.0722, -6.143, -6.1721, -5.8594, -6.1789, -6.1866, -6.2021, -6.2034, -6.2181, -5.7743, -6.2685, -6.2691, -6.0789, -6.3051, -6.3051, -6.3051, -6.3687, -4.9509, -5.5674, -5.585, -6.0028, -5.6195, -5.8524, -5.1427, -5.8353, -5.5607, -6.0229, -5.5863, -6.021, -5.6574, -5.4495, -5.9189, -5.9974, -5.9425], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.6821, 0.6779, 0.6755, 0.6739, 0.6706, 0.6704, 0.6665, 0.6638, 0.6541, 0.6507, 0.6482, 0.6478, 0.6467, 0.6441, 0.6434, 0.6419, 0.6404, 0.6376, 0.6375, 0.6364, 0.6352, 0.6316, 0.6316, 0.6278, 0.6247, 0.6218, 0.62, 0.6196, 0.6195, 0.6194, 0.6173, 0.6154, 0.6001, 0.6124, 0.5739, 0.48, 0.5582, 0.5412, 0.479, 0.4011, 0.5797, 0.4046, 0.3213, 0.3128, 0.1538, 0.4849, 0.3629, 0.2896, 0.0097, 0.237, 0.2175, 0.3421, 0.0355, 2.1138, 2.0853, 2.059, 2.034, 2.0054, 1.9441, 1.896, 1.8501, 1.8292, 1.7979, 1.7788, 1.771, 1.7553, 1.7259, 1.706, 1.6564, 1.6476, 1.6422, 1.6249, 1.6239, 1.6074, 1.605, 1.6021, 1.583, 1.5798, 1.5776, 1.5689, 1.5678, 1.5675, 1.5672, 1.5202, 1.4139, 1.2953, 1.313, 1.2678, 1.4998, 1.5091, 0.9792, 0.9466, 0.6473, 0.5941, 0.5649, 0.9787, 1.1478, 0.8025, 0.9049, 0.9313, -0.2098, -0.1809, -0.0755, 0.1454, -0.0295, 0.0896, 2.5912, 2.3145, 2.263, 2.2159, 2.1057, 2.0512, 2.0412, 2.0202, 2.0139, 1.9996, 1.982, 1.9763, 1.9688, 1.9349, 1.9323, 1.9311, 1.9247, 1.9179, 1.9005, 1.8746, 1.8736, 1.8672, 1.8672, 1.8651, 1.844, 1.844, 1.8246, 1.8227, 1.8072, 1.7985, 1.7892, 1.7935, 1.5554, 1.5058, 1.6834, 1.4291, 1.3439, 1.3881, 0.9691, 0.8561, 1.1598, 0.5864, 1.1544, -0.4449, 1.5966, 0.5434, 1.6292, -0.182, 0.8382, 2.3215, 2.2786, 2.2633, 2.2399, 2.2337, 2.2266, 2.1856, 2.1784, 2.1629, 2.1607, 2.1597, 2.1476, 2.1292, 2.1221, 2.1109, 2.0987, 2.0981, 2.0554, 2.0508, 2.0441, 2.0427, 2.0321, 2.0259, 2.0258, 2.0258, 2.0191, 2.0045, 1.9933, 1.9803, 1.9755, 1.8852, 1.9074, 1.8805, 1.6636, 1.3805, 1.6315, 1.68, 1.7388, 1.5447, 1.2396, 0.3169, 1.1613, 1.0631, 0.6903, 1.0399, 0.4445, -0.9018, -0.2531, -0.5094, 0.2115, 0.5501, 2.6277, 2.5878, 2.4644, 2.4462, 2.385, 2.3548, 2.3529, 2.317, 2.2776, 2.2393, 2.2353, 2.2306, 2.2267, 2.2151, 2.1952, 2.1768, 2.1607, 2.1495, 2.1356, 2.1096, 2.1026, 2.0986, 2.092, 2.0822, 2.0777, 2.0773, 2.0745, 2.0688, 2.0628, 2.0515, 2.0449, 1.9841, 2.0049, 2.0196, 1.9681, 1.8582, 1.565, 1.8009, 1.0133, 1.4942, 0.6274, 1.4379, 0.8052, 1.7808, 1.3708, 0.6458, 2.5684, 2.3596, 2.3426, 2.3146, 2.3088, 2.2701, 2.2116, 2.2104, 2.2074, 2.1712, 2.163, 2.1535, 2.1412, 2.1177, 2.112, 2.0853, 2.0796, 2.0381, 2.0248, 2.0199, 2.0183, 1.9971, 1.9971, 1.9809, 1.979, 1.9642, 1.964, 1.9625, 1.9557, 1.9385, 1.8787, 1.9206, 1.6689, 1.713, 1.8113, 1.1612, 1.7845, 1.111, 1.4124, 1.4634, -0.7478, 1.4159, 1.0271, 1.2192, 1.1305, -0.8314, -0.5624, -0.412, 2.63, 2.5223, 2.4181, 2.3843, 2.297, 2.2826, 2.2603, 2.2234, 2.2222, 2.213, 2.167, 2.1551, 2.1466, 2.1119, 2.0678, 2.0645, 2.0555, 2.0508, 2.048, 2.0414, 2.04, 2.0338, 2.0196, 2.0054, 2.0049, 1.9824, 1.9805, 1.9789, 1.9774, 1.9689, 1.7105, 1.612, 1.8781, 1.3431, 1.8122, 1.6305, 1.8586, 1.8848, 1.5647, 0.8698, 0.4038, 0.4715, 1.4988, 1.132, 0.7504, -1.2916, -0.7564, 2.7532, 2.4785, 2.4637, 2.4145, 2.3565, 2.2354, 2.2255, 2.2049, 2.1785, 2.1756, 2.1575, 2.1425, 2.1185, 2.0899, 2.085, 2.0816, 2.0623, 2.0574, 2.0574, 2.0508, 2.0479, 2.0479, 2.0359, 2.0359, 2.0359, 2.0239, 2.0229, 2.0228, 1.985, 1.9703, 1.723, 1.8687, 1.5122, 0.4827, -0.4116, 0.724, 1.6949, 0.2652, 1.1054, 1.0341, -0.0459, 0.1519, -1.8374, 2.5949, 2.5803, 2.5803, 2.4741, 2.472, 2.436, 2.4251, 2.4166, 2.3579, 2.3487, 2.3313, 2.2402, 2.2346, 2.2289, 2.2289, 2.2205, 2.1805, 2.1745, 2.1745, 2.1745, 2.1579, 2.152, 2.1214, 2.1196, 2.105, 2.1008, 2.0998, 2.0925, 2.0909, 2.0782, 2.0774, 2.0536, 1.7123, 1.1381, 1.9479, 1.87, 2.0165, 0.2103, 1.9585, 1.3126, 1.6084, 1.2587, 1.0129, 1.1089, 2.558, 2.5574, 2.5092, 2.5074, 2.4682, 2.4141, 2.3878, 2.378, 2.3773, 2.3662, 2.3145, 2.3124, 2.3035, 2.2827, 2.2389, 2.2205, 2.2199, 2.2162, 2.2112, 2.2013, 2.2005, 2.1911, 2.1811, 2.1583, 2.1579, 2.1436, 2.1341, 2.1341, 2.1341, 2.0913, 2.0862, 2.0714, 1.9761, 2.0507, 1.9299, 1.9541, 1.4318, 1.8869, 1.5546, 2.0213, 1.3713, 1.9707, 1.2104, 0.5799, 1.4043, 1.7712, 0.8106]}, \"token.table\": {\"Topic\": [6, 4, 1, 7, 9, 5, 1, 2, 7, 1, 5, 5, 4, 1, 10, 1, 2, 3, 4, 9, 2, 3, 4, 5, 1, 8, 1, 5, 1, 1, 4, 7, 1, 4, 1, 1, 5, 2, 5, 1, 3, 5, 4, 6, 1, 6, 1, 1, 7, 5, 7, 3, 9, 1, 3, 4, 5, 5, 1, 3, 4, 6, 6, 1, 4, 1, 6, 7, 5, 7, 1, 2, 3, 1, 2, 5, 1, 9, 6, 1, 4, 10, 7, 4, 5, 7, 1, 5, 2, 1, 4, 2, 1, 2, 1, 2, 4, 8, 7, 2, 4, 1, 1, 5, 6, 1, 1, 6, 7, 9, 8, 2, 1, 4, 6, 5, 1, 10, 2, 1, 1, 7, 5, 8, 6, 1, 5, 1, 3, 7, 1, 1, 8, 2, 1, 3, 1, 6, 1, 10, 1, 2, 3, 5, 1, 2, 1, 3, 7, 1, 2, 6, 1, 2, 7, 1, 9, 6, 1, 2, 4, 9, 3, 3, 6, 6, 1, 7, 1, 1, 1, 2, 4, 1, 2, 4, 1, 5, 8, 1, 7, 1, 4, 5, 5, 9, 5, 2, 4, 2, 1, 7, 1, 2, 8, 7, 1, 3, 8, 1, 4, 2, 10, 1, 7, 4, 6, 5, 1, 1, 4, 1, 4, 5, 9, 1, 6, 7, 3, 1, 10, 1, 2, 1, 2, 1, 1, 1, 2, 6, 3, 1, 3, 5, 4, 1, 1, 1, 4, 4, 1, 1, 1, 2, 6, 8, 1, 1, 1, 7, 6, 2, 4, 5, 6, 4, 7, 6, 10, 1, 9, 1, 2, 3, 4, 6, 7, 1, 4, 1, 4, 6, 7, 1, 1, 2, 1, 2, 5, 6, 1, 2, 7, 8, 1, 3, 5, 1, 10, 1, 1, 3, 1, 3, 7, 6, 5, 1, 2, 8, 1, 1, 6, 5, 5, 2, 5, 5, 5, 10, 1, 10, 9, 6, 9, 1, 10, 1, 4, 7, 1, 1, 2, 6, 7, 9, 6, 6, 10, 1, 2, 1, 6, 1, 4, 6, 4, 8, 3, 1, 7, 1, 4, 5, 1, 3, 9, 1, 5, 5, 4, 1, 6, 1, 2, 1, 7, 1, 2, 6, 3, 3, 5, 4, 2, 4, 10, 1, 2, 1, 3, 4, 1, 3, 9, 1, 2, 4, 4, 2, 5, 9, 4, 5, 7, 1, 3, 1, 1, 1, 7, 1, 2, 6, 7, 10, 1, 3, 6, 4, 2, 1, 2, 6, 1, 2, 7, 1, 6, 1, 2, 8, 1], \"Freq\": [0.649835672264223, 0.9955797734181198, 0.3858443018499927, 0.3858443018499927, 0.9487067860558855, 0.8743750582563139, 0.9087401243590845, 0.6808203166611149, 0.9387031510903593, 0.7362414242834866, 0.3681207121417433, 0.5142208535450542, 0.8431160648001397, 0.694905203425862, 0.347452601712931, 0.5165114423359852, 0.08608524038933087, 0.30129834136265804, 0.04304262019466543, 0.04304262019466543, 0.622276787233278, 0.6693207392800659, 0.16733018482001646, 0.16733018482001646, 0.5603725737518012, 0.5603725737518012, 0.7251128033170987, 0.36255640165854935, 0.8347536934828301, 0.5618992460991453, 0.3745994973994302, 0.5587514327640962, 0.5464314549213092, 0.2732157274606546, 0.6396173879388255, 0.8432055130904165, 0.10540068913630206, 0.4009357585524309, 0.4009357585524309, 0.9237611951918069, 0.07105855347629284, 0.840108116343925, 0.5788095715805015, 0.6472066048002285, 0.6724900583765957, 0.33624502918829785, 0.962654742416562, 0.9931266055903543, 0.6958991385921923, 0.37535218188531244, 0.37535218188531244, 0.6503059972979965, 0.7787483310004208, 0.7939935756489301, 0.15879871512978602, 0.0317597430259572, 0.6373088148774056, 0.6175350005818306, 0.5409776261938769, 0.13524440654846923, 0.13524440654846923, 0.13524440654846923, 0.6851571876076892, 0.41965633277493375, 0.41965633277493375, 0.6291543031724584, 0.3145771515862292, 0.700267305926321, 0.6967919386590417, 0.6973520163324144, 0.4592689421955208, 0.5166775599699609, 0.8899015176008485, 0.9271148292775138, 0.8156794870220634, 0.8335958767216769, 0.6484917598007455, 0.32424587990037274, 0.8221255694836238, 0.6068720296033601, 0.20229067653445335, 0.20229067653445335, 0.5666534449797449, 0.6000315622652417, 0.9885905592511972, 0.6118390993499325, 0.7679041113696898, 0.15358082227393796, 0.9956228880507926, 0.3250368354954502, 0.6500736709909004, 0.5971118729481469, 0.5650678009452834, 0.4163657480649457, 0.492349064156942, 0.1367636289324839, 0.08205817735949034, 0.2735272578649678, 0.6060359466326886, 0.9761987015440247, 0.6529581454363632, 0.9486718168383226, 0.5792519109762277, 0.5792519109762277, 0.7314651282293783, 0.9986355783797983, 0.9272306079923515, 0.03708922431969406, 0.03708922431969406, 0.7865948987084102, 0.5425148702730966, 0.406113240377177, 0.727212441666878, 0.2424041472222927, 0.6352806669628245, 0.527067140906853, 0.5935246672441227, 0.29676233362206134, 0.7044515444254766, 0.8974428989725752, 0.6040995859223289, 0.24163983436893158, 0.6864686800294747, 0.874621353133023, 0.7960449063227024, 0.9257507405348905, 0.7477546904892013, 0.670258182551219, 0.12186512410022164, 0.12186512410022164, 0.9964656500968135, 0.6954329814455631, 0.23181099381518772, 0.7013869362433229, 0.5086501432689661, 0.5086501432689661, 0.6149722185497586, 0.3074861092748793, 0.9194721346774373, 0.8948098814451731, 0.663871953360133, 0.22129065112004434, 0.11064532556002217, 0.9771012810703631, 0.5258507617441791, 0.5258507617441791, 0.4550005533785414, 0.4550005533785414, 0.8671574674191892, 0.729258782915912, 0.22789336966122248, 0.0455786739322445, 0.8913785472492478, 0.074281545604104, 0.9289883406452552, 0.63744895236115, 0.6486559125294681, 0.9669288870484016, 0.4488494022713008, 0.14961646742376694, 0.14961646742376694, 0.5374182244900955, 0.46780576230062015, 0.6048889142076899, 0.9363376135798783, 0.86058003227401, 0.37087206775518416, 0.37087206775518416, 0.9828306526019023, 0.9178569710747924, 0.6024326170736503, 0.20081087235788342, 0.10040543617894171, 0.8177136679642247, 0.0908570742182472, 0.0908570742182472, 0.7344339865220715, 0.18360849663051787, 0.18360849663051787, 0.7198393037934286, 0.6047961085992669, 0.38648182310190543, 0.38648182310190543, 0.9417158299844308, 0.9039891913480259, 0.4545946773035379, 0.6423135033318359, 0.5533398342153663, 0.2766699171076831, 0.6364813036275339, 0.6056358993211223, 0.6056358993211223, 0.13895719810563062, 0.30570583583238736, 0.5280373528013963, 0.6129064887303622, 0.4973446933823547, 0.4262954514705898, 0.8435811971403309, 0.9467131581968667, 0.9315146331875165, 0.32128721078234995, 0.32128721078234995, 0.7255464384782587, 0.18138660961956468, 0.4415215030211954, 0.5388730361643981, 0.6667513030904708, 0.93615167810742, 0.5413479966573813, 0.27067399832869066, 0.32900519464469674, 0.16450259732234837, 0.16450259732234837, 0.16450259732234837, 0.7735709275791236, 0.3867854637895618, 0.5555336962689313, 0.7535736203295684, 0.5363190368318854, 0.5363190368318854, 0.25586362815573843, 0.6396590703893461, 0.5904266387176099, 0.3936177591450733, 0.8034419409225473, 0.8384976716734418, 0.6586305412756174, 0.10977175687926956, 0.21954351375853912, 0.7372805891137604, 0.6103630896048531, 0.24414523584194123, 0.760117873522458, 0.8444994454450635, 0.9263310484010755, 0.9293166366912552, 0.9933735439948083, 0.7590447305361437, 0.38113030719476165, 0.9455246771953487, 0.9492221847813602, 0.7851708162228739, 0.16433807781408988, 0.018259786423787765, 0.03651957284757553, 0.8752428623892128, 0.9604885682013194, 0.5639873739115646, 0.2819936869557823, 0.754958385014187, 0.6074879096547434, 0.9292888586749037, 0.35411224757635407, 0.7082244951527081, 0.42845921194296577, 0.42845921194296577, 0.7732577046609411, 0.6002158391665424, 0.8842709956047409, 0.8312881639197471, 0.7321342811430686, 0.15018139100370637, 0.03754534775092659, 0.018772673875463296, 0.018772673875463296, 0.018772673875463296, 0.790827312843469, 0.08786970142705211, 0.8698506004726857, 0.06691158465174506, 0.06691158465174506, 0.742860228435223, 0.9434008422957287, 0.5048231904890125, 0.5048231904890125, 0.5792969876048041, 0.3861979917365361, 0.7620213045842301, 0.7100473955496863, 0.6594052452095183, 0.10990087420158637, 0.21980174840317274, 0.8583961172844389, 0.5679201371076111, 0.28396006855380557, 0.28396006855380557, 0.8209974176898501, 0.1172853453842643, 0.8938638360694635, 0.67097330598065, 0.26838932239226, 0.3786658625324217, 0.3786658625324217, 0.887939642012457, 0.518666494080886, 0.4857257627776927, 0.5810401073269303, 0.29052005366346517, 0.09684001788782172, 0.9100858716745458, 0.7041280262823222, 0.23470934209410738, 0.894467298504902, 0.5760430457847123, 0.42772743777392924, 0.42772743777392924, 0.762462610252345, 0.5952511986230605, 0.9580356544353453, 0.5425924115874797, 0.5425924115874797, 0.595207635598403, 0.4549170864735982, 0.8312881639197471, 0.9876804083593673, 0.6469762716567797, 0.725640453503522, 0.3825179882536525, 0.3825179882536525, 0.975734662716033, 0.6773741868680756, 0.0796910808080089, 0.03984554040400445, 0.0796910808080089, 0.11953662121201335, 0.7755917137508656, 0.9292235640834215, 0.8999664506826763, 0.7218943535532009, 0.2406314511844003, 0.5293652096336937, 0.26468260481684686, 0.41169641882575153, 0.6175446282386273, 0.7139556573486148, 0.4891433409435401, 0.6038851837888713, 0.8956672946680003, 0.7447047384182843, 0.09308809230228554, 0.6356249614754917, 0.3178124807377459, 0.6248228833027736, 0.7877943322514069, 0.26259811075046896, 0.9465503644771229, 0.5291605211668563, 0.5291605211668563, 0.7110713308248869, 0.8002243346018663, 0.6029987709551445, 0.30149938547757227, 0.879980656548614, 0.07333172137905117, 0.37746332779006303, 0.37746332779006303, 0.8519795688713689, 0.05324872305446056, 0.05324872305446056, 0.6768811602627559, 0.693501013079685, 0.7612411798074393, 0.9452613833358435, 0.5186669726206236, 0.5186669726206236, 0.6525684592364422, 0.6608362319701995, 0.31302768882798926, 0.5657532007442898, 0.2828766003721449, 0.14143830018607245, 0.6695005786930037, 0.22316685956433457, 0.984762691503962, 0.6298999257157998, 0.2099666419052666, 0.7558475929449544, 0.45316019862273393, 0.5993644129246096, 0.8179625688132336, 0.507370249928966, 0.719753510425732, 0.359876755212866, 0.6898806852401489, 0.9190330226664598, 0.8139295592350074, 0.9179165069388409, 0.8879299935295966, 0.6020073832455239, 0.6020073832455239, 0.5839604908295479, 0.19465349694318262, 0.38930699388636525, 0.6536977851847219, 0.5864492361798849, 0.7220080354093432, 0.1805020088523358, 0.9246435746779648, 0.9715643823791121, 0.84787610038956, 0.7740463657894217, 0.1935115914473554, 0.997151551336881, 0.6011085095224512, 0.0500923757935376, 0.3005542547612256, 0.5193434063061024, 0.2596717031530512, 0.41601489575974226, 0.5546865276796563, 0.5979715734248011, 0.9191611652339543], \"Term\": [\"acceptable\", \"acs\", \"address\", \"address\", \"advertise\", \"along\", \"also\", \"anything\", \"arrangement\", \"arrive\", \"arrive\", \"attitude\", \"availability\", \"average\", \"average\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bag\", \"base\", \"base\", \"base\", \"become\", \"become\", \"best\", \"best\", \"better\", \"bite\", \"bite\", \"bottle\", \"box\", \"box\", \"branch\", \"bread\", \"bread\", \"burn\", \"burn\", \"burst\", \"burst\", \"business\", \"bust\", \"buy\", \"cake\", \"cake\", \"call\", \"cancel\", \"capsicum\", \"charge\", \"charge\", \"chat\", \"cheat\", \"cheese\", \"cheese\", \"cheese\", \"cheeseburst\", \"cheez\", \"chicken\", \"chicken\", \"chicken\", \"chicken\", \"chocolava\", \"claim\", \"claim\", \"clean\", \"clean\", \"cleanliness\", \"clearly\", \"coke\", \"cold\", \"cold\", \"combo\", \"come\", \"commit\", \"compromise\", \"condition\", \"condition\", \"confirmation\", \"cook\", \"cook\", \"cook\", \"cost\", \"costly\", \"count\", \"coz\", \"customer\", \"customer\", \"daughter\", \"delay\", \"delay\", \"delievered\", \"deliver\", \"deliver\", \"delivery\", \"delivery\", \"delivery\", \"delivery\", \"deny\", \"difficult\", \"dirty\", \"disappoint\", \"discount\", \"discount\", \"disgust\", \"doesnt\", \"dominos\", \"dominos\", \"dominos\", \"door\", \"dry\", \"due\", \"eat\", \"eat\", \"either\", \"end\", \"enough\", \"enough\", \"estimate\", \"even\", \"ever\", \"ever\", \"everytime\", \"exactly\", \"excellent\", \"expect\", \"expensive\", \"experience\", \"experience\", \"experience\", \"extra\", \"extremely\", \"extremely\", \"fast\", \"fill\", \"fill\", \"find\", \"find\", \"first\", \"flat\", \"food\", \"food\", \"food\", \"form\", \"free\", \"free\", \"fresh\", \"fresh\", \"front\", \"get\", \"get\", \"get\", \"give\", \"give\", \"glass\", \"gonna\", \"green\", \"hair\", \"half\", \"half\", \"half\", \"hand\", \"happy\", \"hard\", \"hate\", \"health\", \"high\", \"high\", \"home\", \"horrible\", \"hot\", \"hot\", \"hot\", \"hour\", \"hour\", \"hour\", \"hours\", \"hours\", \"hours\", \"im\", \"incomplete\", \"inside\", \"inside\", \"intimation\", \"irresponsible\", \"item\", \"items\", \"ketchup\", \"ketchup\", \"km\", \"lack\", \"lack\", \"late\", \"late\", \"late\", \"least\", \"less\", \"less\", \"let\", \"like\", \"local\", \"long\", \"long\", \"look\", \"look\", \"love\", \"low\", \"maintain\", \"make\", \"margarita\", \"margarita\", \"mark\", \"mark\", \"mark\", \"mark\", \"medium\", \"medium\", \"menu\", \"messy\", \"mexicana\", \"mexicana\", \"min\", \"min\", \"mins\", \"mins\", \"minutes\", \"miss\", \"money\", \"money\", \"money\", \"mood\", \"much\", \"much\", \"mushroom\", \"myonies\", \"need\", \"never\", \"non\", \"normally\", \"nothing\", \"one\", \"online\", \"order\", \"order\", \"order\", \"order\", \"oregano\", \"outlet\", \"outlets\", \"outlets\", \"overcook\", \"package\", \"papsi\", \"parcel\", \"parcel\", \"park\", \"park\", \"per\", \"peri\", \"pick\", \"pimple\", \"pizza\", \"pizza\", \"pizza\", \"pizza\", \"pizza\", \"pizza\", \"pizzas\", \"pizzas\", \"place\", \"place\", \"place\", \"plaza\", \"please\", \"plz\", \"plz\", \"pm\", \"pm\", \"point\", \"policy\", \"poor\", \"poor\", \"poor\", \"present\", \"price\", \"price\", \"price\", \"properly\", \"properly\", \"provide\", \"quality\", \"quality\", \"quantity\", \"quantity\", \"rainbow\", \"rat\", \"reason\", \"receive\", \"receive\", \"receive\", \"refund\", \"regular\", \"regular\", \"report\", \"request\", \"rs\", \"rs\", \"rubbish\", \"rudely\", \"saggy\", \"salty\", \"salty\", \"satisfactory\", \"satisfy\", \"saudagar\", \"say\", \"seal\", \"season\", \"seem\", \"seem\", \"serve\", \"service\", \"service\", \"service\", \"service\", \"service\", \"shame\", \"shittiest\", \"short\", \"show\", \"show\", \"size\", \"size\", \"slow\", \"slow\", \"smaller\", \"smell\", \"spicy\", \"st\", \"staff\", \"staff\", \"stale\", \"stale\", \"standard\", \"star\", \"star\", \"step\", \"stuff\", \"stuff\", \"super\", \"sure\", \"taco\", \"taco\", \"take\", \"take\", \"talk\", \"talk\", \"taste\", \"taste\", \"taste\", \"tasty\", \"tax\", \"team\", \"terrible\", \"test\", \"test\", \"theres\", \"time\", \"time\", \"top\", \"top\", \"top\", \"toppings\", \"toppings\", \"toss\", \"totally\", \"totally\", \"type\", \"uncooked\", \"unprofessional\", \"untidy\", \"update\", \"upto\", \"upto\", \"value\", \"veg\", \"veggies\", \"wait\", \"want\", \"washroom\", \"washroom\", \"waste\", \"waste\", \"waste\", \"water\", \"weekend\", \"well\", \"well\", \"whereas\", \"wheres\", \"wing\", \"without\", \"without\", \"wonder\", \"worst\", \"worst\", \"worst\", \"worth\", \"worth\", \"wrong\", \"wrong\", \"yet\", \"zomato\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [9, 1, 8, 7, 10, 5, 4, 6, 2, 3]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el581404381119939364304158226\", ldavis_el581404381119939364304158226_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el581404381119939364304158226\", ldavis_el581404381119939364304158226_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el581404381119939364304158226\", ldavis_el581404381119939364304158226_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "//"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "6ssmOJnmJqu8",
        "outputId": "cc9fe5e1-ff85-4a0a-f2b2-ddb3cb278d4a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-84-6648892c9bac>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    (/)\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "19/04/22"
      ],
      "metadata": {
        "id": "e2qyQgn6qWbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###################"
      ],
      "metadata": {
        "id": "GTc_vmAEqRMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20/04/22"
      ],
      "metadata": {
        "id": "7pKh8Mf49722"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_measures=nltk.collocations.BigramAssocMeasures()\n",
        "\n",
        "finder=nltk.collocations.BigramCollocationFinder.from_documents([comment.split() for comment in data_nouns.NewReview])"
      ],
      "metadata": {
        "id": "6oZC1Yrm-vzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finder.apply_freq_filter(5)\n",
        "bigram_scores=finder.score_ngrams(bigram_measures.pmi)"
      ],
      "metadata": {
        "id": "00qEHaos-vzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bigram_scores[10:30])"
      ],
      "metadata": {
        "id": "9DwTNn3Z-vzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20/04/22"
      ],
      "metadata": {
        "id": "AUg-ssuY9-hy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning the LDA model!!!"
      ],
      "metadata": {
        "id": "_2Gy7zzzknsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing those stopwords which were included before!"
      ],
      "metadata": {
        "id": "WpLL-dhXkq2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "sw=stopwords.words('english')\n",
        "print(sw)\n",
        "sw.append('didnt')\n",
        "sw.append('hadnt')\n",
        "sw.append('wont')\n",
        "sw.append('couldnt')\n",
        "sw.append('dont')\n",
        "sw.append('good')\n",
        "#trial=pd.DataFrame()\n",
        "df_review['NewReview']=df_review['NewReview'].apply(lambda x:\" \".join(x for x in str(x).split() if x not in sw))\n",
        "# trial['Review']=df_review['Review'].apply(lambda x:' '.join(x for x in str(x).split() if x not in sw))\n",
        "# trial['Sentiment']=df_review['Sentiment']"
      ],
      "metadata": {
        "id": "j4qkbJkzkwEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_nouns.head()"
      ],
      "metadata": {
        "id": "MkK7HAbBDEiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization done to apply Lemmatization\n",
        "w_tokenizer=nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer=nltk.stem.WordNetLemmatizer()\n",
        "d=pd.DataFrame()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "  return [w for w in w_tokenizer.tokenize(text)]\n",
        "\n",
        "d['TokenReviewLda']=data_nouns.NewReview.apply(lemmatize_text)\n",
        "print(d.head())"
      ],
      "metadata": {
        "id": "gudRMhtZXjrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.corpora import Dictionary\n",
        "dict_=Dictionary(d.TokenReviewLda)\n",
        "print(dict_)"
      ],
      "metadata": {
        "id": "c5GIaJHYpo7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_term_matrix=[dict_.doc2bow(i) for i in d.TokenReviewLda]\n",
        "for i in doc_term_matrix:\n",
        "  if i==[]:\n",
        "    doc_term_matrix.remove(i)\n",
        "print(doc_term_matrix)"
      ],
      "metadata": {
        "id": "U_QCSP6urYLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LdaModel=gensim.models.ldamodel.LdaModel\n",
        "lda=LdaModel(doc_term_matrix,num_topics=10,id2word=dict_,passes=50,iterations=500)"
      ],
      "metadata": {
        "id": "CNeuEE1Drzqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tpc in lda.print_topics():\n",
        "  print(tpc,\"\\n\")"
      ],
      "metadata": {
        "id": "tyqRhumWsN1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# vectorizer = CountVectorizer(analyzer='word',       \n",
        "#                              min_df=10,                        # minimum reqd occurences of a word \n",
        "#                              stop_words='english',             # remove stop words\n",
        "#                              lowercase=True,                   # convert all words to lowercase\n",
        "#                              token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
        "#                              # max_features=50000,             # max number of uniq words\n",
        "#                             )\n",
        "#vectorizer=CountVectorizer()\n",
        "num_components=4\n",
        "\n",
        "lda=LatentDirichletAllocation(n_components=num_components)\n",
        "train_vectorizer=TfidfVectorizer(use_idf=True,lowercase=True,strip_accents='ascii')\n",
        "\n",
        "#train_vectorizer=CountVectorizer(lowercase=True,strip_accents='ascii')\n",
        "nr_vectorized_neg_reviews=train_vectorizer.fit_transform(df_review[df_review['Sentiment']==0].NewReview)\n",
        "\n",
        "lda_matrix=lda.fit_transform(nr_vectorized_neg_reviews)\n",
        "\n",
        "lda_model_components=lda.components_"
      ],
      "metadata": {
        "id": "M3WlEWbSREME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the topics with their terms\n",
        "terms=train_vectorizer.get_feature_names()\n",
        "\n",
        "for index, component in enumerate(lda_model_components):\n",
        "  zipped=zip(terms,component)\n",
        "  top_terms_key=sorted(zipped, key=lambda t:t[1], reverse=True)[:10]\n",
        "  top_terms_list=list(dict(top_terms_key).keys())\n",
        "  print(\"Topic \"+str(index)+\": \",top_terms_list)"
      ],
      "metadata": {
        "id": "8fDDMmZURG1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###"
      ],
      "metadata": {
        "id": "A_ze5XeCfwrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count = CountVectorizer(stop_words='english', max_df=.1, max_features=2000)\n",
        "X = count.fit_transform(data_nouns.NewReview) #feature matrix"
      ],
      "metadata": {
        "id": "orcOc5L4fxp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda = LatentDirichletAllocation(n_components=5,\n",
        "                                learning_method='batch',\n",
        "                               )\n",
        "X_topics=lda.fit_transform(X)"
      ],
      "metadata": {
        "id": "MRWMQPQLgOma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_top_words=15\n",
        "feature_names=count.get_feature_names()\n",
        "for topic_idx, topic in enumerate(lda.components_):\n",
        "  print('Topic %d:' % (topic_idx+1))\n",
        "  print(\", \".join([feature_names[i]\n",
        "                  for i in topic.argsort()\n",
        "                  [:-n_top_words-1:-1]]))"
      ],
      "metadata": {
        "id": "lC048J0Nhi7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fBA5bdiIkxxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bigram_measures=nltk.collocations.BigramAssocMeasures()\n",
        "\n",
        "# finder=nltk.collocations.BigramCollocationFinder.from_documents([comment.split() for comment in df_review.NewReview])"
      ],
      "metadata": {
        "id": "EkuJ6kB_WnqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finder.apply_freq_filter(5)\n",
        "# bigram_scores=finder.score_ngrams(bigram_measures.pmi)"
      ],
      "metadata": {
        "id": "NXX3kxGVWqfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(bigram_scores))"
      ],
      "metadata": {
        "id": "bmGbY0DXXChK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def replace_ngram(x):\n",
        "#     for gram in bigram_scores:\n",
        "#         x = x.replace(gram, '_'.join(gram.split()))\n",
        "#     return x\n",
        "# reviews_w_ngrams = df_review.NewReview.copy()\n",
        "# reviews_w_ngrams.reviewText = reviews_w_ngrams.NewReview.map(lambda x: replace_ngram(x))"
      ],
      "metadata": {
        "id": "IN1xrsAifGNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning the LDA model #2- Nouns only!"
      ],
      "metadata": {
        "id": "xKec07K2aePh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "ncTJyIEebddr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from nltk.corpus import stopwords\n",
        "# sw=stopwords.words('english')\n",
        "# print(sw)\n",
        "# df_review['NewReview']=df_review['NewReview'].apply(lambda x:\" \".join(x for x in str(x).split() if x not in sw))"
      ],
      "metadata": {
        "id": "CBMR2DyMlEpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize, pos_tag\n",
        "\n",
        "def nouns(text):\n",
        "  '''extract nouns only from given string'''\n",
        "  is_noun=lambda pos:pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
        "  tokenized=word_tokenize(text)\n",
        "  all_nouns=[word for (word,pos) in pos_tag(tokenized) if is_noun(pos)]\n",
        "  return ' '.join(all_nouns)"
      ],
      "metadata": {
        "id": "HJrc1hfmaioC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_nouns=pd.DataFrame(df_review[df_review['Sentiment']==0].NewReview.apply(nouns))"
      ],
      "metadata": {
        "id": "3QmJchqTbBRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_nouns.head())"
      ],
      "metadata": {
        "id": "w_L-67BObWrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization\n",
        "w_tokenizer=nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer=nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def tokenize_text(text):\n",
        "  return [w for w in w_tokenizer.tokenize(text)]\n",
        "\n",
        "data_nouns['TokenReviewLda']=data_nouns.NewReview.apply(tokenize_text)\n",
        "print(data_nouns.head())"
      ],
      "metadata": {
        "id": "Hts9BLDCg8bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.corpora import Dictionary\n",
        "dict_=Dictionary(data_nouns.TokenReviewLda)\n",
        "print(dict_)"
      ],
      "metadata": {
        "id": "uIcAqLCyitMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a new document-term matrix using only nouns\n",
        "doc_term_matrix=[dict_.doc2bow(i) for i in data_nouns['TokenReviewLda']]\n",
        "print(doc_term_matrix)"
      ],
      "metadata": {
        "id": "huo35xe-cJUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LdaModel=gensim.models.ldamodel.LdaModel\n",
        "lda=LdaModel(doc_term_matrix,num_topics=5,id2word=dict_,)"
      ],
      "metadata": {
        "id": "G_HYVF5xhE35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tpc in lda.print_topics():\n",
        "  print(tpc,\"\\n\")"
      ],
      "metadata": {
        "id": "KsmigIOChG9r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}